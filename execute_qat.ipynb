{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *<font face =微軟黑體 color = aqua>qat.py</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available()) \n",
    "print(torch.version.cuda) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.8.0.43\n"
     ]
    }
   ],
   "source": [
    "import tensorrt\n",
    "print(tensorrt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *<font face =微軟黑體 color = aqua>quantize</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python qat.py quantize  --weights \"C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\train\\yolov9-c7\\weights\\best.pt\" --data data/coco.yaml --hyp ./data/hyps/hyp.scratch-high.yaml --name qat_yolov9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *<font face =微軟黑體 color = aqua>sensitive</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cmd='sensitive', weights='C:\\\\Users\\\\PZJ\\\\Desktop\\\\yolov9\\\\yolov9-main_measure\\\\yolov9-main\\\\runs\\\\train\\\\yolov9-c7\\\\weights\\\\best.pt', device='cuda:0', data='data/coco.yaml', batch_size=10, imgsz=640, hyp='./data/hyps/hyp.scratch-high.yaml', project=WindowsPath('runs/qat_sentive'), name='exp', exist_ok=False, num_image=None, save_dir='runs\\\\qat_sentive\\\\exp')\n",
      "Add QuantAdd to model.3.cv2.0.m.0\n",
      "Add QuantAdd to model.3.cv3.0.m.0\n",
      "Add ADownQuantChunk to model.4\n",
      "Add QuantAdd to model.5.cv2.0.m.0\n",
      "Add QuantAdd to model.5.cv3.0.m.0\n",
      "Add ADownQuantChunk to model.6\n",
      "Add QuantAdd to model.7.cv2.0.m.0\n",
      "Add QuantAdd to model.7.cv3.0.m.0\n",
      "Add ADownQuantChunk to model.8\n",
      "Add QuantAdd to model.9.cv2.0.m.0\n",
      "Add QuantAdd to model.9.cv3.0.m.0\n",
      "Add QuantUpsample to model.11\n",
      "Add QuantConcat to model.12\n",
      "Add QuantAdd to model.13.cv2.0.m.0\n",
      "Add QuantAdd to model.13.cv3.0.m.0\n",
      "Add QuantUpsample to model.14\n",
      "Add QuantConcat to model.15\n",
      "Add QuantAdd to model.16.cv2.0.m.0\n",
      "Add QuantAdd to model.16.cv3.0.m.0\n",
      "Add ADownQuantChunk to model.17\n",
      "Add QuantConcat to model.18\n",
      "Add QuantAdd to model.19.cv2.0.m.0\n",
      "Add QuantAdd to model.19.cv3.0.m.0\n",
      "Add ADownQuantChunk to model.20\n",
      "Add QuantConcat to model.21\n",
      "Add QuantAdd to model.22.cv2.0.m.0\n",
      "Add QuantAdd to model.22.cv3.0.m.0\n",
      "Add QuantAdd to model.28.cv2.0.m.0\n",
      "Add QuantAdd to model.28.cv3.0.m.0\n",
      "Add ADownQuantChunk to model.29\n",
      "Add QuantAdd to model.31.cv2.0.m.0\n",
      "Add QuantAdd to model.31.cv3.0.m.0\n",
      "Add ADownQuantChunk to model.32\n",
      "Add QuantAdd to model.34.cv2.0.m.0\n",
      "Add QuantAdd to model.34.cv3.0.m.0\n",
      "Add ADownQuantChunk to model.35\n",
      "Add QuantAdd to model.37.cv2.0.m.0\n",
      "Add QuantAdd to model.37.cv3.0.m.0\n",
      "Sensitive summary:\n",
      "Top0: Using fp16 model.6, ap = 0.31720\n",
      "Top1: Using fp16 model.8, ap = 0.31720\n",
      "Top2: Using fp16 model.18, ap = 0.31710\n",
      "Top3: Using fp16 model.12, ap = 0.31690\n",
      "Top4: Using fp16 model.5, ap = 0.31680\n",
      "Top5: Using fp16 model.13, ap = 0.31680\n",
      "Top6: Using fp16 model.16, ap = 0.31680\n",
      "Top7: Using fp16 model.17, ap = 0.31680\n",
      "Top8: Using fp16 model.19, ap = 0.31680\n",
      "Top9: Using fp16 model.22, ap = 0.31680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "yolov9-c summary: 604 layers, 50714448 parameters, 0 gradients, 236.7 GFLOPs\n",
      "\n",
      "Scanning C:\\Users\\PZJ\\Desktop\\yolov9\\train+val\\train+val\\train.cache... 802 images, 0 backgrounds, 0 corrupt: 100%|██████████| 802/802 00:00\n",
      "Scanning C:\\Users\\PZJ\\Desktop\\yolov9\\train+val\\train+val\\train.cache... 802 images, 0 backgrounds, 0 corrupt: 100%|██████████| 802/802 00:00\n",
      "\n",
      "Scanning C:\\Users\\PZJ\\Desktop\\yolov9\\train+val\\train+val\\val.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 00:00\n",
      "Scanning C:\\Users\\PZJ\\Desktop\\yolov9\\train+val\\train+val\\val.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 00:00\n",
      "\n",
      "Collect stats for calibrating:   0%|          | 0/25 [00:00<?, ?it/s]\n",
      "Collect stats for calibrating:   4%|▍         | 1/25 [00:01<00:25,  1.05s/it]\n",
      "Collect stats for calibrating:   8%|▊         | 2/25 [00:01<00:16,  1.39it/s]\n",
      "Collect stats for calibrating:  12%|█▏        | 3/25 [00:02<00:14,  1.49it/s]\n",
      "Collect stats for calibrating:  16%|█▌        | 4/25 [00:02<00:13,  1.56it/s]\n",
      "Collect stats for calibrating:  20%|██        | 5/25 [00:03<00:12,  1.59it/s]\n",
      "Collect stats for calibrating:  24%|██▍       | 6/25 [00:03<00:11,  1.62it/s]\n",
      "Collect stats for calibrating:  28%|██▊       | 7/25 [00:04<00:11,  1.63it/s]\n",
      "Collect stats for calibrating:  32%|███▏      | 8/25 [00:05<00:10,  1.64it/s]\n",
      "Collect stats for calibrating:  36%|███▌      | 9/25 [00:05<00:09,  1.65it/s]\n",
      "Collect stats for calibrating:  40%|████      | 10/25 [00:06<00:09,  1.66it/s]\n",
      "Collect stats for calibrating:  44%|████▍     | 11/25 [00:06<00:08,  1.66it/s]\n",
      "Collect stats for calibrating:  48%|████▊     | 12/25 [00:07<00:07,  1.66it/s]\n",
      "Collect stats for calibrating:  52%|█████▏    | 13/25 [00:08<00:07,  1.66it/s]\n",
      "Collect stats for calibrating:  56%|█████▌    | 14/25 [00:08<00:06,  1.66it/s]\n",
      "Collect stats for calibrating:  60%|██████    | 15/25 [00:09<00:05,  1.67it/s]\n",
      "Collect stats for calibrating:  64%|██████▍   | 16/25 [00:09<00:05,  1.67it/s]\n",
      "Collect stats for calibrating:  68%|██████▊   | 17/25 [00:10<00:04,  1.67it/s]\n",
      "Collect stats for calibrating:  72%|███████▏  | 18/25 [00:11<00:04,  1.67it/s]\n",
      "Collect stats for calibrating:  76%|███████▌  | 19/25 [00:11<00:03,  1.67it/s]\n",
      "Collect stats for calibrating:  80%|████████  | 20/25 [00:12<00:03,  1.66it/s]\n",
      "Collect stats for calibrating:  84%|████████▍ | 21/25 [00:12<00:02,  1.67it/s]\n",
      "Collect stats for calibrating:  88%|████████▊ | 22/25 [00:13<00:01,  1.67it/s]\n",
      "Collect stats for calibrating:  92%|█████████▏| 23/25 [00:14<00:01,  1.67it/s]\n",
      "Collect stats for calibrating:  96%|█████████▌| 24/25 [00:14<00:00,  1.67it/s]\n",
      "Collect stats for calibrating: 100%|██████████| 25/25 [00:15<00:00,  1.67it/s]\n",
      "Collect stats for calibrating: 100%|██████████| 25/25 [00:15<00:00,  1.57it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Evaluating PTQ...\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:07\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:07\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.942      0.596\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.495      0.467      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204       0.07\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT enabled on All Layers - AP: 0.3167 AP50: 0.6829 Precision: 0.6333 Recall: 0.6981\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Sensitive analysis by each layer. Layers Detected: 39\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Ignored Layer model.0 because it is <class 'models.common.Silence'>\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Ignored Layer model.1 because it is <class 'models.common.Conv'>\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Ignored Layer model.2 because it is <class 'models.common.Conv'>\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.3\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.634      0.698      0.683      0.316\n",
      "                hat_on        200        241      0.878      0.917      0.937      0.415\n",
      "               hat_off        200        238      0.855      0.937      0.943       0.41\n",
      "            clothes_on        200        292      0.848      0.921      0.942      0.594\n",
      "           clothes_off        200        196      0.758      0.896      0.894      0.467\n",
      "              shoes_on        200        283      0.506      0.802      0.671      0.287\n",
      "             shoes_off        200        104      0.492      0.493      0.466      0.175\n",
      "               mask_on        200        113      0.375      0.522      0.402      0.111\n",
      "              mask_off        200         63      0.356     0.0952      0.204     0.0702\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.3 - AP: 0.3162 AP50: 0.6825 Precision: 0.6336 Recall: 0.698\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.4\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530       0.63      0.701      0.685      0.317\n",
      "                hat_on        200        241       0.88      0.917      0.938      0.414\n",
      "               hat_off        200        238      0.846      0.937      0.942      0.411\n",
      "            clothes_on        200        292      0.851      0.928      0.943      0.596\n",
      "           clothes_off        200        196       0.75      0.901      0.895      0.467\n",
      "              shoes_on        200        283        0.5      0.802      0.671      0.286\n",
      "             shoes_off        200        104      0.484       0.49      0.458      0.174\n",
      "               mask_on        200        113      0.376      0.522      0.408      0.112\n",
      "              mask_off        200         63      0.355      0.111      0.222     0.0731\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.4 - AP: 0.3166 AP50: 0.6847 Precision: 0.6301 Recall: 0.7011\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.5\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530       0.64      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.884      0.915      0.935      0.414\n",
      "               hat_off        200        238      0.847      0.937      0.942      0.413\n",
      "            clothes_on        200        292      0.851      0.921      0.943      0.596\n",
      "           clothes_off        200        196      0.755      0.897      0.896      0.467\n",
      "              shoes_on        200        283      0.517      0.802      0.669      0.285\n",
      "             shoes_off        200        104      0.493      0.496      0.469      0.177\n",
      "               mask_on        200        113      0.375      0.522      0.401      0.112\n",
      "              mask_off        200         63      0.402     0.0952      0.206     0.0713\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.5 - AP: 0.3168 AP50: 0.6825 Precision: 0.6404 Recall: 0.6981\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.6\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530       0.63        0.7      0.684      0.317\n",
      "                hat_on        200        241       0.88      0.916      0.939      0.415\n",
      "               hat_off        200        238      0.848      0.937      0.943       0.41\n",
      "            clothes_on        200        292      0.843      0.925      0.942      0.596\n",
      "           clothes_off        200        196       0.75      0.901      0.897      0.467\n",
      "              shoes_on        200        283      0.504      0.809      0.671      0.287\n",
      "             shoes_off        200        104      0.492      0.494      0.468      0.177\n",
      "               mask_on        200        113      0.384      0.522      0.406      0.113\n",
      "              mask_off        200         63       0.34     0.0952      0.203     0.0715\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.6 - AP: 0.3172 AP50: 0.6835 Precision: 0.6302 Recall: 0.6999\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.7\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.634      0.696      0.682      0.316\n",
      "                hat_on        200        241      0.876      0.909      0.933      0.415\n",
      "               hat_off        200        238      0.849      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.847      0.921      0.943      0.592\n",
      "           clothes_off        200        196      0.744      0.898      0.895      0.465\n",
      "              shoes_on        200        283      0.507      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.483      0.485      0.463      0.175\n",
      "               mask_on        200        113      0.384      0.522      0.405      0.111\n",
      "              mask_off        200         63      0.381     0.0952      0.203     0.0738\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.7 - AP: 0.3164 AP50: 0.6818 Precision: 0.6339 Recall: 0.6962\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.8\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.699      0.683      0.317\n",
      "                hat_on        200        241      0.877      0.913      0.938      0.414\n",
      "               hat_off        200        238      0.846      0.937      0.943      0.412\n",
      "            clothes_on        200        292      0.851      0.923      0.943      0.595\n",
      "           clothes_off        200        196       0.75      0.898      0.899       0.47\n",
      "              shoes_on        200        283      0.511      0.806      0.668      0.286\n",
      "             shoes_off        200        104      0.498      0.495      0.467      0.175\n",
      "               mask_on        200        113      0.386      0.522      0.406      0.111\n",
      "              mask_off        200         63      0.349     0.0952      0.203     0.0729\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.8 - AP: 0.3172 AP50: 0.6834 Precision: 0.6334 Recall: 0.6986\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.9\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.621      0.698      0.682      0.317\n",
      "                hat_on        200        241      0.873      0.912      0.934      0.414\n",
      "               hat_off        200        238      0.843      0.937      0.943      0.412\n",
      "            clothes_on        200        292      0.844      0.921      0.943      0.595\n",
      "           clothes_off        200        196      0.744      0.903      0.899      0.468\n",
      "              shoes_on        200        283      0.507      0.811       0.67      0.287\n",
      "             shoes_off        200        104      0.477      0.481      0.461      0.174\n",
      "               mask_on        200        113      0.371      0.522      0.404      0.112\n",
      "              mask_off        200         63      0.309     0.0952      0.202     0.0708\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.9 - AP: 0.3166 AP50: 0.682 Precision: 0.6211 Recall: 0.6979\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Ignored Layer model.10 because it is <class 'models.common.SPPELAN'>\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.11\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.942      0.596\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.495      0.467      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204       0.07\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.11 - AP: 0.3167 AP50: 0.6829 Precision: 0.6333 Recall: 0.6981\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.12\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.638      0.697      0.682      0.317\n",
      "                hat_on        200        241      0.884      0.918      0.939      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.411\n",
      "            clothes_on        200        292      0.852      0.921      0.943      0.596\n",
      "           clothes_off        200        196      0.745      0.888      0.894      0.466\n",
      "              shoes_on        200        283      0.516      0.806      0.669      0.285\n",
      "             shoes_off        200        104      0.492      0.493      0.461      0.178\n",
      "               mask_on        200        113      0.382      0.522      0.404      0.112\n",
      "              mask_off        200         63      0.385     0.0952      0.205     0.0738\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.12 - AP: 0.3169 AP50: 0.6821 Precision: 0.6375 Recall: 0.6975\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.13\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.635      0.698      0.683      0.317\n",
      "                hat_on        200        241       0.88      0.913      0.938      0.413\n",
      "               hat_off        200        238      0.848      0.937      0.943      0.411\n",
      "            clothes_on        200        292      0.853      0.921      0.943      0.595\n",
      "           clothes_off        200        196      0.748      0.898      0.898       0.47\n",
      "              shoes_on        200        283      0.509      0.802      0.668      0.287\n",
      "             shoes_off        200        104      0.494      0.497      0.469      0.175\n",
      "               mask_on        200        113      0.379      0.522      0.403      0.111\n",
      "              mask_off        200         63       0.37     0.0952      0.204     0.0724\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.13 - AP: 0.3168 AP50: 0.6832 Precision: 0.6351 Recall: 0.6982\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.14\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.942      0.596\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.495      0.467      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204       0.07\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.14 - AP: 0.3167 AP50: 0.6829 Precision: 0.6333 Recall: 0.6981\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.15\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.697      0.683      0.317\n",
      "                hat_on        200        241       0.88      0.914      0.935      0.415\n",
      "               hat_off        200        238      0.849      0.937      0.943      0.412\n",
      "            clothes_on        200        292       0.85      0.925      0.943      0.595\n",
      "           clothes_off        200        196      0.746      0.903      0.898      0.465\n",
      "              shoes_on        200        283      0.507      0.795      0.668      0.284\n",
      "             shoes_off        200        104      0.483      0.485      0.459      0.174\n",
      "               mask_on        200        113      0.384      0.522      0.409      0.114\n",
      "              mask_off        200         63      0.366     0.0952      0.206     0.0732\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.15 - AP: 0.3166 AP50: 0.6826 Precision: 0.633 Recall: 0.6971\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.16\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.638      0.697      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.933      0.414\n",
      "               hat_off        200        238      0.846      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.852      0.921      0.943      0.595\n",
      "           clothes_off        200        196      0.749      0.898      0.898      0.466\n",
      "              shoes_on        200        283      0.514      0.802       0.67      0.288\n",
      "             shoes_off        200        104      0.479      0.477      0.459      0.175\n",
      "               mask_on        200        113      0.393       0.54      0.414      0.115\n",
      "              mask_off        200         63      0.401     0.0952      0.201     0.0699\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.16 - AP: 0.3168 AP50: 0.6826 Precision: 0.6384 Recall: 0.6974\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.17\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.696      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.935      0.414\n",
      "               hat_off        200        238      0.843      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.849      0.921      0.943      0.594\n",
      "           clothes_off        200        196      0.751      0.903      0.899      0.467\n",
      "              shoes_on        200        283      0.512      0.802       0.67      0.287\n",
      "             shoes_off        200        104      0.485      0.479      0.467      0.177\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204     0.0699\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.17 - AP: 0.3168 AP50: 0.6833 Precision: 0.6325 Recall: 0.6961\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.18\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.634      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.933      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.849      0.921      0.942      0.596\n",
      "           clothes_off        200        196      0.749      0.903      0.897      0.468\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.494      0.497      0.468      0.178\n",
      "               mask_on        200        113      0.382      0.522      0.407      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.203     0.0697\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.18 - AP: 0.3171 AP50: 0.6827 Precision: 0.6336 Recall: 0.6984\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.19\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.943      0.596\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.496      0.468      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204     0.0699\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.19 - AP: 0.3168 AP50: 0.6831 Precision: 0.6332 Recall: 0.6982\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.20\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.413\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.942      0.597\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.495      0.467      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.203     0.0697\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.20 - AP: 0.3166 AP50: 0.6827 Precision: 0.6333 Recall: 0.6981\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.21\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.413\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.942      0.597\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.495      0.468      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204     0.0699\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.21 - AP: 0.3167 AP50: 0.6831 Precision: 0.6333 Recall: 0.6981\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.22\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.942      0.597\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.495      0.468      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.407      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204     0.0699\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.22 - AP: 0.3168 AP50: 0.6831 Precision: 0.6333 Recall: 0.6981\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Ignored Layer model.23 because it is <class 'models.common.CBLinear'>\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Ignored Layer model.24 because it is <class 'models.common.CBLinear'>\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Ignored Layer model.25 because it is <class 'models.common.CBLinear'>\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Ignored Layer model.26 because it is <class 'models.common.Conv'>\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Ignored Layer model.27 because it is <class 'models.common.Conv'>\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.28\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.942      0.596\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.495      0.467      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204       0.07\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.28 - AP: 0.3167 AP50: 0.6829 Precision: 0.6333 Recall: 0.6981\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.29\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.942      0.596\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.495      0.467      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204       0.07\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.29 - AP: 0.3167 AP50: 0.6829 Precision: 0.6333 Recall: 0.6981\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Ignored Layer model.30 because it is <class 'models.common.CBFuse'>\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.31\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.942      0.596\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.495      0.467      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204       0.07\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.31 - AP: 0.3167 AP50: 0.6829 Precision: 0.6333 Recall: 0.6981\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.32\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.942      0.596\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.495      0.467      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204       0.07\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.32 - AP: 0.3167 AP50: 0.6829 Precision: 0.6333 Recall: 0.6981\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Ignored Layer model.33 because it is <class 'models.common.CBFuse'>\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.34\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.942      0.596\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.495      0.467      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204       0.07\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.34 - AP: 0.3167 AP50: 0.6829 Precision: 0.6333 Recall: 0.6981\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.35\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.942      0.596\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.495      0.467      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204       0.07\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.35 - AP: 0.3167 AP50: 0.6829 Precision: 0.6333 Recall: 0.6981\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Ignored Layer model.36 because it is <class 'models.common.CBFuse'>\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m QAT disabled on Layer model.37\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:06\n",
      "                   all        200       1530      0.633      0.698      0.683      0.317\n",
      "                hat_on        200        241      0.873      0.909      0.934      0.414\n",
      "               hat_off        200        238      0.845      0.937      0.943      0.413\n",
      "            clothes_on        200        292      0.846      0.921      0.942      0.596\n",
      "           clothes_off        200        196      0.749      0.903      0.898      0.467\n",
      "              shoes_on        200        283      0.512      0.802      0.669      0.287\n",
      "             shoes_off        200        104      0.493      0.495      0.467      0.175\n",
      "               mask_on        200        113      0.382      0.522      0.406      0.112\n",
      "              mask_off        200         63      0.366     0.0952      0.204       0.07\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Eval PTQ - QAT disabled on Layer model.37 - AP: 0.3167 AP50: 0.6829 Precision: 0.6333 Recall: 0.6981\n",
      "\n",
      "\u001b[34m\u001b[1mQAT ANALYSIS:\u001b[0m Ignored Layer model.38 because it is <class 'models.yolo.DualDDetect'>\n"
     ]
    }
   ],
   "source": [
    "!python qat.py sensitive --weights \"C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\train\\yolov9-c7\\weights\\best.pt\" --data data/coco.yaml --hyp ./data/hyps/hyp.scratch-high.yaml --name sensitive_qat_yolov9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *<font face =微軟黑體 color = aqua>Evaluate QAT Model</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Evaluate using Pytorch</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cmd='eval', weights='C:\\\\Users\\\\PZJ\\\\Desktop\\\\yolov9\\\\yolov9-main_measure\\\\yolov9-main\\\\runs\\\\qat\\\\exp\\\\weights\\\\qat_best_best.pt', data='data/coco.yaml', batch_size=10, imgsz=640, device='cuda:0', conf_thres=0.001, iou_thres=0.7, project=WindowsPath('runs/qat_eval'), name='eval_qat_yolov9', exist_ok=False, save_dir='runs\\\\qat_eval\\\\eval_qat_yolov9')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "yolov9-c summary: 1051 layers, 50714448 parameters, 50714448 gradients, 3.6 GFLOPs\n",
      "\n",
      "Scanning C:\\Users\\PZJ\\Desktop\\yolov9\\train+val\\train+val\\val.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 00:00\n",
      "Scanning C:\\Users\\PZJ\\Desktop\\yolov9\\train+val\\train+val\\val.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 00:00\n",
      "\n",
      "\u001b[34m\u001b[1mQAT TEST:\u001b[0m Evaluating ...\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/20 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▌         | 1/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 2/20 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▌        | 3/20 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|██        | 4/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 5/20 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|███       | 6/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▌      | 7/20 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 8/20 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▌     | 9/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 10/20 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 11/20 00:07\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|██████    | 12/20 00:07\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 13/20 00:08\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 14/20 00:08\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 15/20 00:09\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 16/20 00:10\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 17/20 00:10\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|█████████ | 18/20 00:11\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 19/20 00:11\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:12\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 20/20 00:12\n",
      "                   all        200       1530      0.618      0.707      0.686      0.318\n",
      "                hat_on        200        241      0.888      0.923      0.941      0.413\n",
      "               hat_off        200        238      0.845      0.937      0.939      0.411\n",
      "            clothes_on        200        292      0.856      0.935      0.943      0.599\n",
      "           clothes_off        200        196      0.715      0.895      0.887      0.461\n",
      "              shoes_on        200        283       0.48       0.83      0.682      0.289\n",
      "             shoes_off        200        104      0.476      0.533      0.485      0.186\n",
      "               mask_on        200        113      0.358      0.504      0.399      0.113\n",
      "              mask_off        200         63      0.329     0.0952      0.214     0.0722\n",
      "\n",
      "\u001b[34m\u001b[1mQAT TEST:\u001b[0m Eval Result - AP: 0.318 AP50: 0.6862 Precision: 0.6184 Recall: 0.7065\n",
      "\n",
      "\u001b[34m\u001b[1mQAT TEST:\u001b[0m Eval Result, saved on runs\\qat_eval\\eval_qat_yolov9\n"
     ]
    }
   ],
   "source": [
    "!python qat.py eval --weights \"C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\qat\\qat_yolov9\\weights\\qat_best_best.pt\"  --name eval_qat_yolov9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *<font face=\"微軟黑體\" color=\"aqua\">Export ONNX (<font color=\"red\">YOLO model has already trained by QAT</font>)</font>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face=\"微軟黑體\" color=\"aqua\">pip install numpy==1.23.5</font>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = #FF79BC>Purpose：Export .pt file to .engine or .onnx file</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *<font face =微軟黑體 color = \t#FFAF60>Include Options：torchscript, onnx, onnx_end2end, openvino, engine, coreml, saved_model, pb, tflite, edgetpu, tfjs, paddle</font>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 微軟黑體; color: #FFAF60;\">Notes：\n",
    "    if 'onnx_end2end' in opt.include:  \n",
    "        opt.simplify = True  \n",
    "        opt.dynamic = True  \n",
    "        opt.inplace = True  \n",
    "        opt.half = False\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Export ONNX Model without End2End </font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport_qat: \u001b[0mdata=C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\data\\coco.yaml, weights=['C:\\\\Users\\\\PZJ\\\\Desktop\\\\yolov9\\\\yolov9-main_measure\\\\yolov9-main\\\\runs\\\\qat\\\\qat_yolov9\\\\weights\\\\qat_best_best.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=True, keras=False, optimize=False, int8=False, dynamic=True, simplify=True, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, class_agnostic=False, mask_resolution=160, pooler_scale=0.25, sampling_ratio=0, include=['onnx']\n",
      "YOLO  2025-1-27 Python-3.10.16 torch-2.5.1+cu121 CPU\n",
      "\n",
      "c:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\models\\experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
      "Fusing layers... \n",
      "yolov9-c summary: 1051 layers, 50714448 parameters, 50714448 gradients, 3.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\qat\\qat_yolov9\\weights\\qat_best_best.pt with output shape (1, 12, 8400) (198.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m Model QAT Detected ...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnx-simplifier 0.4.35...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m Removing redundant Q/DQ layer with onnx_graphsurgeon 0.5.2...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  32.8s, saved as C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\qat\\qat_yolov9\\weights\\qat_best_best.onnx (194.3 MB)\n",
      "\n",
      "Export complete (35.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\qat\\qat_yolov9\\weights\u001b[0m\n",
      "Detect:          python detect.py --weights C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\qat\\qat_yolov9\\weights\\qat_best_best.onnx \n",
      "Validate:        python val.py --weights C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\qat\\qat_yolov9\\weights\\qat_best_best.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\qat\\qat_yolov9\\weights\\qat_best_best.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "# First step\n",
    "!python export_qat.py --weights \"C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\qat\\qat_yolov9\\weights\\qat_best_best.pt\" --include onnx --dynamic --simplify --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Export ONNX Model End2End</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PZJ\\AppData\\Local\\Temp\\ipykernel_29388\\698396166.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['model'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 載入模型\n",
    "model_path = \"C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.pt\"\n",
    "model = torch.load(model_path, map_location=\"cpu\")\n",
    "\n",
    "# 檢查模型類別\n",
    "print(type(model))\n",
    "print(model.keys())  # 查看權重字典的鍵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport_qat: \u001b[0mdata=C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\data\\coco.yaml, weights=['C:\\\\Users\\\\PZJ\\\\Desktop\\\\yolov9\\\\yolov9-main_measure\\\\yolov9-main\\\\runs\\\\qat\\\\qat_yolov9\\\\weights\\\\qat_best_best.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=True, keras=False, optimize=False, int8=False, dynamic=True, simplify=True, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, class_agnostic=False, mask_resolution=160, pooler_scale=0.25, sampling_ratio=0, include=['onnx_end2end']\n",
      "YOLO  2025-1-27 Python-3.10.16 torch-2.5.1+cu121 CPU\n",
      "\n",
      "c:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\models\\experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
      "Fusing layers... \n",
      "yolov9-c summary: 1051 layers, 50714448 parameters, 50714448 gradients, 3.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\qat\\qat_yolov9\\weights\\qat_best_best.pt with output shape (1, 12, 8400) (198.4 MB)\n",
      "\u001b[34m\u001b[1mONNX END2END:\u001b[0m export failure  0.0s: Model not supported. Only Detection Models can be exported with End2End functionality.\n"
     ]
    }
   ],
   "source": [
    "# First step\n",
    "!python export_qat.py --weights \"C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\qat\\qat_yolov9\\weights\\qat_best_best.pt\" --include onnx_end2end\n",
    "\n",
    "# -> YOLOv9 可能不支援 End2End 模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *<font face=\"微軟黑體\" color=\"aqua\">Export ONNX (<font color=\"red\">YOLO model hasn't trained by QAT yet</font>)</font>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face=\"微軟黑體\" color=\"aqua\">pip install numpy==1.23.5</font>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = #FF79BC>Purpose：Export .pt file to .engine or onnx file</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *<font face =微軟黑體 color = \t#FFAF60>Include Options：torchscript, onnx, onnx_end2end, openvino, engine, coreml, saved_model, pb, tflite, edgetpu, tfjs, paddle</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 微軟黑體; color: #FFAF60;\">Notes：\n",
    "    if 'onnx_end2end' in opt.include:  \n",
    "        opt.simplify = True  \n",
    "        opt.dynamic = True  \n",
    "        opt.inplace = True  \n",
    "        opt.half = False\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Export ONNX Model without End2End </font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\data\\coco.yaml, weights=['C:\\\\Users\\\\PZJ\\\\Desktop\\\\yolov9\\\\yolov9-main_measure\\\\yolov9-main\\\\runs\\\\train\\\\yolov9-c7\\\\weights\\\\best.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=True, keras=False, optimize=False, int8=False, dynamic=True, simplify=True, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\n",
      "YOLO  2025-1-27 Python-3.10.16 torch-2.5.1+cu121 CPU\n",
      "\n",
      "c:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\models\\experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
      "Fusing layers... \n",
      "yolov9-c summary: 604 layers, 50714448 parameters, 0 gradients, 236.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\train\\yolov9-c7\\weights\\best.pt with output shape (1, 12, 8400) (98.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnx-simplifier 0.4.35...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  19.1s, saved as C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\train\\yolov9-c7\\weights\\best.onnx (193.7 MB)\n",
      "\n",
      "Export complete (21.6s)\n",
      "Results saved to \u001b[1mC:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\train\\yolov9-c7\\weights\u001b[0m\n",
      "Detect:          python detect.py --weights C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\train\\yolov9-c7\\weights\\best.onnx \n",
      "Validate:        python val.py --weights C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\train\\yolov9-c7\\weights\\best.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\train\\yolov9-c7\\weights\\best.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "# First step\n",
    "!python export.py --weights \"C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\train\\yolov9-c7\\weights\\best.pt\" --include onnx --dynamic --simplify --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Export ONNX Model End2End</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting to simplify ONNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\data\\coco.yaml, weights=['C:\\\\Users\\\\PZJ\\\\Desktop\\\\yolov9\\\\yolov9-main_measure\\\\yolov9-main\\\\runs\\\\train\\\\yolov9-c7\\\\weights\\\\best.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=True, keras=False, optimize=False, int8=False, dynamic=True, simplify=True, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx_end2end']\n",
      "YOLO  2025-1-27 Python-3.10.16 torch-2.5.1+cu121 CPU\n",
      "\n",
      "c:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\models\\experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
      "Fusing layers... \n",
      "yolov9-c summary: 604 layers, 50714448 parameters, 0 gradients, 236.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\train\\yolov9-c7\\weights\\best.pt with output shape (1, 12, 8400) (98.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX END2END:\u001b[0m starting export with onnx 1.17.0...\n",
      "[W129 00:59:38.000000000 shape_type_inference.cpp:1999] Warning: The shape inference of TRT::EfficientNMS_TRT type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W129 00:59:38.000000000 shape_type_inference.cpp:1999] Warning: The shape inference of TRT::EfficientNMS_TRT type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W129 00:59:38.000000000 shape_type_inference.cpp:1999] Warning: The shape inference of TRT::EfficientNMS_TRT type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W129 00:59:38.000000000 shape_type_inference.cpp:1999] Warning: The shape inference of TRT::EfficientNMS_TRT type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n"
     ]
    }
   ],
   "source": [
    "# First step\n",
    "!python export.py --weights \"C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\train\\yolov9-c7\\weights\\best.pt\" --include onnx_end2end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *<font face =微軟黑體 color = aqua>Evaluate QAT Model</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Evaluate using TensorRT</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./scripts/val_trt.sh \"C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.pt\" data/coco.yaml 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./scripts/val_trt.sh \"C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.pt\" data/coco.yaml 640 --generate-graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *<font face =微軟黑體 color = #FFAF60>Run on WSL Ubuntu-20.04 LTS</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *<font face =微軟黑體 color = #FFAF60>python -c \"import torch; import torchvision; print(torch.__version__, torch.version.cuda, torchvision.__version__)\"  -> 2.6.0+cu118 11.8 0.21.0+cu118 </font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on WSL Ubuntu-20.04 LTS \n",
    "# cd /mnt/c/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./scripts/val_trt.sh runs/qat/qat_yolov9/weights/qat_best_best.pt data/coco.yaml 640 --generate-graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Generate TensorRT Profiling and SVG image](Generate-TensoRT-Profiling-and-SVG-image-within-pt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./scripts/val_trt.sh runs/qat/qat_yolov9/weights/qat_best_best.onnx data/coco.yaml 640 --generate-graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Generate TensorRT Profiling and SVG image](Generate-TensoRT-Profiling-and-SVG-image-within-onnx.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./scripts/val_trt.sh runs/qat/qat_yolov9/weights/qat_best_best.engine data/coco.yaml 640 --generate-graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Generate TensorRT Profiling and SVG image](Generate-TensoRT-Profiling-and-SVG-image-within-engine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *<font face =微軟黑體 color = #FFAF60>=============================================================================</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ONNX 模型檢查通過！\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# 指定 ONNX 模型路徑\n",
    "model_path = \"../yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.onnx\"\n",
    "\n",
    "# 讀取並檢查 ONNX 模型\n",
    "try:\n",
    "    model = onnx.load(model_path)\n",
    "    onnx.checker.check_model(model)\n",
    "    print(\"✅ ONNX 模型檢查通過！\")\n",
    "except onnx.onnx_cpp2py_export.checker.ValidationError as e:\n",
    "    print(f\"❌ ONNX 模型無效: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 無法加載 ONNX 模型: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Name: images, Shape: [0, 3, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "model_path = \"C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.onnx\"\n",
    "onnx_model = onnx.load(model_path)\n",
    "for input in onnx_model.graph.input:\n",
    "    name = input.name\n",
    "    shape = [dim.dim_value for dim in input.type.tensor_type.shape.dim]\n",
    "    print(f\"Input Name: {name}, Shape: {shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing command: trtexec --onnx C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.onnx --saveEngine C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.engine --fp16 --int8 --useCudaGraph --minShapes=images:1x3x672x672 --optShapes=images:1x3x672x672 --maxShapes=images:1x3x672x672 --memPoolSize=workspace:5239MiB --timingCacheFile C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.engine.timing.cache\n",
      "&&&& RUNNING TensorRT.trtexec [TensorRT v100100] # trtexec --onnx C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.onnx --saveEngine C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.engine --fp16 --int8 --useCudaGraph --minShapes=images:1x3x672x672 --optShapes=images:1x3x672x672 --maxShapes=images:1x3x672x672 --memPoolSize=workspace:5239MiB --timingCacheFile C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.engine.timing.cache\n",
      "=== Model Options ===\n",
      "  --onnx=<file>               ONNX model\n",
      "\n",
      "=== Build Options ===\n",
      "  --minShapes=spec                   Build with dynamic shapes using a profile with the min shapes provided\n",
      "  --optShapes=spec                   Build with dynamic shapes using a profile with the opt shapes provided\n",
      "  --maxShapes=spec                   Build with dynamic shapes using a profile with the max shapes provided\n",
      "  --minShapesCalib=spec              Calibrate with dynamic shapes using a profile with the min shapes provided\n",
      "  --optShapesCalib=spec              Calibrate with dynamic shapes using a profile with the opt shapes provided\n",
      "  --maxShapesCalib=spec              Calibrate with dynamic shapes using a profile with the max shapes provided\n",
      "                                     Note: All three of min, opt and max shapes must be supplied.\n",
      "                                           However, if only opt shapes is supplied then it will be expanded so\n",
      "                                           that min shapes and max shapes are set to the same values as opt shapes.\n",
      "                                           Input names can be wrapped with escaped single quotes (ex: 'Input:0').\n",
      "                                     Example input shapes spec: input0:1x3x256x256,input1:1x3x128x128\n",
      "                                     For scalars (0-D shapes), use input0:scalar or simply input0: with nothing after the colon.\n",
      "                                     Each input shape is supplied as a key-value pair where key is the input name and\n",
      "                                     value is the dimensions (including the batch dimension) to be used for that input.\n",
      "                                     Each key-value pair has the key and value separated using a colon (:).\n",
      "                                     Multiple input shapes can be provided via comma-separated key-value pairs, and each input name can\n",
      "                                     contain at most one wildcard ('*') character.\n",
      "  --inputIOFormats=spec              Type and format of each of the input tensors (default = all inputs in fp32:chw)\n",
      "                                     See --outputIOFormats help for the grammar of type and format list.\n",
      "                                     Note: If this option is specified, please set comma-separated types and formats for all\n",
      "                                           inputs following the same order as network inputs ID (even if only one input\n",
      "                                           needs specifying IO format) or set the type and format once for broadcasting.\n",
      "  --outputIOFormats=spec             Type and format of each of the output tensors (default = all outputs in fp32:chw)\n",
      "                                     Note: If this option is specified, please set comma-separated types and formats for all\n",
      "                                           outputs following the same order as network outputs ID (even if only one output\n",
      "                                           needs specifying IO format) or set the type and format once for broadcasting.\n",
      "                                     IO Formats: spec  ::= IOfmt[\",\"spec]\n",
      "                                                 IOfmt ::= type:fmt\n",
      "                                               type  ::= \"fp32\"|\"fp16\"|\"bf16\"|\"int32\"|\"int64\"|\"int8\"|\"uint8\"|\"bool\"\n",
      "                                               fmt   ::= (\"chw\"|\"chw2\"|\"chw4\"|\"hwc8\"|\"chw16\"|\"chw32\"|\"dhwc8\"|\n",
      "                                                          \"cdhw32\"|\"hwc\"|\"dla_linear\"|\"dla_hwc4\")[\"+\"fmt]\n",
      "  --memPoolSize=poolspec             Specify the size constraints of the designated memory pool(s)\n",
      "                                     Supports the following base-2 suffixes: B (Bytes), G (Gibibytes), K (Kibibytes), M (Mebibytes).\n",
      "                                     If none of suffixes is appended, the defualt unit is in MiB.\n",
      "                                     Note: Also accepts decimal sizes, e.g. 0.25M. Will be rounded down to the nearest integer bytes.\n",
      "                                     In particular, for dlaSRAM the bytes will be rounded down to the nearest power of 2.\n",
      "                                   Pool constraint: poolspec ::= poolfmt[\",\"poolspec]\n",
      "                                                      poolfmt ::= pool:size\n",
      "                                                    pool ::= \"workspace\"|\"dlaSRAM\"|\"dlaLocalDRAM\"|\"dlaGlobalDRAM\"|\"tacticSharedMem\"\n",
      "  --profilingVerbosity=mode          Specify profiling verbosity. mode ::= layer_names_only|detailed|none (default = layer_names_only).\n",
      "                                     Please only assign once.\n",
      "  --avgTiming=M                      Set the number of times averaged in each iteration for kernel selection (default = 8)\n",
      "  --refit                            Mark the engine as refittable. This will allow the inspection of refittable layers \n",
      "                                     and weights within the engine.\n",
      "  --stripWeights                     Strip weights from plan. This flag works with either refit or refit with identical weights. Default\n",
      "                                     to latter, but you can switch to the former by enabling both --stripWeights and --refit at the same\n",
      "                                     time.\n",
      "  --stripAllWeights                  Alias for combining the --refit and --stripWeights options. It marks all weights as refittable,\n",
      "                                     disregarding any performance impact. Additionally, it strips all refittable weights after the \n",
      "                                     engine is built.\n",
      "  --weightless                       [Deprecated] this knob has been deprecated. Please use --stripWeights\n",
      "  --versionCompatible, --vc          Mark the engine as version compatible. This allows the engine to be used with newer versions\n",
      "                                     of TensorRT on the same host OS, as well as TensorRT's dispatch and lean runtimes.\n",
      "  --pluginInstanceNorm, --pi         Set `kNATIVE_INSTANCENORM` to false in the ONNX parser. This will cause the ONNX parser to use\n",
      "                                     a plugin InstanceNorm implementation over the native implementation when parsing.\n",
      "  --useRuntime=runtime               TensorRT runtime to execute engine. \"lean\" and \"dispatch\" require loading VC engine and do\n",
      "                                     not support building an engine.\n",
      "                                           runtime::= \"full\"|\"lean\"|\"dispatch\"\n",
      "  --leanDLLPath=<file>               External lean runtime DLL to use in version compatiable mode.\n",
      "  --excludeLeanRuntime               When --versionCompatible is enabled, this flag indicates that the generated engine should\n",
      "                                     not include an embedded lean runtime. If this is set, the user must explicitly specify a\n",
      "                                     valid lean runtime to use when loading the engine.\n",
      "  --sparsity=spec                    Control sparsity (default = disabled). \n",
      "                                   Sparsity: spec ::= \"disable\", \"enable\", \"force\"\n",
      "                                     Note: Description about each of these options is as below\n",
      "                                           disable = do not enable sparse tactics in the builder (this is the default)\n",
      "                                           enable  = enable sparse tactics in the builder (but these tactics will only be\n",
      "                                                     considered if the weights have the right sparsity pattern)\n",
      "                                           force   = enable sparse tactics in the builder and force-overwrite the weights to have\n",
      "                                                     a sparsity pattern (even if you loaded a model yourself)\n",
      "                                                     [Deprecated] this knob has been deprecated.\n",
      "                                                     Please use <polygraphy surgeon prune> to rewrite the weights.\n",
      "  --noTF32                           Disable tf32 precision (default is to enable tf32, in addition to fp32)\n",
      "  --fp16                             Enable fp16 precision, in addition to fp32 (default = disabled)\n",
      "  --bf16                             Enable bf16 precision, in addition to fp32 (default = disabled)\n",
      "  --int8                             Enable int8 precision, in addition to fp32 (default = disabled)\n",
      "  --fp8                              Enable fp8 precision, in addition to fp32 (default = disabled)\n",
      "  --int4                             Enable int4 precision, in addition to fp32 (default = disabled)\n",
      "  --best                             Enable all precisions to achieve the best performance (default = disabled)\n",
      "  --stronglyTyped                    Create a strongly typed network. (default = disabled)\n",
      "  --directIO                         Avoid reformatting at network boundaries. (default = disabled)\n",
      "  --precisionConstraints=spec        Control precision constraint setting. (default = none)\n",
      "                                       Precision Constraints: spec ::= \"none\" | \"obey\" | \"prefer\"\n",
      "                                         none = no constraints\n",
      "                                         prefer = meet precision constraints set by --layerPrecisions/--layerOutputTypes if possible\n",
      "                                         obey = meet precision constraints set by --layerPrecisions/--layerOutputTypes or fail\n",
      "                                                otherwise\n",
      "  --layerPrecisions=spec             Control per-layer precision constraints. Effective only when precisionConstraints is set to\n",
      "                                   \"obey\" or \"prefer\". (default = none)\n",
      "                                   The specs are read left-to-right, and later ones override earlier ones. Each layer name can\n",
      "                                     contain at most one wildcard ('*') character.\n",
      "                                   Per-layer precision spec ::= layerPrecision[\",\"spec]\n",
      "                                                       layerPrecision ::= layerName\":\"precision\n",
      "                                                       precision ::= \"fp32\"|\"fp16\"|\"bf16\"|\"int32\"|\"int8\"\n",
      "  --layerOutputTypes=spec            Control per-layer output type constraints. Effective only when precisionConstraints is set to\n",
      "                                   \"obey\" or \"prefer\". (default = none\n",
      "                                   The specs are read left-to-right, and later ones override earlier ones. Each layer name can\n",
      "                                     contain at most one wildcard ('*') character. If a layer has more than\n",
      "                                   one output, then multiple types separated by \"+\" can be provided for this layer.\n",
      "                                   Per-layer output type spec ::= layerOutputTypes[\",\"spec]\n",
      "                                                         layerOutputTypes ::= layerName\":\"type\n",
      "                                                         type ::= \"fp32\"|\"fp16\"|\"bf16\"|\"int32\"|\"int8\"[\"+\"type]\n",
      "  --layerDeviceTypes=spec            Specify layer-specific device type.\n",
      "                                     The specs are read left-to-right, and later ones override earlier ones. If a layer does not have\n",
      "                                     a device type specified, the layer will opt for the default device type.\n",
      "                                   Per-layer device type spec ::= layerDeviceTypePair[\",\"spec]\n",
      "                                                         layerDeviceTypePair ::= layerName\":\"deviceType\n",
      "                                                           deviceType ::= \"GPU\"|\"DLA\"\n",
      "  --calib=<file>                     Read INT8 calibration cache file\n",
      "  --safe                             Enable build safety certified engine, if DLA is enable, --buildDLAStandalone will be specified\n",
      "                                     automatically (default = disabled)\n",
      "  --buildDLAStandalone               Enable build DLA standalone loadable which can be loaded by cuDLA, when this option is enabled, \n",
      "                                     --allowGPUFallback is disallowed and --skipInference is enabled by default. Additionally, \n",
      "                                     specifying --inputIOFormats and --outputIOFormats restricts I/O data type and memory layout\n",
      "                                     (default = disabled)\n",
      "  --allowGPUFallback                 When DLA is enabled, allow GPU fallback for unsupported layers (default = disabled)\n",
      "  --consistency                      Perform consistency checking on safety certified engine\n",
      "  --restricted                       Enable safety scope checking with kSAFETY_SCOPE build flag\n",
      "  --saveEngine=<file>                Save the serialized engine\n",
      "  --loadEngine=<file>                Load a serialized engine\n",
      "  --getPlanVersionOnly               Print TensorRT version when loaded plan was created. Works without deserialization of the plan.\n",
      "                                     Use together with --loadEngine. Supported only for engines created with 8.6 and forward.\n",
      "  --tacticSources=tactics            Specify the tactics to be used by adding (+) or removing (-) tactics from the default \n",
      "                                     tactic sources (default = all available tactics).\n",
      "                                     Note: Currently only cuDNN, cuBLAS, cuBLAS-LT, and edge mask convolutions are listed as optional\n",
      "                                           tactics.\n",
      "                                   Tactic Sources: tactics ::= [\",\"tactic]\n",
      "                                                     tactic  ::= (+|-)lib\n",
      "                                                   lib     ::= \"CUBLAS\"|\"CUBLAS_LT\"|\"CUDNN\"|\"EDGE_MASK_CONVOLUTIONS\"\n",
      "                                                               |\"JIT_CONVOLUTIONS\"\n",
      "                                     For example, to disable cudnn and enable cublas: --tacticSources=-CUDNN,+CUBLAS\n",
      "  --noBuilderCache                   Disable timing cache in builder (default is to enable timing cache)\n",
      "  --noCompilationCache               Disable Compilation cache in builder, and the cache is part of timing cache (default is to enable compilation cache)\n",
      "  --errorOnTimingCacheMiss           Emit error when a tactic being timed is not present in the timing cache (default = false)\n",
      "  --timingCacheFile=<file>           Save/load the serialized global timing cache\n",
      "  --preview=features                 Specify preview feature to be used by adding (+) or removing (-) preview features from the default\n",
      "                                   Preview Features: features ::= [\",\"feature]\n",
      "                                                       feature  ::= (+|-)flag\n",
      "                                                     flag     ::= \"profileSharing0806\"\n",
      "  --builderOptimizationLevel         Set the builder optimization level. (default is 3)\n",
      "                                     Higher level allows TensorRT to spend more building time for more optimization options.\n",
      "                                     Valid values include integers from 0 to the maximum optimization level, which is currently 5.\n",
      "  --hardwareCompatibilityLevel=mode  Make the engine file compatible with other GPU architectures. (default = none)\n",
      "                                   Hardware Compatibility Level: mode ::= \"none\" | \"ampere+\"\n",
      "                                         none = no compatibility\n",
      "                                         ampere+ = compatible with Ampere and newer GPUs\n",
      "  --tempdir=<dir>                    Overrides the default temporary directory TensorRT will use when creating temporary files.\n",
      "                                     See IRuntime::setTemporaryDirectory API documentation for more information.\n",
      "  --tempfileControls=controls        Controls what TensorRT is allowed to use when creating temporary executable files.\n",
      "                                     Should be a comma-separated list with entries in the format (in_memory|temporary):(allow|deny).\n",
      "                                     in_memory: Controls whether TensorRT is allowed to create temporary in-memory executable files.\n",
      "                                     temporary: Controls whether TensorRT is allowed to create temporary executable files in the\n",
      "                                                filesystem (in the directory given by --tempdir).\n",
      "                                     For example, to allow in-memory files and disallow temporary files:\n",
      "                                         --tempfileControls=in_memory:allow,temporary:deny\n",
      "                                     If a flag is unspecified, the default behavior is \"allow\".\n",
      "  --maxAuxStreams=N                  Set maximum number of auxiliary streams per inference stream that TRT is allowed to use to run \n",
      "                                     kernels in parallel if the network contains ops that can run in parallel, with the cost of more \n",
      "                                     memory usage. Set this to 0 for optimal memory usage. (default = using heuristics)\n",
      "  --profile                          Build with dynamic shapes using a profile with the min/max/opt shapes provided. Can be specified\n",
      "                                         multiple times to create multiple profiles with contiguous index.\n",
      "                                     (ex: --profile=0 --minShapes=<spec> --optShapes=<spec> --maxShapes=<spec> --profile=1 ...)\n",
      "  --calibProfile                     Select the optimization profile to calibrate by index. (default = 0)\n",
      "  --allowWeightStreaming             Enable a weight streaming engine. Must be specified with --stronglyTyped. TensorRT will disable\n",
      "                                     weight streaming at runtime unless --weightStreamingBudget is specified.\n",
      "  --markDebug                        Specify list of names of tensors to be marked as debug tensors. Separate names with a comma\n",
      "\n",
      "=== Inference Options ===\n",
      "  --shapes=spec               Set input shapes for dynamic shapes inference inputs.\n",
      "                              Note: Input names can be wrapped with escaped single quotes (ex: 'Input:0').\n",
      "                              Example input shapes spec: input0:1x3x256x256, input1:1x3x128x128\n",
      "                              For scalars (0-D shapes), use input0:scalar or simply input0: with nothing after the colon.\n",
      "                              Each input shape is supplied as a key-value pair where key is the input name and\n",
      "                              value is the dimensions (including the batch dimension) to be used for that input.\n",
      "                              Each key-value pair has the key and value separated using a colon (:).\n",
      "                              Multiple input shapes can be provided via comma-separated key-value pairs, and each input \n",
      "                              name can contain at most one wildcard ('*') character.\n",
      "  --loadInputs=spec           Load input values from files (default = generate random inputs). Input names can be wrapped with single quotes (ex: 'Input:0')\n",
      "                            Input values spec ::= Ival[\",\"spec]\n",
      "                                         Ival ::= name\":\"file\n",
      "                              Consult the README for more information on generating files for custom inputs.\n",
      "  --iterations=N              Run at least N inference iterations (default = 10)\n",
      "  --warmUp=N                  Run for N milliseconds to warmup before measuring performance (default = 200)\n",
      "  --duration=N                Run performance measurements for at least N seconds wallclock time (default = 3)\n",
      "                              If -1 is specified, inference will keep running unless stopped manually\n",
      "  --sleepTime=N               Delay inference start with a gap of N milliseconds between launch and compute (default = 0)\n",
      "  --idleTime=N                Sleep N milliseconds between two continuous iterations(default = 0)\n",
      "  --infStreams=N              Instantiate N execution contexts to run inference concurrently (default = 1)\n",
      "  --exposeDMA                 Serialize DMA transfers to and from device (default = disabled).\n",
      "  --noDataTransfers           Disable DMA transfers to and from device (default = enabled).\n",
      "  --useManagedMemory          Use managed memory instead of separate host and device allocations (default = disabled).\n",
      "  --useSpinWait               Actively synchronize on GPU events. This option may decrease synchronization time but increase CPU usage and power (default = disabled)\n",
      "  --threads                   Enable multithreading to drive engines with independent threads or speed up refitting (default = disabled) \n",
      "  --useCudaGraph              Use CUDA graph to capture engine execution and then launch inference (default = disabled).\n",
      "                              This flag may be ignored if the graph capture fails.\n",
      "  --timeDeserialize           Time the amount of time it takes to deserialize the network and exit.\n",
      "  --timeRefit                 Time the amount of time it takes to refit the engine before inference.\n",
      "  --separateProfileRun        Do not attach the profiler in the benchmark run; if profiling is enabled, a second profile run will be executed (default = disabled)\n",
      "  --skipInference             Exit after the engine has been built and skip inference perf measurement (default = disabled)\n",
      "  --persistentCacheRatio      Set the persistentCacheLimit in ratio, 0.5 represent half of max persistent L2 size (default = 0)\n",
      "  --useProfile                Set the optimization profile for the inference context (default = 0 ).\n",
      "  --allocationStrategy=spec   Specify how the internal device memory for inference is allocated.\n",
      "                            Strategy: spec ::= \"static\", \"profile\", \"runtime\"\n",
      "                                  static = Allocate device memory based on max size across all profiles.\n",
      "                                  profile = Allocate device memory based on max size of the current profile.\n",
      "                                  runtime = Allocate device memory based on the actual input shapes.\n",
      "  --saveDebugTensors          Specify list of names of tensors to turn on the debug state\n",
      "                              and filename to save raw outputs to.\n",
      "                              These tensors must be specified as debug tensors during build time.\n",
      "                            Input values spec ::= Ival[\",\"spec]\n",
      "                                         Ival ::= name\":\"file\n",
      "  --weightStreamingBudget     Set the maximum amount of GPU memory TensorRT is allowed to use for weights.\n",
      "                              It can take on the following values:\n",
      "                                -2: (default) Disable weight streaming at runtime.\n",
      "                                -1: TensorRT will automatically decide the budget.\n",
      "                                 0-100%: Percentage of streamable weights that reside on the GPU.\n",
      "                                         0% saves the most memory but will have the worst performance.\n",
      "                                         Requires the % character.\n",
      "                                >=0B: The exact amount of streamable weights that reside on the GPU. Supports the \n",
      "                                     following base-2 suffixes: B (Bytes), G (Gibibytes), K (Kibibytes), M (Mebibytes).\n",
      "\n",
      "=== Reporting Options ===\n",
      "  --verbose                   Use verbose logging (default = false)\n",
      "  --avgRuns=N                 Report performance measurements averaged over N consecutive iterations (default = 10)\n",
      "  --percentile=P1,P2,P3,...   Report performance for the P1,P2,P3,... percentages (0<=P_i<=100, 0 representing max perf, and 100 representing min perf; (default = 90,95,99%)\n",
      "  --dumpRefit                 Print the refittable layers and weights from a refittable engine\n",
      "  --dumpOutput                Print the output tensor(s) of the last inference iteration (default = disabled)\n",
      "  --dumpRawBindingsToFile     Print the input/output tensor(s) of the last inference iteration to file(default = disabled)\n",
      "  --dumpProfile               Print profile information per layer (default = disabled)\n",
      "  --dumpLayerInfo             Print layer information of the engine to console (default = disabled)\n",
      "  --dumpOptimizationProfile   Print the optimization profile(s) information (default = disabled)\n",
      "  --exportTimes=<file>        Write the timing results in a json file (default = disabled)\n",
      "  --exportOutput=<file>       Write the output tensors to a json file (default = disabled)\n",
      "  --exportProfile=<file>      Write the profile information per layer in a json file (default = disabled)\n",
      "  --exportLayerInfo=<file>    Write the layer information of the engine in a json file (default = disabled)\n",
      "\n",
      "=== System Options ===\n",
      "  --device=N                  Select cuda device N (default = 0)\n",
      "  --useDLACore=N              Select DLA core N for layers that support DLA (default = none)\n",
      "  --staticPlugins             Plugin library (.so) to load statically (can be specified multiple times)\n",
      "  --dynamicPlugins            Plugin library (.so) to load dynamically and may be serialized with the engine if they are included in --setPluginsToSerialize (can be specified multiple times)\n",
      "  --setPluginsToSerialize     Plugin library (.so) to be serialized with the engine (can be specified multiple times)\n",
      "  --ignoreParsedPluginLibs    By default, when building a version-compatible engine, plugin libraries specified by the ONNX parser \n",
      "                              are implicitly serialized with the engine (unless --excludeLeanRuntime is specified) and loaded dynamically. \n",
      "                              Enable this flag to ignore these plugin libraries instead.\n",
      "\n",
      "=== Help ===\n",
      "  --help, -h                  Print this message\n",
      "&&&& FAILED TensorRT.trtexec [TensorRT v100100] # trtexec --onnx C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.onnx --saveEngine C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.engine --fp16 --int8 --useCudaGraph --minShapes=images:1x3x672x672 --optShapes=images:1x3x672x672 --maxShapes=images:1x3x672x672 --memPoolSize=workspace:5239MiB --timingCacheFile C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.engine.timing.cache\n",
      "Failed to generate engine file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/02/2025-22:52:32] [E] Unknown option: C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.onnx \n",
      "[02/02/2025-22:52:32] [E] Unknown option: C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.engine \n",
      "[02/02/2025-22:52:32] [E] Unknown option: C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.engine.timing.cache \n"
     ]
    }
   ],
   "source": [
    "# First step\n",
    "!python generate_trt_engine.py \"C:/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main/runs/qat/qat_yolov9/weights/qat_best_best.onnx\" 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval_trt: \u001b[0mdata=data/coco.yaml, engine_file=C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\qat\\qat_yolov9\\weights\\qat_best_best.engine, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=0, workers=8, single_cls=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs\\val_trt, name=exp, exist_ok=False\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\val_trt.py\", line 438, in <module>\n",
      "    main(opt)\n",
      "  File \"c:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\val_trt.py\", line 411, in main\n",
      "    run(**vars(opt))\n",
      "  File \"c:\\Users\\PZJ\\anaconda3\\envs\\torch-3.10\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\val_trt.py\", line 175, in run\n",
      "    engine = runtime.deserialize_cuda_engine(open(engine_file, 'rb') .read())\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\PZJ\\\\Desktop\\\\yolov9\\\\yolov9-main_measure\\\\yolov9-main\\\\runs\\\\qat\\\\qat_yolov9\\\\weights\\\\qat_best_best.engine'\n"
     ]
    }
   ],
   "source": [
    "# Second step\n",
    "# --name val_trt_yolov9\n",
    "!python val_trt.py --engine-file \"C:\\Users\\PZJ\\Desktop\\yolov9\\yolov9-main_measure\\yolov9-main\\runs\\qat\\qat_yolov9\\weights\\qat_best_best.engine\" --data data/coco.yaml  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *<font face =微軟黑體 color = aqua>Deployment with Tensorrt</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = #FF79BC>支持多種 Batch Size，例如 [1, 2, 4, 8]，可以將 maxShapes 設為 12，optShapes 設為 8 或 12，這樣引擎會在一定範圍內自適應不同的 Batch Size。</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "\n",
    " /usr/src/tensorrt/bin/trtexec \\\n",
    "  --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    "  --int8 --fp16  \\\n",
    "  --useCudaGraph \\\n",
    "  --minShapes=images:1x3x640x640 \\\n",
    "  --optShapes=images:4x3x640x640 \\\n",
    "  --maxShapes=images:8x3x640x640 \\\n",
    "  --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best.engine\n",
    "  \n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Result</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(torch-3.10) user_pzj@DESKTOP-20USVPU:/mnt/c/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main$  /usr/src/tensorrt/bin/trtexec \\\n",
    ">   --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    ">   --int8 --fp16  \\\n",
    ">   --useCudaGraph \\\n",
    ">   --minShapes=images:1x3x640x640 \\\n",
    ">   --optShapes=images:4x3x640x640 \\\n",
    ">   --maxShapes=images:8x3x640x640 \\\n",
    ">   --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best.engine\n",
    "&&&& RUNNING TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:4x3x640x640 --maxShapes=images:8x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best.engine\n",
    "[02/02/2025-16:02:10] [I] === Model Options ===\n",
    "[02/02/2025-16:02:10] [I] Format: ONNX\n",
    "[02/02/2025-16:02:10] [I] Model: runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-16:02:10] [I] Output:\n",
    "[02/02/2025-16:02:10] [I] === Build Options ===\n",
    "[02/02/2025-16:02:10] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
    "[02/02/2025-16:02:10] [I] avgTiming: 8\n",
    "[02/02/2025-16:02:10] [I] Precision: FP32+FP16+INT8\n",
    "[02/02/2025-16:02:10] [I] LayerPrecisions:\n",
    "[02/02/2025-16:02:10] [I] Layer Device Types:\n",
    "[02/02/2025-16:02:10] [I] Calibration: Dynamic\n",
    "[02/02/2025-16:02:10] [I] Refit: Disabled\n",
    "[02/02/2025-16:02:10] [I] Strip weights: Disabled\n",
    "[02/02/2025-16:02:10] [I] Version Compatible: Disabled\n",
    "[02/02/2025-16:02:10] [I] ONNX Plugin InstanceNorm: Disabled\n",
    "[02/02/2025-16:02:10] [I] TensorRT runtime: full\n",
    "[02/02/2025-16:02:10] [I] Lean DLL Path:\n",
    "[02/02/2025-16:02:10] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
    "[02/02/2025-16:02:10] [I] Exclude Lean Runtime: Disabled\n",
    "[02/02/2025-16:02:10] [I] Sparsity: Disabled\n",
    "[02/02/2025-16:02:10] [I] Safe mode: Disabled\n",
    "[02/02/2025-16:02:10] [I] Build DLA standalone loadable: Disabled\n",
    "[02/02/2025-16:02:10] [I] Allow GPU fallback for DLA: Disabled\n",
    "[02/02/2025-16:02:10] [I] DirectIO mode: Disabled\n",
    "[02/02/2025-16:02:10] [I] Restricted mode: Disabled\n",
    "[02/02/2025-16:02:10] [I] Skip inference: Disabled\n",
    "[02/02/2025-16:02:10] [I] Save engine: runs/qat/qat_yolov9/weights/qat_best_best.engine\n",
    "[02/02/2025-16:02:10] [I] Load engine:\n",
    "[02/02/2025-16:02:10] [I] Profiling verbosity: 0\n",
    "[02/02/2025-16:02:10] [I] Tactic sources: Using default tactic sources\n",
    "[02/02/2025-16:02:10] [I] timingCacheMode: local\n",
    "[02/02/2025-16:02:10] [I] timingCacheFile:\n",
    "[02/02/2025-16:02:10] [I] Enable Compilation Cache: Enabled\n",
    "[02/02/2025-16:02:10] [I] errorOnTimingCacheMiss: Disabled\n",
    "[02/02/2025-16:02:10] [I] Preview Features: Use default preview flags.\n",
    "[02/02/2025-16:02:10] [I] MaxAuxStreams: -1\n",
    "[02/02/2025-16:02:10] [I] BuilderOptimizationLevel: -1\n",
    "[02/02/2025-16:02:10] [I] Calibration Profile Index: 0\n",
    "[02/02/2025-16:02:10] [I] Weight Streaming: Disabled\n",
    "[02/02/2025-16:02:10] [I] Debug Tensors:\n",
    "[02/02/2025-16:02:10] [I] Input(s)s format: fp32:CHW\n",
    "[02/02/2025-16:02:10] [I] Output(s)s format: fp32:CHW\n",
    "[02/02/2025-16:02:10] [I] Input build shape (profile 0): images=1x3x640x640+4x3x640x640+8x3x640x640\n",
    "[02/02/2025-16:02:10] [I] Input calibration shapes: model\n",
    "[02/02/2025-16:02:10] [I] === System Options ===\n",
    "[02/02/2025-16:02:10] [I] Device: 0\n",
    "[02/02/2025-16:02:10] [I] DLACore:\n",
    "[02/02/2025-16:02:10] [I] Plugins:\n",
    "[02/02/2025-16:02:10] [I] setPluginsToSerialize:\n",
    "[02/02/2025-16:02:10] [I] dynamicPlugins:\n",
    "[02/02/2025-16:02:10] [I] ignoreParsedPluginLibs: 0\n",
    "[02/02/2025-16:02:10] [I]\n",
    "[02/02/2025-16:02:10] [I] === Inference Options ===\n",
    "[02/02/2025-16:02:10] [I] Batch: Explicit\n",
    "[02/02/2025-16:02:10] [I] Input inference shape : images=4x3x640x640\n",
    "[02/02/2025-16:02:10] [I] Iterations: 10\n",
    "[02/02/2025-16:02:10] [I] Duration: 3s (+ 200ms warm up)\n",
    "[02/02/2025-16:02:10] [I] Sleep time: 0ms\n",
    "[02/02/2025-16:02:10] [I] Idle time: 0ms\n",
    "[02/02/2025-16:02:10] [I] Inference Streams: 1\n",
    "[02/02/2025-16:02:10] [I] ExposeDMA: Disabled\n",
    "[02/02/2025-16:02:10] [I] Data transfers: Enabled\n",
    "[02/02/2025-16:02:10] [I] Spin-wait: Disabled\n",
    "[02/02/2025-16:02:10] [I] Multithreading: Disabled\n",
    "[02/02/2025-16:02:10] [I] CUDA Graph: Enabled\n",
    "[02/02/2025-16:02:10] [I] Separate profiling: Disabled\n",
    "[02/02/2025-16:02:10] [I] Time Deserialize: Disabled\n",
    "[02/02/2025-16:02:10] [I] Time Refit: Disabled\n",
    "[02/02/2025-16:02:10] [I] NVTX verbosity: 0\n",
    "[02/02/2025-16:02:10] [I] Persistent Cache Ratio: 0\n",
    "[02/02/2025-16:02:10] [I] Optimization Profile Index: 0\n",
    "[02/02/2025-16:02:10] [I] Weight Streaming Budget: 100.000000%\n",
    "[02/02/2025-16:02:10] [I] Inputs:\n",
    "[02/02/2025-16:02:10] [I] Debug Tensor Save Destinations:\n",
    "[02/02/2025-16:02:10] [I] === Reporting Options ===\n",
    "[02/02/2025-16:02:10] [I] Verbose: Disabled\n",
    "[02/02/2025-16:02:10] [I] Averages: 10 inferences\n",
    "[02/02/2025-16:02:10] [I] Percentiles: 90,95,99\n",
    "[02/02/2025-16:02:10] [I] Dump refittable layers:Disabled\n",
    "[02/02/2025-16:02:10] [I] Dump output: Disabled\n",
    "[02/02/2025-16:02:10] [I] Profile: Disabled\n",
    "[02/02/2025-16:02:10] [I] Export timing to JSON file:\n",
    "[02/02/2025-16:02:10] [I] Export output to JSON file:\n",
    "[02/02/2025-16:02:10] [I] Export profile to JSON file:\n",
    "[02/02/2025-16:02:10] [I]\n",
    "[02/02/2025-16:02:10] [I] === Device Information ===\n",
    "[02/02/2025-16:02:10] [I] Available Devices:\n",
    "[02/02/2025-16:02:10] [I]   Device 0: \"NVIDIA GeForce RTX 4050 Laptop GPU\" UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-16:02:10] [I] Selected Device: NVIDIA GeForce RTX 4050 Laptop GPU\n",
    "[02/02/2025-16:02:10] [I] Selected Device ID: 0\n",
    "[02/02/2025-16:02:10] [I] Selected Device UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-16:02:10] [I] Compute Capability: 8.9\n",
    "[02/02/2025-16:02:10] [I] SMs: 20\n",
    "[02/02/2025-16:02:10] [I] Device Global Memory: 6140 MiB\n",
    "[02/02/2025-16:02:10] [I] Shared Memory per SM: 100 KiB\n",
    "[02/02/2025-16:02:10] [I] Memory Bus Width: 96 bits (ECC disabled)\n",
    "[02/02/2025-16:02:10] [I] Application Compute Clock Rate: 2.355 GHz\n",
    "[02/02/2025-16:02:10] [I] Application Memory Clock Rate: 7.825 GHz\n",
    "[02/02/2025-16:02:10] [I]\n",
    "[02/02/2025-16:02:10] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
    "[02/02/2025-16:02:10] [I]\n",
    "[02/02/2025-16:02:10] [I] TensorRT version: 10.1.0\n",
    "[02/02/2025-16:02:10] [I] Loading standard plugins\n",
    "[02/02/2025-16:02:10] [I] [TRT] [MemUsageChange] Init CUDA: CPU +14, GPU +0, now: CPU 24, GPU 1065 (MiB)\n",
    "[02/02/2025-16:02:15] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1659, GPU +292, now: CPU 1830, GPU 1357 (MiB)\n",
    "[02/02/2025-16:02:15] [I] Start parsing network model.\n",
    "[02/02/2025-16:02:16] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-16:02:16] [I] [TRT] Input filename:   runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-16:02:16] [I] [TRT] ONNX IR version:  0.0.10\n",
    "[02/02/2025-16:02:16] [I] [TRT] Opset version:    13\n",
    "[02/02/2025-16:02:16] [I] [TRT] Producer name:    pytorch\n",
    "[02/02/2025-16:02:16] [I] [TRT] Producer version: 2.5.1\n",
    "[02/02/2025-16:02:16] [I] [TRT] Domain:\n",
    "[02/02/2025-16:02:16] [I] [TRT] Model version:    0\n",
    "[02/02/2025-16:02:16] [I] [TRT] Doc string:\n",
    "[02/02/2025-16:02:16] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-16:02:16] [I] Finished parsing network model. Parse time: 1.34104\n",
    "[02/02/2025-16:02:16] [I] Set shape of input tensor images for optimization profile 0 to: MIN=1x3x640x640 OPT=4x3x640x640 MAX=8x3x640x640\n",
    "[02/02/2025-16:02:16] [W] [TRT] Calibrator won't be used in explicit quantization mode. Please insert Quantize/Dequantize layers to indicate which tensors to quantize/dequantize.\n",
    "[02/02/2025-16:02:16] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
    "[02/02/2025-16:09:41] [I] [TRT] Detected 1 inputs and 6 output network tensors.\n",
    "[02/02/2025-16:09:55] [I] [TRT] Total Host Persistent Memory: 1306464\n",
    "[02/02/2025-16:09:55] [I] [TRT] Total Device Persistent Memory: 54272\n",
    "[02/02/2025-16:09:55] [I] [TRT] Total Scratch Memory: 8601600\n",
    "[02/02/2025-16:09:55] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 387 steps to complete.\n",
    "[02/02/2025-16:09:55] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 47.5268ms to assign 14 blocks to 387 nodes requiring 410521088 bytes.\n",
    "[02/02/2025-16:09:55] [I] [TRT] Total Activation Memory: 410520576\n",
    "[02/02/2025-16:09:55] [I] [TRT] Total Weights Memory: 52559872\n",
    "[02/02/2025-16:09:55] [I] [TRT] Engine generation completed in 458.703 seconds.\n",
    "[02/02/2025-16:09:55] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 301 MiB\n",
    "[02/02/2025-16:09:55] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3026 MiB\n",
    "[02/02/2025-16:09:55] [I] Engine built in 459.475 sec.\n",
    "[02/02/2025-16:09:55] [I] Created engine with size: 57.6647 MiB\n",
    "[02/02/2025-16:09:57] [I] [TRT] Loaded engine size: 57 MiB\n",
    "[02/02/2025-16:09:57] [I] Engine deserialized in 0.502452 sec.\n",
    "[02/02/2025-16:09:57] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +391, now: CPU 2, GPU 441 (MiB)\n",
    "[02/02/2025-16:09:57] [I] Setting persistentCacheLimit to 0 bytes.\n",
    "[02/02/2025-16:09:57] [I] Set shape of input tensor images to: 4x3x640x640\n",
    "[02/02/2025-16:09:57] [I] Created execution context with device memory size: 391.503 MiB\n",
    "[02/02/2025-16:09:57] [I] Using random values for input images\n",
    "[02/02/2025-16:09:57] [I] Input binding for images with dimensions 4x3x640x640 is created.\n",
    "[02/02/2025-16:09:57] [I] Output binding for output0 with dimensions 4x12x8400 is created.\n",
    "[02/02/2025-16:09:57] [I] Output binding for 4518 with dimensions 4x12x8400 is created.\n",
    "[02/02/2025-16:09:57] [I] Starting inference\n",
    "[02/02/2025-16:09:57] [I] Capturing CUDA graph for the current execution context\n",
    "[02/02/2025-16:09:57] [I] Successfully captured CUDA graph for the current execution context\n",
    "[02/02/2025-16:10:00] [I] Warmup completed 7 queries over 200 ms\n",
    "[02/02/2025-16:10:00] [I] Timing trace has 128 queries over 3.05181 s\n",
    "[02/02/2025-16:10:00] [I]\n",
    "[02/02/2025-16:10:00] [I] === Trace details ===\n",
    "[02/02/2025-16:10:00] [I] Trace averages of 10 runs:\n",
    "[02/02/2025-16:10:00] [I] Average on 10 runs - GPU latency: 21.8794 ms - Host latency: 23.6617 ms (enqueue 0.0850021 ms)\n",
    "[02/02/2025-16:10:00] [I] Average on 10 runs - GPU latency: 21.8981 ms - Host latency: 23.6801 ms (enqueue 0.0654785 ms)\n",
    "[02/02/2025-16:10:00] [I] Average on 10 runs - GPU latency: 21.9012 ms - Host latency: 23.6809 ms (enqueue 0.0824219 ms)\n",
    "[02/02/2025-16:10:00] [I] Average on 10 runs - GPU latency: 21.9082 ms - Host latency: 23.6824 ms (enqueue 0.0663757 ms)\n",
    "[02/02/2025-16:10:00] [I] Average on 10 runs - GPU latency: 21.8981 ms - Host latency: 23.6779 ms (enqueue 0.0619995 ms)\n",
    "[02/02/2025-16:10:00] [I] Average on 10 runs - GPU latency: 21.9027 ms - Host latency: 23.689 ms (enqueue 0.0970093 ms)\n",
    "[02/02/2025-16:10:00] [I] Average on 10 runs - GPU latency: 21.8951 ms - Host latency: 23.6809 ms (enqueue 0.10249 ms)\n",
    "[02/02/2025-16:10:00] [I] Average on 10 runs - GPU latency: 21.9009 ms - Host latency: 23.6921 ms (enqueue 0.084021 ms)\n",
    "[02/02/2025-16:10:00] [I] Average on 10 runs - GPU latency: 21.9061 ms - Host latency: 23.7073 ms (enqueue 0.0842285 ms)\n",
    "[02/02/2025-16:10:00] [I] Average on 10 runs - GPU latency: 21.9122 ms - Host latency: 23.6972 ms (enqueue 0.102197 ms)\n",
    "[02/02/2025-16:10:00] [I] Average on 10 runs - GPU latency: 21.908 ms - Host latency: 23.6907 ms (enqueue 0.112134 ms)\n",
    "[02/02/2025-16:10:00] [I] Average on 10 runs - GPU latency: 21.9165 ms - Host latency: 23.6986 ms (enqueue 0.135547 ms)\n",
    "[02/02/2025-16:10:00] [I]\n",
    "[02/02/2025-16:10:00] [I] === Performance summary ===\n",
    "[02/02/2025-16:10:00] [I] Throughput: 41.9423 qps\n",
    "[02/02/2025-16:10:00] [I] Latency: min = 23.6311 ms, max = 23.7593 ms, mean = 23.6873 ms, median = 23.6843 ms, percentile(90%) = 23.7173 ms, percentile(95%) = 23.731 ms, percentile(99%) = 23.7374 ms\n",
    "[02/02/2025-16:10:00] [I] Enqueue Time: min = 0.0405273 ms, max = 0.196655 ms, mean = 0.0907611 ms, median = 0.0776367 ms, percentile(90%) = 0.156738 ms, percentile(95%) = 0.165787 ms, percentile(99%) = 0.188477 ms\n",
    "[02/02/2025-16:10:00] [I] H2D Latency: min = 1.5116 ms, max = 1.5957 ms, mean = 1.53215 ms, median = 1.52551 ms, percentile(90%) = 1.55933 ms, percentile(95%) = 1.56274 ms, percentile(99%) = 1.57471 ms\n",
    "[02/02/2025-16:10:00] [I] GPU Compute Time: min = 21.8614 ms, max = 21.9697 ms, mean = 21.9028 ms, median = 21.9023 ms, percentile(90%) = 21.9177 ms, percentile(95%) = 21.9219 ms, percentile(99%) = 21.9392 ms\n",
    "[02/02/2025-16:10:00] [I] D2H Latency: min = 0.25 ms, max = 0.297974 ms, mean = 0.252319 ms, median = 0.251038 ms, percentile(90%) = 0.254883 ms, percentile(95%) = 0.256104 ms, percentile(99%) = 0.272339 ms\n",
    "[02/02/2025-16:10:00] [I] Total Host Walltime: 3.05181 s\n",
    "[02/02/2025-16:10:00] [I] Total GPU Compute Time: 2.80356 s\n",
    "[02/02/2025-16:10:00] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
    "[02/02/2025-16:10:00] [I]\n",
    "&&&& PASSED TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:4x3x640x640 --maxShapes=images:8x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>===================================================================</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 測試不使用優化標誌\n",
    " \"\"\"\n",
    "\n",
    " /usr/src/tensorrt/bin/trtexec \\\n",
    "  --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    "  --int8 --fp16  \\\n",
    "  --minShapes=images:1x3x640x640 \\\n",
    "  --optShapes=images:4x3x640x640 \\\n",
    "  --maxShapes=images:8x3x640x640 \\\n",
    "  --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_without_useCudaGraph.engine\n",
    "  \n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Result</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(torch-3.10) user_pzj@DESKTOP-20USVPU:/mnt/c/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main$  /usr/src/tensorrt/bin/trtexec \\\n",
    ">   --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    ">   --int8 --fp16  \\\n",
    ">   --minShapes=images:1x3x640x640 \\\n",
    ">   --optShapes=images:4x3x640x640 \\\n",
    ">   --maxShapes=images:8x3x640x640 \\\n",
    ">   --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best.engine\n",
    "&&&& RUNNING TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --minShapes=images:1x3x640x640 --optShapes=images:4x3x640x640 --maxShapes=images:8x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best.engine\n",
    "[02/02/2025-19:43:03] [I] === Model Options ===\n",
    "[02/02/2025-19:43:03] [I] Format: ONNX\n",
    "[02/02/2025-19:43:03] [I] Model: runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-19:43:03] [I] Output:\n",
    "[02/02/2025-19:43:03] [I] === Build Options ===\n",
    "[02/02/2025-19:43:03] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
    "[02/02/2025-19:43:03] [I] avgTiming: 8\n",
    "[02/02/2025-19:43:03] [I] Precision: FP32+FP16+INT8\n",
    "[02/02/2025-19:43:03] [I] LayerPrecisions:\n",
    "[02/02/2025-19:43:03] [I] Layer Device Types:\n",
    "[02/02/2025-19:43:03] [I] Calibration: Dynamic\n",
    "[02/02/2025-19:43:03] [I] Refit: Disabled\n",
    "[02/02/2025-19:43:03] [I] Strip weights: Disabled\n",
    "[02/02/2025-19:43:03] [I] Version Compatible: Disabled\n",
    "[02/02/2025-19:43:03] [I] ONNX Plugin InstanceNorm: Disabled\n",
    "[02/02/2025-19:43:03] [I] TensorRT runtime: full\n",
    "[02/02/2025-19:43:03] [I] Lean DLL Path:\n",
    "[02/02/2025-19:43:03] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
    "[02/02/2025-19:43:03] [I] Exclude Lean Runtime: Disabled\n",
    "[02/02/2025-19:43:03] [I] Sparsity: Disabled\n",
    "[02/02/2025-19:43:03] [I] Safe mode: Disabled\n",
    "[02/02/2025-19:43:03] [I] Build DLA standalone loadable: Disabled\n",
    "[02/02/2025-19:43:03] [I] Allow GPU fallback for DLA: Disabled\n",
    "[02/02/2025-19:43:03] [I] DirectIO mode: Disabled\n",
    "[02/02/2025-19:43:03] [I] Restricted mode: Disabled\n",
    "[02/02/2025-19:43:03] [I] Skip inference: Disabled\n",
    "[02/02/2025-19:43:03] [I] Save engine: runs/qat/qat_yolov9/weights/qat_best_best.engine\n",
    "[02/02/2025-19:43:03] [I] Load engine:\n",
    "[02/02/2025-19:43:03] [I] Profiling verbosity: 0\n",
    "[02/02/2025-19:43:03] [I] Tactic sources: Using default tactic sources\n",
    "[02/02/2025-19:43:03] [I] timingCacheMode: local\n",
    "[02/02/2025-19:43:03] [I] timingCacheFile:\n",
    "[02/02/2025-19:43:03] [I] Enable Compilation Cache: Enabled\n",
    "[02/02/2025-19:43:03] [I] errorOnTimingCacheMiss: Disabled\n",
    "[02/02/2025-19:43:03] [I] Preview Features: Use default preview flags.\n",
    "[02/02/2025-19:43:03] [I] MaxAuxStreams: -1\n",
    "[02/02/2025-19:43:03] [I] BuilderOptimizationLevel: -1\n",
    "[02/02/2025-19:43:03] [I] Calibration Profile Index: 0\n",
    "[02/02/2025-19:43:03] [I] Weight Streaming: Disabled\n",
    "[02/02/2025-19:43:03] [I] Debug Tensors:\n",
    "[02/02/2025-19:43:03] [I] Input(s)s format: fp32:CHW\n",
    "[02/02/2025-19:43:03] [I] Output(s)s format: fp32:CHW\n",
    "[02/02/2025-19:43:03] [I] Input build shape (profile 0): images=1x3x640x640+4x3x640x640+8x3x640x640\n",
    "[02/02/2025-19:43:03] [I] Input calibration shapes: model\n",
    "[02/02/2025-19:43:03] [I] === System Options ===\n",
    "[02/02/2025-19:43:03] [I] Device: 0\n",
    "[02/02/2025-19:43:03] [I] DLACore:\n",
    "[02/02/2025-19:43:03] [I] Plugins:\n",
    "[02/02/2025-19:43:03] [I] setPluginsToSerialize:\n",
    "[02/02/2025-19:43:03] [I] dynamicPlugins:\n",
    "[02/02/2025-19:43:03] [I] ignoreParsedPluginLibs: 0\n",
    "[02/02/2025-19:43:03] [I]\n",
    "[02/02/2025-19:43:03] [I] === Inference Options ===\n",
    "[02/02/2025-19:43:03] [I] Batch: Explicit\n",
    "[02/02/2025-19:43:03] [I] Input inference shape : images=4x3x640x640\n",
    "[02/02/2025-19:43:03] [I] Iterations: 10\n",
    "[02/02/2025-19:43:03] [I] Duration: 3s (+ 200ms warm up)\n",
    "[02/02/2025-19:43:03] [I] Sleep time: 0ms\n",
    "[02/02/2025-19:43:03] [I] Idle time: 0ms\n",
    "[02/02/2025-19:43:03] [I] Inference Streams: 1\n",
    "[02/02/2025-19:43:03] [I] ExposeDMA: Disabled\n",
    "[02/02/2025-19:43:03] [I] Data transfers: Enabled\n",
    "[02/02/2025-19:43:03] [I] Spin-wait: Disabled\n",
    "[02/02/2025-19:43:03] [I] Multithreading: Disabled\n",
    "[02/02/2025-19:43:03] [I] CUDA Graph: Disabled\n",
    "[02/02/2025-19:43:03] [I] Separate profiling: Disabled\n",
    "[02/02/2025-19:43:03] [I] Time Deserialize: Disabled\n",
    "[02/02/2025-19:43:03] [I] Time Refit: Disabled\n",
    "[02/02/2025-19:43:03] [I] NVTX verbosity: 0\n",
    "[02/02/2025-19:43:03] [I] Persistent Cache Ratio: 0\n",
    "[02/02/2025-19:43:03] [I] Optimization Profile Index: 0\n",
    "[02/02/2025-19:43:03] [I] Weight Streaming Budget: 100.000000%\n",
    "[02/02/2025-19:43:03] [I] Inputs:\n",
    "[02/02/2025-19:43:03] [I] Debug Tensor Save Destinations:\n",
    "[02/02/2025-19:43:03] [I] === Reporting Options ===\n",
    "[02/02/2025-19:43:03] [I] Verbose: Disabled\n",
    "[02/02/2025-19:43:03] [I] Averages: 10 inferences\n",
    "[02/02/2025-19:43:03] [I] Percentiles: 90,95,99\n",
    "[02/02/2025-19:43:03] [I] Dump refittable layers:Disabled\n",
    "[02/02/2025-19:43:03] [I] Dump output: Disabled\n",
    "[02/02/2025-19:43:03] [I] Profile: Disabled\n",
    "[02/02/2025-19:43:03] [I] Export timing to JSON file:\n",
    "[02/02/2025-19:43:03] [I] Export output to JSON file:\n",
    "[02/02/2025-19:43:03] [I] Export profile to JSON file:\n",
    "[02/02/2025-19:43:03] [I]\n",
    "[02/02/2025-19:43:03] [I] === Device Information ===\n",
    "[02/02/2025-19:43:03] [I] Available Devices:\n",
    "[02/02/2025-19:43:03] [I]   Device 0: \"NVIDIA GeForce RTX 4050 Laptop GPU\" UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-19:43:03] [I] Selected Device: NVIDIA GeForce RTX 4050 Laptop GPU\n",
    "[02/02/2025-19:43:03] [I] Selected Device ID: 0\n",
    "[02/02/2025-19:43:03] [I] Selected Device UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-19:43:03] [I] Compute Capability: 8.9\n",
    "[02/02/2025-19:43:03] [I] SMs: 20\n",
    "[02/02/2025-19:43:03] [I] Device Global Memory: 6140 MiB\n",
    "[02/02/2025-19:43:03] [I] Shared Memory per SM: 100 KiB\n",
    "[02/02/2025-19:43:03] [I] Memory Bus Width: 96 bits (ECC disabled)\n",
    "[02/02/2025-19:43:03] [I] Application Compute Clock Rate: 2.355 GHz\n",
    "[02/02/2025-19:43:03] [I] Application Memory Clock Rate: 7.825 GHz\n",
    "[02/02/2025-19:43:03] [I]\n",
    "[02/02/2025-19:43:03] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
    "[02/02/2025-19:43:03] [I]\n",
    "[02/02/2025-19:43:03] [I] TensorRT version: 10.1.0\n",
    "[02/02/2025-19:43:03] [I] Loading standard plugins\n",
    "[02/02/2025-19:43:04] [I] [TRT] [MemUsageChange] Init CUDA: CPU +14, GPU +0, now: CPU 24, GPU 1065 (MiB)\n",
    "[02/02/2025-19:43:06] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1659, GPU +292, now: CPU 1830, GPU 1357 (MiB)\n",
    "[02/02/2025-19:43:06] [I] Start parsing network model.\n",
    "[02/02/2025-19:43:07] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-19:43:07] [I] [TRT] Input filename:   runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-19:43:07] [I] [TRT] ONNX IR version:  0.0.10\n",
    "[02/02/2025-19:43:07] [I] [TRT] Opset version:    13\n",
    "[02/02/2025-19:43:07] [I] [TRT] Producer name:    pytorch\n",
    "[02/02/2025-19:43:07] [I] [TRT] Producer version: 2.5.1\n",
    "[02/02/2025-19:43:07] [I] [TRT] Domain:\n",
    "[02/02/2025-19:43:07] [I] [TRT] Model version:    0\n",
    "[02/02/2025-19:43:07] [I] [TRT] Doc string:\n",
    "[02/02/2025-19:43:07] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-19:43:07] [I] Finished parsing network model. Parse time: 0.821801\n",
    "[02/02/2025-19:43:07] [I] Set shape of input tensor images for optimization profile 0 to: MIN=1x3x640x640 OPT=4x3x640x640 MAX=8x3x640x640\n",
    "[02/02/2025-19:43:07] [W] [TRT] Calibrator won't be used in explicit quantization mode. Please insert Quantize/Dequantize layers to indicate which tensors to quantize/dequantize.\n",
    "[02/02/2025-19:43:07] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
    "[02/02/2025-19:50:16] [I] [TRT] Detected 1 inputs and 6 output network tensors.\n",
    "[02/02/2025-19:50:28] [I] [TRT] Total Host Persistent Memory: 1307536\n",
    "[02/02/2025-19:50:28] [I] [TRT] Total Device Persistent Memory: 51200\n",
    "[02/02/2025-19:50:28] [I] [TRT] Total Scratch Memory: 8601600\n",
    "[02/02/2025-19:50:28] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 389 steps to complete.\n",
    "[02/02/2025-19:50:28] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 43.3732ms to assign 14 blocks to 389 nodes requiring 410504192 bytes.\n",
    "[02/02/2025-19:50:28] [I] [TRT] Total Activation Memory: 410503680\n",
    "[02/02/2025-19:50:28] [I] [TRT] Total Weights Memory: 52566016\n",
    "[02/02/2025-19:50:28] [I] [TRT] Engine generation completed in 441.388 seconds.\n",
    "[02/02/2025-19:50:28] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 301 MiB\n",
    "[02/02/2025-19:50:29] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3028 MiB\n",
    "[02/02/2025-19:50:29] [I] Engine built in 442.121 sec.\n",
    "[02/02/2025-19:50:29] [I] Created engine with size: 58.2077 MiB\n",
    "[02/02/2025-19:50:30] [I] [TRT] Loaded engine size: 58 MiB\n",
    "[02/02/2025-19:50:30] [I] Engine deserialized in 0.322675 sec.\n",
    "[02/02/2025-19:50:30] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +391, now: CPU 2, GPU 441 (MiB)\n",
    "[02/02/2025-19:50:30] [I] Setting persistentCacheLimit to 0 bytes.\n",
    "[02/02/2025-19:50:30] [I] Set shape of input tensor images to: 4x3x640x640\n",
    "[02/02/2025-19:50:30] [I] Created execution context with device memory size: 391.487 MiB\n",
    "[02/02/2025-19:50:30] [I] Using random values for input images\n",
    "[02/02/2025-19:50:30] [I] Input binding for images with dimensions 4x3x640x640 is created.\n",
    "[02/02/2025-19:50:30] [I] Output binding for output0 with dimensions 4x12x8400 is created.\n",
    "[02/02/2025-19:50:30] [I] Output binding for 4518 with dimensions 4x12x8400 is created.\n",
    "[02/02/2025-19:50:30] [I] Starting inference\n",
    "[02/02/2025-19:50:33] [I] Warmup completed 1 queries over 200 ms\n",
    "[02/02/2025-19:50:33] [I] Timing trace has 121 queries over 3.006 s\n",
    "[02/02/2025-19:50:33] [I]\n",
    "[02/02/2025-19:50:33] [I] === Trace details ===\n",
    "[02/02/2025-19:50:33] [I] Trace averages of 10 runs:\n",
    "[02/02/2025-19:50:33] [I] Average on 10 runs - GPU latency: 23.324 ms - Host latency: 25.1125 ms (enqueue 2.84137 ms)\n",
    "[02/02/2025-19:50:33] [I] Average on 10 runs - GPU latency: 22.9223 ms - Host latency: 24.7085 ms (enqueue 2.73676 ms)\n",
    "[02/02/2025-19:50:33] [I] Average on 10 runs - GPU latency: 22.9067 ms - Host latency: 24.7025 ms (enqueue 2.66243 ms)\n",
    "[02/02/2025-19:50:33] [I] Average on 10 runs - GPU latency: 22.7854 ms - Host latency: 24.5789 ms (enqueue 2.67289 ms)\n",
    "[02/02/2025-19:50:33] [I] Average on 10 runs - GPU latency: 22.8735 ms - Host latency: 24.6722 ms (enqueue 2.71139 ms)\n",
    "[02/02/2025-19:50:33] [I] Average on 10 runs - GPU latency: 22.7902 ms - Host latency: 24.5815 ms (enqueue 3.22256 ms)\n",
    "[02/02/2025-19:50:33] [I] Average on 10 runs - GPU latency: 22.9484 ms - Host latency: 24.7331 ms (enqueue 2.76648 ms)\n",
    "[02/02/2025-19:50:33] [I] Average on 10 runs - GPU latency: 23.0709 ms - Host latency: 24.8612 ms (enqueue 2.78151 ms)\n",
    "[02/02/2025-19:50:33] [I] Average on 10 runs - GPU latency: 22.9729 ms - Host latency: 24.7606 ms (enqueue 2.46401 ms)\n",
    "[02/02/2025-19:50:33] [I] Average on 10 runs - GPU latency: 23.037 ms - Host latency: 24.8226 ms (enqueue 2.59023 ms)\n",
    "[02/02/2025-19:50:33] [I] Average on 10 runs - GPU latency: 22.968 ms - Host latency: 24.7537 ms (enqueue 2.57297 ms)\n",
    "[02/02/2025-19:50:33] [I] Average on 10 runs - GPU latency: 23.027 ms - Host latency: 24.8186 ms (enqueue 2.4261 ms)\n",
    "[02/02/2025-19:50:33] [I]\n",
    "[02/02/2025-19:50:33] [I] === Performance summary ===\n",
    "[02/02/2025-19:50:33] [I] Throughput: 40.2528 qps\n",
    "[02/02/2025-19:50:33] [I] Latency: min = 24.468 ms, max = 26.0828 ms, mean = 24.7583 ms, median = 24.6057 ms, percentile(90%) = 25.3337 ms, percentile(95%) = 25.5648 ms, percentile(99%) = 25.7732 ms\n",
    "[02/02/2025-19:50:33] [I] Enqueue Time: min = 2.12134 ms, max = 6.4104 ms, mean = 2.70068 ms, median = 2.46875 ms, percentile(90%) = 3.3755 ms, percentile(95%) = 3.78247 ms, percentile(99%) = 5.05054 ms\n",
    "[02/02/2025-19:50:33] [I] H2D Latency: min = 1.51611 ms, max = 1.58472 ms, mean = 1.53785 ms, median = 1.53632 ms, percentile(90%) = 1.55127 ms, percentile(95%) = 1.55566 ms, percentile(99%) = 1.5697 ms\n",
    "[02/02/2025-19:50:33] [I] GPU Compute Time: min = 22.6908 ms, max = 24.2668 ms, mean = 22.9682 ms, median = 22.8076 ms, percentile(90%) = 23.5475 ms, percentile(95%) = 23.7844 ms, percentile(99%) = 23.9915 ms\n",
    "[02/02/2025-19:50:33] [I] D2H Latency: min = 0.249756 ms, max = 0.297363 ms, mean = 0.252253 ms, median = 0.250732 ms, percentile(90%) = 0.252686 ms, percentile(95%) = 0.263794 ms, percentile(99%) = 0.288696 ms\n",
    "[02/02/2025-19:50:33] [I] Total Host Walltime: 3.006 s\n",
    "[02/02/2025-19:50:33] [I] Total GPU Compute Time: 2.77915 s\n",
    "[02/02/2025-19:50:33] [W] * GPU compute time is unstable, with coefficient of variance = 1.47859%.\n",
    "[02/02/2025-19:50:33] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\n",
    "[02/02/2025-19:50:33] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
    "[02/02/2025-19:50:33] [I]\n",
    "&&&& PASSED TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --minShapes=images:1x3x640x640 --optShapes=images:4x3x640x640 --maxShapes=images:8x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>===================================================================</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *<font face =微軟黑體 color = aqua>YOLOv9-C QAT</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = #FF79BC> Batch Size = 1</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "\n",
    " /usr/src/tensorrt/bin/trtexec \\\n",
    "  --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    "  --int8 --fp16  \\\n",
    "  --useCudaGraph \\\n",
    "  --minShapes=images:1x3x640x640 \\\n",
    "  --optShapes=images:1x3x640x640 \\\n",
    "  --maxShapes=images:1x3x640x640 \\\n",
    "  --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs1.engine\n",
    "  \n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Result</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(torch-3.10) user_pzj@DESKTOP-20USVPU:/mnt/c/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main$  /usr/src/tensorrt/bin/trtexec \\\n",
    ">   --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    ">   --int8 --fp16  \\\n",
    ">   --useCudaGraph \\\n",
    ">   --minShapes=images:1x3x640x640 \\\n",
    ">   --optShapes=images:1x3x640x640 \\\n",
    ">   --maxShapes=images:1x3x640x640 \\\n",
    ">   --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs1.engine\n",
    "&&&& RUNNING TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:1x3x640x640 --maxShapes=images:1x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs1.engine\n",
    "[02/02/2025-22:22:06] [I] === Model Options ===\n",
    "[02/02/2025-22:22:06] [I] Format: ONNX\n",
    "[02/02/2025-22:22:06] [I] Model: runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-22:22:06] [I] Output:\n",
    "[02/02/2025-22:22:06] [I] === Build Options ===\n",
    "[02/02/2025-22:22:06] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
    "[02/02/2025-22:22:06] [I] avgTiming: 8\n",
    "[02/02/2025-22:22:06] [I] Precision: FP32+FP16+INT8\n",
    "[02/02/2025-22:22:06] [I] LayerPrecisions:\n",
    "[02/02/2025-22:22:06] [I] Layer Device Types:\n",
    "[02/02/2025-22:22:06] [I] Calibration: Dynamic\n",
    "[02/02/2025-22:22:06] [I] Refit: Disabled\n",
    "[02/02/2025-22:22:06] [I] Strip weights: Disabled\n",
    "[02/02/2025-22:22:06] [I] Version Compatible: Disabled\n",
    "[02/02/2025-22:22:06] [I] ONNX Plugin InstanceNorm: Disabled\n",
    "[02/02/2025-22:22:06] [I] TensorRT runtime: full\n",
    "[02/02/2025-22:22:06] [I] Lean DLL Path:\n",
    "[02/02/2025-22:22:06] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
    "[02/02/2025-22:22:06] [I] Exclude Lean Runtime: Disabled\n",
    "[02/02/2025-22:22:06] [I] Sparsity: Disabled\n",
    "[02/02/2025-22:22:06] [I] Safe mode: Disabled\n",
    "[02/02/2025-22:22:06] [I] Build DLA standalone loadable: Disabled\n",
    "[02/02/2025-22:22:06] [I] Allow GPU fallback for DLA: Disabled\n",
    "[02/02/2025-22:22:06] [I] DirectIO mode: Disabled\n",
    "[02/02/2025-22:22:06] [I] Restricted mode: Disabled\n",
    "[02/02/2025-22:22:06] [I] Skip inference: Disabled\n",
    "[02/02/2025-22:22:06] [I] Save engine: runs/qat/qat_yolov9/weights/qat_best_best_bs1.engine\n",
    "[02/02/2025-22:22:06] [I] Load engine:\n",
    "[02/02/2025-22:22:06] [I] Profiling verbosity: 0\n",
    "[02/02/2025-22:22:06] [I] Tactic sources: Using default tactic sources\n",
    "[02/02/2025-22:22:06] [I] timingCacheMode: local\n",
    "[02/02/2025-22:22:06] [I] timingCacheFile:\n",
    "[02/02/2025-22:22:06] [I] Enable Compilation Cache: Enabled\n",
    "[02/02/2025-22:22:06] [I] errorOnTimingCacheMiss: Disabled\n",
    "[02/02/2025-22:22:06] [I] Preview Features: Use default preview flags.\n",
    "[02/02/2025-22:22:06] [I] MaxAuxStreams: -1\n",
    "[02/02/2025-22:22:06] [I] BuilderOptimizationLevel: -1\n",
    "[02/02/2025-22:22:06] [I] Calibration Profile Index: 0\n",
    "[02/02/2025-22:22:06] [I] Weight Streaming: Disabled\n",
    "[02/02/2025-22:22:06] [I] Debug Tensors:\n",
    "[02/02/2025-22:22:06] [I] Input(s)s format: fp32:CHW\n",
    "[02/02/2025-22:22:06] [I] Output(s)s format: fp32:CHW\n",
    "[02/02/2025-22:22:06] [I] Input build shape (profile 0): images=1x3x640x640+1x3x640x640+1x3x640x640\n",
    "[02/02/2025-22:22:06] [I] Input calibration shapes: model\n",
    "[02/02/2025-22:22:06] [I] === System Options ===\n",
    "[02/02/2025-22:22:06] [I] Device: 0\n",
    "[02/02/2025-22:22:06] [I] DLACore:\n",
    "[02/02/2025-22:22:06] [I] Plugins:\n",
    "[02/02/2025-22:22:06] [I] setPluginsToSerialize:\n",
    "[02/02/2025-22:22:06] [I] dynamicPlugins:\n",
    "[02/02/2025-22:22:06] [I] ignoreParsedPluginLibs: 0\n",
    "[02/02/2025-22:22:06] [I]\n",
    "[02/02/2025-22:22:06] [I] === Inference Options ===\n",
    "[02/02/2025-22:22:06] [I] Batch: Explicit\n",
    "[02/02/2025-22:22:06] [I] Input inference shape : images=1x3x640x640\n",
    "[02/02/2025-22:22:06] [I] Iterations: 10\n",
    "[02/02/2025-22:22:06] [I] Duration: 3s (+ 200ms warm up)\n",
    "[02/02/2025-22:22:06] [I] Sleep time: 0ms\n",
    "[02/02/2025-22:22:06] [I] Idle time: 0ms\n",
    "[02/02/2025-22:22:06] [I] Inference Streams: 1\n",
    "[02/02/2025-22:22:06] [I] ExposeDMA: Disabled\n",
    "[02/02/2025-22:22:06] [I] Data transfers: Enabled\n",
    "[02/02/2025-22:22:06] [I] Spin-wait: Disabled\n",
    "[02/02/2025-22:22:06] [I] Multithreading: Disabled\n",
    "[02/02/2025-22:22:06] [I] CUDA Graph: Enabled\n",
    "[02/02/2025-22:22:06] [I] Separate profiling: Disabled\n",
    "[02/02/2025-22:22:06] [I] Time Deserialize: Disabled\n",
    "[02/02/2025-22:22:06] [I] Time Refit: Disabled\n",
    "[02/02/2025-22:22:06] [I] NVTX verbosity: 0\n",
    "[02/02/2025-22:22:06] [I] Persistent Cache Ratio: 0\n",
    "[02/02/2025-22:22:06] [I] Optimization Profile Index: 0\n",
    "[02/02/2025-22:22:06] [I] Weight Streaming Budget: 100.000000%\n",
    "[02/02/2025-22:22:06] [I] Inputs:\n",
    "[02/02/2025-22:22:06] [I] Debug Tensor Save Destinations:\n",
    "[02/02/2025-22:22:06] [I] === Reporting Options ===\n",
    "[02/02/2025-22:22:06] [I] Verbose: Disabled\n",
    "[02/02/2025-22:22:06] [I] Averages: 10 inferences\n",
    "[02/02/2025-22:22:06] [I] Percentiles: 90,95,99\n",
    "[02/02/2025-22:22:06] [I] Dump refittable layers:Disabled\n",
    "[02/02/2025-22:22:06] [I] Dump output: Disabled\n",
    "[02/02/2025-22:22:06] [I] Profile: Disabled\n",
    "[02/02/2025-22:22:06] [I] Export timing to JSON file:\n",
    "[02/02/2025-22:22:06] [I] Export output to JSON file:\n",
    "[02/02/2025-22:22:06] [I] Export profile to JSON file:\n",
    "[02/02/2025-22:22:06] [I]\n",
    "[02/02/2025-22:22:06] [I] === Device Information ===\n",
    "[02/02/2025-22:22:06] [I] Available Devices:\n",
    "[02/02/2025-22:22:06] [I]   Device 0: \"NVIDIA GeForce RTX 4050 Laptop GPU\" UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-22:22:06] [I] Selected Device: NVIDIA GeForce RTX 4050 Laptop GPU\n",
    "[02/02/2025-22:22:06] [I] Selected Device ID: 0\n",
    "[02/02/2025-22:22:06] [I] Selected Device UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-22:22:06] [I] Compute Capability: 8.9\n",
    "[02/02/2025-22:22:06] [I] SMs: 20\n",
    "[02/02/2025-22:22:06] [I] Device Global Memory: 6140 MiB\n",
    "[02/02/2025-22:22:06] [I] Shared Memory per SM: 100 KiB\n",
    "[02/02/2025-22:22:06] [I] Memory Bus Width: 96 bits (ECC disabled)\n",
    "[02/02/2025-22:22:06] [I] Application Compute Clock Rate: 2.355 GHz\n",
    "[02/02/2025-22:22:06] [I] Application Memory Clock Rate: 7.825 GHz\n",
    "[02/02/2025-22:22:06] [I]\n",
    "[02/02/2025-22:22:06] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
    "[02/02/2025-22:22:06] [I]\n",
    "[02/02/2025-22:22:06] [I] TensorRT version: 10.1.0\n",
    "[02/02/2025-22:22:06] [I] Loading standard plugins\n",
    "[02/02/2025-22:22:06] [I] [TRT] [MemUsageChange] Init CUDA: CPU +14, GPU +0, now: CPU 24, GPU 1065 (MiB)\n",
    "[02/02/2025-22:22:10] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1659, GPU +292, now: CPU 1830, GPU 1357 (MiB)\n",
    "[02/02/2025-22:22:10] [I] Start parsing network model.\n",
    "[02/02/2025-22:22:11] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-22:22:11] [I] [TRT] Input filename:   runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-22:22:11] [I] [TRT] ONNX IR version:  0.0.10\n",
    "[02/02/2025-22:22:11] [I] [TRT] Opset version:    13\n",
    "[02/02/2025-22:22:11] [I] [TRT] Producer name:    pytorch\n",
    "[02/02/2025-22:22:11] [I] [TRT] Producer version: 2.5.1\n",
    "[02/02/2025-22:22:11] [I] [TRT] Domain:\n",
    "[02/02/2025-22:22:11] [I] [TRT] Model version:    0\n",
    "[02/02/2025-22:22:11] [I] [TRT] Doc string:\n",
    "[02/02/2025-22:22:11] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-22:22:11] [I] Finished parsing network model. Parse time: 1.16889\n",
    "[02/02/2025-22:22:11] [I] Set shape of input tensor images for optimization profile 0 to: MIN=1x3x640x640 OPT=1x3x640x640 MAX=1x3x640x640\n",
    "[02/02/2025-22:22:11] [W] [TRT] Calibrator won't be used in explicit quantization mode. Please insert Quantize/Dequantize layers to indicate which tensors to quantize/dequantize.\n",
    "[02/02/2025-22:22:12] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
    "[02/02/2025-22:27:53] [I] [TRT] Detected 1 inputs and 6 output network tensors.\n",
    "[02/02/2025-22:28:05] [I] [TRT] Total Host Persistent Memory: 1304224\n",
    "[02/02/2025-22:28:05] [I] [TRT] Total Device Persistent Memory: 51200\n",
    "[02/02/2025-22:28:05] [I] [TRT] Total Scratch Memory: 0\n",
    "[02/02/2025-22:28:05] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 364 steps to complete.\n",
    "[02/02/2025-22:28:05] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 40.2717ms to assign 14 blocks to 364 nodes requiring 56729088 bytes.\n",
    "[02/02/2025-22:28:05] [I] [TRT] Total Activation Memory: 56728576\n",
    "[02/02/2025-22:28:05] [I] [TRT] Total Weights Memory: 52581888\n",
    "[02/02/2025-22:28:05] [I] [TRT] Engine generation completed in 353.438 seconds.\n",
    "[02/02/2025-22:28:05] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 140 MiB\n",
    "[02/02/2025-22:28:06] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 2941 MiB\n",
    "[02/02/2025-22:28:06] [I] Engine built in 354.204 sec.\n",
    "[02/02/2025-22:28:06] [I] Created engine with size: 59.1619 MiB\n",
    "[02/02/2025-22:28:07] [I] [TRT] Loaded engine size: 59 MiB\n",
    "[02/02/2025-22:28:07] [I] Engine deserialized in 0.512302 sec.\n",
    "[02/02/2025-22:28:07] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +54, now: CPU 2, GPU 104 (MiB)\n",
    "[02/02/2025-22:28:07] [I] Setting persistentCacheLimit to 0 bytes.\n",
    "[02/02/2025-22:28:07] [I] Created execution context with device memory size: 54.1006 MiB\n",
    "[02/02/2025-22:28:07] [I] Using random values for input images\n",
    "[02/02/2025-22:28:07] [I] Input binding for images with dimensions 1x3x640x640 is created.\n",
    "[02/02/2025-22:28:07] [I] Output binding for output0 with dimensions 1x12x8400 is created.\n",
    "[02/02/2025-22:28:07] [I] Output binding for 4518 with dimensions 1x12x8400 is created.\n",
    "[02/02/2025-22:28:07] [I] Starting inference\n",
    "[02/02/2025-22:28:07] [I] Capturing CUDA graph for the current execution context\n",
    "[02/02/2025-22:28:07] [I] Successfully captured CUDA graph for the current execution context\n",
    "[02/02/2025-22:28:10] [I] Warmup completed 2 queries over 200 ms\n",
    "[02/02/2025-22:28:10] [I] Timing trace has 455 queries over 3.00076 s\n",
    "[02/02/2025-22:28:10] [I]\n",
    "[02/02/2025-22:28:10] [I] === Trace details ===\n",
    "[02/02/2025-22:28:10] [I] Trace averages of 10 runs:\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.37659 ms - Host latency: 6.82809 ms (enqueue 0.0607025 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.37774 ms - Host latency: 6.83731 ms (enqueue 0.080719 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.27834 ms - Host latency: 6.73713 ms (enqueue 0.0951904 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.02925 ms - Host latency: 6.48018 ms (enqueue 0.0535248 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.02674 ms - Host latency: 6.47914 ms (enqueue 0.0408875 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03323 ms - Host latency: 6.48897 ms (enqueue 0.0749207 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03909 ms - Host latency: 6.49251 ms (enqueue 0.0908325 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03807 ms - Host latency: 6.49305 ms (enqueue 0.0668091 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03798 ms - Host latency: 6.49229 ms (enqueue 0.0479065 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03705 ms - Host latency: 6.49269 ms (enqueue 0.0829956 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03891 ms - Host latency: 6.49426 ms (enqueue 0.0628235 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.04044 ms - Host latency: 6.49607 ms (enqueue 0.0775635 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03818 ms - Host latency: 6.49859 ms (enqueue 0.0655334 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.0374 ms - Host latency: 6.4946 ms (enqueue 0.055249 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03879 ms - Host latency: 6.49514 ms (enqueue 0.0811646 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03397 ms - Host latency: 6.49143 ms (enqueue 0.072168 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03733 ms - Host latency: 6.49276 ms (enqueue 0.0688599 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.0371 ms - Host latency: 6.49619 ms (enqueue 0.0820435 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03697 ms - Host latency: 6.48829 ms (enqueue 0.0698975 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03759 ms - Host latency: 6.48843 ms (enqueue 0.0886353 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03928 ms - Host latency: 6.49199 ms (enqueue 0.0949463 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03697 ms - Host latency: 6.49249 ms (enqueue 0.0829346 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.0392 ms - Host latency: 6.49459 ms (enqueue 0.0836792 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03944 ms - Host latency: 6.49772 ms (enqueue 0.0772339 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.04199 ms - Host latency: 6.49482 ms (enqueue 0.0810791 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03563 ms - Host latency: 6.48994 ms (enqueue 0.0658081 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.08403 ms - Host latency: 6.53552 ms (enqueue 0.0889038 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03711 ms - Host latency: 6.48883 ms (enqueue 0.123914 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.0405 ms - Host latency: 6.49404 ms (enqueue 0.0751221 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03721 ms - Host latency: 6.48857 ms (enqueue 0.073877 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03723 ms - Host latency: 6.49011 ms (enqueue 0.0666016 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03628 ms - Host latency: 6.49194 ms (enqueue 0.162939 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.04048 ms - Host latency: 6.49595 ms (enqueue 0.0686035 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03906 ms - Host latency: 6.49021 ms (enqueue 0.0803711 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03845 ms - Host latency: 6.49797 ms (enqueue 0.0536865 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.04006 ms - Host latency: 6.49656 ms (enqueue 0.0623779 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.04094 ms - Host latency: 6.49868 ms (enqueue 0.0570313 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03982 ms - Host latency: 6.49966 ms (enqueue 0.0758057 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.04104 ms - Host latency: 6.49651 ms (enqueue 0.088208 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03765 ms - Host latency: 6.49309 ms (enqueue 0.072168 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03433 ms - Host latency: 6.49277 ms (enqueue 0.0624023 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.03855 ms - Host latency: 6.49431 ms (enqueue 0.0857666 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.04199 ms - Host latency: 6.49436 ms (enqueue 0.0863281 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.04255 ms - Host latency: 6.49973 ms (enqueue 0.0732666 ms)\n",
    "[02/02/2025-22:28:10] [I] Average on 10 runs - GPU latency: 6.04282 ms - Host latency: 6.49783 ms (enqueue 0.0482666 ms)\n",
    "[02/02/2025-22:28:10] [I]\n",
    "[02/02/2025-22:28:10] [I] === Performance summary ===\n",
    "[02/02/2025-22:28:10] [I] Throughput: 151.628 qps\n",
    "[02/02/2025-22:28:10] [I] Latency: min = 6.4718 ms, max = 6.95068 ms, mean = 6.51435 ms, median = 6.49292 ms, percentile(90%) = 6.51465 ms, percentile(95%) = 6.8248 ms, percentile(99%) = 6.84305 ms\n",
    "[02/02/2025-22:28:10] [I] Enqueue Time: min = 0.0300293 ms, max = 0.53418 ms, mean = 0.0758189 ms, median = 0.0618896 ms, percentile(90%) = 0.129395 ms, percentile(95%) = 0.151123 ms, percentile(99%) = 0.320007 ms\n",
    "[02/02/2025-22:28:10] [I] H2D Latency: min = 0.383057 ms, max = 0.414276 ms, mean = 0.387695 ms, median = 0.388428 ms, percentile(90%) = 0.388916 ms, percentile(95%) = 0.389282 ms, percentile(99%) = 0.412598 ms\n",
    "[02/02/2025-22:28:10] [I] GPU Compute Time: min = 6.01993 ms, max = 6.49829 ms, mean = 6.0592 ms, median = 6.03857 ms, percentile(90%) = 6.04846 ms, percentile(95%) = 6.37302 ms, percentile(99%) = 6.38327 ms\n",
    "[02/02/2025-22:28:10] [I] D2H Latency: min = 0.0664062 ms, max = 0.107422 ms, mean = 0.0674516 ms, median = 0.0668335 ms, percentile(90%) = 0.0671387 ms, percentile(95%) = 0.0679321 ms, percentile(99%) = 0.092041 ms\n",
    "[02/02/2025-22:28:10] [I] Total Host Walltime: 3.00076 s\n",
    "[02/02/2025-22:28:10] [I] Total GPU Compute Time: 2.75693 s\n",
    "[02/02/2025-22:28:10] [W] * GPU compute time is unstable, with coefficient of variance = 1.36735%.\n",
    "[02/02/2025-22:28:10] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\n",
    "[02/02/2025-22:28:10] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
    "[02/02/2025-22:28:10] [I]\n",
    "&&&& PASSED TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:1x3x640x640 --maxShapes=images:1x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs1.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>===================================================================</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = #FF79BC> Batch Size = 4</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "\n",
    " /usr/src/tensorrt/bin/trtexec \\\n",
    "  --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    "  --int8 --fp16  \\\n",
    "  --useCudaGraph \\\n",
    "  --minShapes=images:1x3x640x640 \\\n",
    "  --optShapes=images:4x3x640x640 \\\n",
    "  --maxShapes=images:4x3x640x640 \\\n",
    "  --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs4.engine\n",
    "  \n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Result</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(torch-3.10) user_pzj@DESKTOP-20USVPU:/mnt/c/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main$  /usr/src/tensorrt/bin/trtexec \\\n",
    ">   --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    ">   --int8 --fp16  \\\n",
    ">   --useCudaGraph \\\n",
    ">   --minShapes=images:1x3x640x640 \\\n",
    ">   --optShapes=images:4x3x640x640 \\\n",
    ">   --maxShapes=images:4x3x640x640 \\\n",
    ">   --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs4.engine\n",
    "&&&& RUNNING TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:4x3x640x640 --maxShapes=images:4x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs4.engine\n",
    "[02/02/2025-22:30:27] [I] === Model Options ===\n",
    "[02/02/2025-22:30:27] [I] Format: ONNX\n",
    "[02/02/2025-22:30:27] [I] Model: runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-22:30:27] [I] Output:\n",
    "[02/02/2025-22:30:27] [I] === Build Options ===\n",
    "[02/02/2025-22:30:27] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
    "[02/02/2025-22:30:27] [I] avgTiming: 8\n",
    "[02/02/2025-22:30:27] [I] Precision: FP32+FP16+INT8\n",
    "[02/02/2025-22:30:27] [I] LayerPrecisions:\n",
    "[02/02/2025-22:30:27] [I] Layer Device Types:\n",
    "[02/02/2025-22:30:27] [I] Calibration: Dynamic\n",
    "[02/02/2025-22:30:27] [I] Refit: Disabled\n",
    "[02/02/2025-22:30:27] [I] Strip weights: Disabled\n",
    "[02/02/2025-22:30:27] [I] Version Compatible: Disabled\n",
    "[02/02/2025-22:30:27] [I] ONNX Plugin InstanceNorm: Disabled\n",
    "[02/02/2025-22:30:27] [I] TensorRT runtime: full\n",
    "[02/02/2025-22:30:27] [I] Lean DLL Path:\n",
    "[02/02/2025-22:30:27] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
    "[02/02/2025-22:30:27] [I] Exclude Lean Runtime: Disabled\n",
    "[02/02/2025-22:30:27] [I] Sparsity: Disabled\n",
    "[02/02/2025-22:30:27] [I] Safe mode: Disabled\n",
    "[02/02/2025-22:30:27] [I] Build DLA standalone loadable: Disabled\n",
    "[02/02/2025-22:30:27] [I] Allow GPU fallback for DLA: Disabled\n",
    "[02/02/2025-22:30:27] [I] DirectIO mode: Disabled\n",
    "[02/02/2025-22:30:27] [I] Restricted mode: Disabled\n",
    "[02/02/2025-22:30:27] [I] Skip inference: Disabled\n",
    "[02/02/2025-22:30:27] [I] Save engine: runs/qat/qat_yolov9/weights/qat_best_best_bs4.engine\n",
    "[02/02/2025-22:30:27] [I] Load engine:\n",
    "[02/02/2025-22:30:27] [I] Profiling verbosity: 0\n",
    "[02/02/2025-22:30:27] [I] Tactic sources: Using default tactic sources\n",
    "[02/02/2025-22:30:27] [I] timingCacheMode: local\n",
    "[02/02/2025-22:30:27] [I] timingCacheFile:\n",
    "[02/02/2025-22:30:27] [I] Enable Compilation Cache: Enabled\n",
    "[02/02/2025-22:30:27] [I] errorOnTimingCacheMiss: Disabled\n",
    "[02/02/2025-22:30:27] [I] Preview Features: Use default preview flags.\n",
    "[02/02/2025-22:30:27] [I] MaxAuxStreams: -1\n",
    "[02/02/2025-22:30:27] [I] BuilderOptimizationLevel: -1\n",
    "[02/02/2025-22:30:27] [I] Calibration Profile Index: 0\n",
    "[02/02/2025-22:30:27] [I] Weight Streaming: Disabled\n",
    "[02/02/2025-22:30:27] [I] Debug Tensors:\n",
    "[02/02/2025-22:30:27] [I] Input(s)s format: fp32:CHW\n",
    "[02/02/2025-22:30:27] [I] Output(s)s format: fp32:CHW\n",
    "[02/02/2025-22:30:27] [I] Input build shape (profile 0): images=1x3x640x640+4x3x640x640+4x3x640x640\n",
    "[02/02/2025-22:30:27] [I] Input calibration shapes: model\n",
    "[02/02/2025-22:30:27] [I] === System Options ===\n",
    "[02/02/2025-22:30:27] [I] Device: 0\n",
    "[02/02/2025-22:30:27] [I] DLACore:\n",
    "[02/02/2025-22:30:27] [I] Plugins:\n",
    "[02/02/2025-22:30:27] [I] setPluginsToSerialize:\n",
    "[02/02/2025-22:30:27] [I] dynamicPlugins:\n",
    "[02/02/2025-22:30:27] [I] ignoreParsedPluginLibs: 0\n",
    "[02/02/2025-22:30:27] [I]\n",
    "[02/02/2025-22:30:27] [I] === Inference Options ===\n",
    "[02/02/2025-22:30:27] [I] Batch: Explicit\n",
    "[02/02/2025-22:30:27] [I] Input inference shape : images=4x3x640x640\n",
    "[02/02/2025-22:30:27] [I] Iterations: 10\n",
    "[02/02/2025-22:30:27] [I] Duration: 3s (+ 200ms warm up)\n",
    "[02/02/2025-22:30:27] [I] Sleep time: 0ms\n",
    "[02/02/2025-22:30:27] [I] Idle time: 0ms\n",
    "[02/02/2025-22:30:27] [I] Inference Streams: 1\n",
    "[02/02/2025-22:30:27] [I] ExposeDMA: Disabled\n",
    "[02/02/2025-22:30:27] [I] Data transfers: Enabled\n",
    "[02/02/2025-22:30:27] [I] Spin-wait: Disabled\n",
    "[02/02/2025-22:30:27] [I] Multithreading: Disabled\n",
    "[02/02/2025-22:30:27] [I] CUDA Graph: Enabled\n",
    "[02/02/2025-22:30:27] [I] Separate profiling: Disabled\n",
    "[02/02/2025-22:30:27] [I] Time Deserialize: Disabled\n",
    "[02/02/2025-22:30:27] [I] Time Refit: Disabled\n",
    "[02/02/2025-22:30:27] [I] NVTX verbosity: 0\n",
    "[02/02/2025-22:30:27] [I] Persistent Cache Ratio: 0\n",
    "[02/02/2025-22:30:27] [I] Optimization Profile Index: 0\n",
    "[02/02/2025-22:30:27] [I] Weight Streaming Budget: 100.000000%\n",
    "[02/02/2025-22:30:27] [I] Inputs:\n",
    "[02/02/2025-22:30:27] [I] Debug Tensor Save Destinations:\n",
    "[02/02/2025-22:30:27] [I] === Reporting Options ===\n",
    "[02/02/2025-22:30:27] [I] Verbose: Disabled\n",
    "[02/02/2025-22:30:27] [I] Averages: 10 inferences\n",
    "[02/02/2025-22:30:27] [I] Percentiles: 90,95,99\n",
    "[02/02/2025-22:30:27] [I] Dump refittable layers:Disabled\n",
    "[02/02/2025-22:30:27] [I] Dump output: Disabled\n",
    "[02/02/2025-22:30:27] [I] Profile: Disabled\n",
    "[02/02/2025-22:30:27] [I] Export timing to JSON file:\n",
    "[02/02/2025-22:30:27] [I] Export output to JSON file:\n",
    "[02/02/2025-22:30:27] [I] Export profile to JSON file:\n",
    "[02/02/2025-22:30:27] [I]\n",
    "[02/02/2025-22:30:27] [I] === Device Information ===\n",
    "[02/02/2025-22:30:27] [I] Available Devices:\n",
    "[02/02/2025-22:30:27] [I]   Device 0: \"NVIDIA GeForce RTX 4050 Laptop GPU\" UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-22:30:27] [I] Selected Device: NVIDIA GeForce RTX 4050 Laptop GPU\n",
    "[02/02/2025-22:30:27] [I] Selected Device ID: 0\n",
    "[02/02/2025-22:30:27] [I] Selected Device UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-22:30:27] [I] Compute Capability: 8.9\n",
    "[02/02/2025-22:30:27] [I] SMs: 20\n",
    "[02/02/2025-22:30:27] [I] Device Global Memory: 6140 MiB\n",
    "[02/02/2025-22:30:27] [I] Shared Memory per SM: 100 KiB\n",
    "[02/02/2025-22:30:27] [I] Memory Bus Width: 96 bits (ECC disabled)\n",
    "[02/02/2025-22:30:27] [I] Application Compute Clock Rate: 2.355 GHz\n",
    "[02/02/2025-22:30:27] [I] Application Memory Clock Rate: 7.825 GHz\n",
    "[02/02/2025-22:30:27] [I]\n",
    "[02/02/2025-22:30:27] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
    "[02/02/2025-22:30:27] [I]\n",
    "[02/02/2025-22:30:27] [I] TensorRT version: 10.1.0\n",
    "[02/02/2025-22:30:27] [I] Loading standard plugins\n",
    "[02/02/2025-22:30:27] [I] [TRT] [MemUsageChange] Init CUDA: CPU +14, GPU +0, now: CPU 24, GPU 1065 (MiB)\n",
    "[02/02/2025-22:30:30] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1659, GPU +292, now: CPU 1830, GPU 1357 (MiB)\n",
    "[02/02/2025-22:30:30] [I] Start parsing network model.\n",
    "[02/02/2025-22:30:31] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-22:30:31] [I] [TRT] Input filename:   runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-22:30:31] [I] [TRT] ONNX IR version:  0.0.10\n",
    "[02/02/2025-22:30:31] [I] [TRT] Opset version:    13\n",
    "[02/02/2025-22:30:31] [I] [TRT] Producer name:    pytorch\n",
    "[02/02/2025-22:30:31] [I] [TRT] Producer version: 2.5.1\n",
    "[02/02/2025-22:30:31] [I] [TRT] Domain:\n",
    "[02/02/2025-22:30:31] [I] [TRT] Model version:    0\n",
    "[02/02/2025-22:30:31] [I] [TRT] Doc string:\n",
    "[02/02/2025-22:30:31] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-22:30:31] [I] Finished parsing network model. Parse time: 1.32485\n",
    "[02/02/2025-22:30:31] [I] Set shape of input tensor images for optimization profile 0 to: MIN=1x3x640x640 OPT=4x3x640x640 MAX=4x3x640x640\n",
    "[02/02/2025-22:30:31] [W] [TRT] Calibrator won't be used in explicit quantization mode. Please insert Quantize/Dequantize layers to indicate which tensors to quantize/dequantize.\n",
    "[02/02/2025-22:30:31] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
    "[02/02/2025-22:36:56] [I] [TRT] Detected 1 inputs and 6 output network tensors.\n",
    "[02/02/2025-22:37:10] [I] [TRT] Total Host Persistent Memory: 1305488\n",
    "[02/02/2025-22:37:10] [I] [TRT] Total Device Persistent Memory: 54272\n",
    "[02/02/2025-22:37:10] [I] [TRT] Total Scratch Memory: 4300800\n",
    "[02/02/2025-22:37:10] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 383 steps to complete.\n",
    "[02/02/2025-22:37:10] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 45.5956ms to assign 14 blocks to 383 nodes requiring 205294592 bytes.\n",
    "[02/02/2025-22:37:10] [I] [TRT] Total Activation Memory: 205294080\n",
    "[02/02/2025-22:37:10] [I] [TRT] Total Weights Memory: 52560896\n",
    "[02/02/2025-22:37:10] [I] [TRT] Engine generation completed in 399.031 seconds.\n",
    "[02/02/2025-22:37:10] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 151 MiB\n",
    "[02/02/2025-22:37:11] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 2980 MiB\n",
    "[02/02/2025-22:37:11] [I] Engine built in 399.784 sec.\n",
    "[02/02/2025-22:37:11] [I] Created engine with size: 57.5559 MiB\n",
    "[02/02/2025-22:37:12] [I] [TRT] Loaded engine size: 57 MiB\n",
    "[02/02/2025-22:37:12] [I] Engine deserialized in 0.59964 sec.\n",
    "[02/02/2025-22:37:12] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +196, now: CPU 2, GPU 246 (MiB)\n",
    "[02/02/2025-22:37:12] [I] Setting persistentCacheLimit to 0 bytes.\n",
    "[02/02/2025-22:37:12] [I] Set shape of input tensor images to: 4x3x640x640\n",
    "[02/02/2025-22:37:12] [I] Created execution context with device memory size: 195.784 MiB\n",
    "[02/02/2025-22:37:12] [I] Using random values for input images\n",
    "[02/02/2025-22:37:12] [I] Input binding for images with dimensions 4x3x640x640 is created.\n",
    "[02/02/2025-22:37:12] [I] Output binding for output0 with dimensions 4x12x8400 is created.\n",
    "[02/02/2025-22:37:12] [I] Output binding for 4518 with dimensions 4x12x8400 is created.\n",
    "[02/02/2025-22:37:12] [I] Starting inference\n",
    "[02/02/2025-22:37:12] [I] Capturing CUDA graph for the current execution context\n",
    "[02/02/2025-22:37:13] [I] Successfully captured CUDA graph for the current execution context\n",
    "[02/02/2025-22:37:16] [I] Warmup completed 2 queries over 200 ms\n",
    "[02/02/2025-22:37:16] [I] Timing trace has 128 queries over 3.04992 s\n",
    "[02/02/2025-22:37:16] [I]\n",
    "[02/02/2025-22:37:16] [I] === Trace details ===\n",
    "[02/02/2025-22:37:16] [I] Trace averages of 10 runs:\n",
    "[02/02/2025-22:37:16] [I] Average on 10 runs - GPU latency: 22.3064 ms - Host latency: 24.0853 ms (enqueue 0.0825958 ms)\n",
    "[02/02/2025-22:37:16] [I] Average on 10 runs - GPU latency: 21.8552 ms - Host latency: 23.6302 ms (enqueue 0.100592 ms)\n",
    "[02/02/2025-22:37:16] [I] Average on 10 runs - GPU latency: 21.8591 ms - Host latency: 23.6523 ms (enqueue 0.0938293 ms)\n",
    "[02/02/2025-22:37:16] [I] Average on 10 runs - GPU latency: 21.8561 ms - Host latency: 23.6298 ms (enqueue 0.115594 ms)\n",
    "[02/02/2025-22:37:16] [I] Average on 10 runs - GPU latency: 21.8582 ms - Host latency: 23.633 ms (enqueue 0.127014 ms)\n",
    "[02/02/2025-22:37:16] [I] Average on 10 runs - GPU latency: 21.8613 ms - Host latency: 23.6311 ms (enqueue 0.0869019 ms)\n",
    "[02/02/2025-22:37:16] [I] Average on 10 runs - GPU latency: 21.8648 ms - Host latency: 23.6386 ms (enqueue 0.101941 ms)\n",
    "[02/02/2025-22:37:16] [I] Average on 10 runs - GPU latency: 21.8583 ms - Host latency: 23.6376 ms (enqueue 0.0922974 ms)\n",
    "[02/02/2025-22:37:16] [I] Average on 10 runs - GPU latency: 21.861 ms - Host latency: 23.641 ms (enqueue 0.123047 ms)\n",
    "[02/02/2025-22:37:16] [I] Average on 10 runs - GPU latency: 21.8587 ms - Host latency: 23.6391 ms (enqueue 0.109277 ms)\n",
    "[02/02/2025-22:37:16] [I] Average on 10 runs - GPU latency: 21.8722 ms - Host latency: 23.6381 ms (enqueue 0.112354 ms)\n",
    "[02/02/2025-22:37:16] [I] Average on 10 runs - GPU latency: 21.9138 ms - Host latency: 23.6907 ms (enqueue 0.111011 ms)\n",
    "[02/02/2025-22:37:16] [I]\n",
    "[02/02/2025-22:37:16] [I] === Performance summary ===\n",
    "[02/02/2025-22:37:16] [I] Throughput: 41.9683 qps\n",
    "[02/02/2025-22:37:16] [I] Latency: min = 23.603 ms, max = 24.628 ms, mean = 23.6797 ms, median = 23.6375 ms, percentile(90%) = 23.6938 ms, percentile(95%) = 23.7236 ms, percentile(99%) = 24.5702 ms\n",
    "[02/02/2025-22:37:16] [I] Enqueue Time: min = 0.0372314 ms, max = 0.287964 ms, mean = 0.107136 ms, median = 0.0908203 ms, percentile(90%) = 0.166565 ms, percentile(95%) = 0.177734 ms, percentile(99%) = 0.214355 ms\n",
    "[02/02/2025-22:37:16] [I] H2D Latency: min = 1.51099 ms, max = 1.56659 ms, mean = 1.52453 ms, median = 1.51581 ms, percentile(90%) = 1.55359 ms, percentile(95%) = 1.55493 ms, percentile(99%) = 1.56274 ms\n",
    "[02/02/2025-22:37:16] [I] GPU Compute Time: min = 21.8243 ms, max = 22.8291 ms, mean = 21.9031 ms, median = 21.8613 ms, percentile(90%) = 21.9167 ms, percentile(95%) = 21.9299 ms, percentile(99%) = 22.8014 ms\n",
    "[02/02/2025-22:37:16] [I] D2H Latency: min = 0.250366 ms, max = 0.279755 ms, mean = 0.252016 ms, median = 0.250732 ms, percentile(90%) = 0.252991 ms, percentile(95%) = 0.25415 ms, percentile(99%) = 0.270508 ms\n",
    "[02/02/2025-22:37:16] [I] Total Host Walltime: 3.04992 s\n",
    "[02/02/2025-22:37:16] [I] Total GPU Compute Time: 2.8036 s\n",
    "[02/02/2025-22:37:16] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
    "[02/02/2025-22:37:16] [I]\n",
    "&&&& PASSED TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:4x3x640x640 --maxShapes=images:4x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs4.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>===================================================================</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = #FF79BC> Batch Size = 8</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "\n",
    " /usr/src/tensorrt/bin/trtexec \\\n",
    "  --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    "  --int8 --fp16  \\\n",
    "  --useCudaGraph \\\n",
    "  --minShapes=images:1x3x640x640 \\\n",
    "  --optShapes=images:8x3x640x640 \\\n",
    "  --maxShapes=images:8x3x640x640 \\\n",
    "  --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs8.engine\n",
    "  \n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Result</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(torch-3.10) user_pzj@DESKTOP-20USVPU:/mnt/c/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main$  /usr/src/tensorrt/bin/trtexec \\\n",
    ">   --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    ">   --int8 --fp16  \\\n",
    ">   --useCudaGraph \\\n",
    ">   --minShapes=images:1x3x640x640 \\\n",
    ">   --optShapes=images:8x3x640x640 \\\n",
    ">   --maxShapes=images:8x3x640x640 \\\n",
    ">   --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs8.engine\n",
    "&&&& RUNNING TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:8x3x640x640 --maxShapes=images:8x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs8.engine\n",
    "[02/02/2025-22:38:53] [I] === Model Options ===\n",
    "[02/02/2025-22:38:53] [I] Format: ONNX\n",
    "[02/02/2025-22:38:53] [I] Model: runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-22:38:53] [I] Output:\n",
    "[02/02/2025-22:38:53] [I] === Build Options ===\n",
    "[02/02/2025-22:38:53] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
    "[02/02/2025-22:38:53] [I] avgTiming: 8\n",
    "[02/02/2025-22:38:53] [I] Precision: FP32+FP16+INT8\n",
    "[02/02/2025-22:38:53] [I] LayerPrecisions:\n",
    "[02/02/2025-22:38:53] [I] Layer Device Types:\n",
    "[02/02/2025-22:38:53] [I] Calibration: Dynamic\n",
    "[02/02/2025-22:38:53] [I] Refit: Disabled\n",
    "[02/02/2025-22:38:53] [I] Strip weights: Disabled\n",
    "[02/02/2025-22:38:53] [I] Version Compatible: Disabled\n",
    "[02/02/2025-22:38:53] [I] ONNX Plugin InstanceNorm: Disabled\n",
    "[02/02/2025-22:38:53] [I] TensorRT runtime: full\n",
    "[02/02/2025-22:38:53] [I] Lean DLL Path:\n",
    "[02/02/2025-22:38:53] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
    "[02/02/2025-22:38:53] [I] Exclude Lean Runtime: Disabled\n",
    "[02/02/2025-22:38:53] [I] Sparsity: Disabled\n",
    "[02/02/2025-22:38:53] [I] Safe mode: Disabled\n",
    "[02/02/2025-22:38:53] [I] Build DLA standalone loadable: Disabled\n",
    "[02/02/2025-22:38:53] [I] Allow GPU fallback for DLA: Disabled\n",
    "[02/02/2025-22:38:53] [I] DirectIO mode: Disabled\n",
    "[02/02/2025-22:38:53] [I] Restricted mode: Disabled\n",
    "[02/02/2025-22:38:53] [I] Skip inference: Disabled\n",
    "[02/02/2025-22:38:53] [I] Save engine: runs/qat/qat_yolov9/weights/qat_best_best_bs8.engine\n",
    "[02/02/2025-22:38:53] [I] Load engine:\n",
    "[02/02/2025-22:38:53] [I] Profiling verbosity: 0\n",
    "[02/02/2025-22:38:53] [I] Tactic sources: Using default tactic sources\n",
    "[02/02/2025-22:38:53] [I] timingCacheMode: local\n",
    "[02/02/2025-22:38:53] [I] timingCacheFile:\n",
    "[02/02/2025-22:38:53] [I] Enable Compilation Cache: Enabled\n",
    "[02/02/2025-22:38:53] [I] errorOnTimingCacheMiss: Disabled\n",
    "[02/02/2025-22:38:53] [I] Preview Features: Use default preview flags.\n",
    "[02/02/2025-22:38:53] [I] MaxAuxStreams: -1\n",
    "[02/02/2025-22:38:53] [I] BuilderOptimizationLevel: -1\n",
    "[02/02/2025-22:38:53] [I] Calibration Profile Index: 0\n",
    "[02/02/2025-22:38:53] [I] Weight Streaming: Disabled\n",
    "[02/02/2025-22:38:53] [I] Debug Tensors:\n",
    "[02/02/2025-22:38:53] [I] Input(s)s format: fp32:CHW\n",
    "[02/02/2025-22:38:53] [I] Output(s)s format: fp32:CHW\n",
    "[02/02/2025-22:38:53] [I] Input build shape (profile 0): images=1x3x640x640+8x3x640x640+8x3x640x640\n",
    "[02/02/2025-22:38:53] [I] Input calibration shapes: model\n",
    "[02/02/2025-22:38:53] [I] === System Options ===\n",
    "[02/02/2025-22:38:53] [I] Device: 0\n",
    "[02/02/2025-22:38:53] [I] DLACore:\n",
    "[02/02/2025-22:38:53] [I] Plugins:\n",
    "[02/02/2025-22:38:53] [I] setPluginsToSerialize:\n",
    "[02/02/2025-22:38:53] [I] dynamicPlugins:\n",
    "[02/02/2025-22:38:53] [I] ignoreParsedPluginLibs: 0\n",
    "[02/02/2025-22:38:53] [I]\n",
    "[02/02/2025-22:38:53] [I] === Inference Options ===\n",
    "[02/02/2025-22:38:53] [I] Batch: Explicit\n",
    "[02/02/2025-22:38:53] [I] Input inference shape : images=8x3x640x640\n",
    "[02/02/2025-22:38:53] [I] Iterations: 10\n",
    "[02/02/2025-22:38:53] [I] Duration: 3s (+ 200ms warm up)\n",
    "[02/02/2025-22:38:53] [I] Sleep time: 0ms\n",
    "[02/02/2025-22:38:53] [I] Idle time: 0ms\n",
    "[02/02/2025-22:38:53] [I] Inference Streams: 1\n",
    "[02/02/2025-22:38:53] [I] ExposeDMA: Disabled\n",
    "[02/02/2025-22:38:53] [I] Data transfers: Enabled\n",
    "[02/02/2025-22:38:53] [I] Spin-wait: Disabled\n",
    "[02/02/2025-22:38:53] [I] Multithreading: Disabled\n",
    "[02/02/2025-22:38:53] [I] CUDA Graph: Enabled\n",
    "[02/02/2025-22:38:53] [I] Separate profiling: Disabled\n",
    "[02/02/2025-22:38:53] [I] Time Deserialize: Disabled\n",
    "[02/02/2025-22:38:53] [I] Time Refit: Disabled\n",
    "[02/02/2025-22:38:53] [I] NVTX verbosity: 0\n",
    "[02/02/2025-22:38:53] [I] Persistent Cache Ratio: 0\n",
    "[02/02/2025-22:38:53] [I] Optimization Profile Index: 0\n",
    "[02/02/2025-22:38:53] [I] Weight Streaming Budget: 100.000000%\n",
    "[02/02/2025-22:38:53] [I] Inputs:\n",
    "[02/02/2025-22:38:53] [I] Debug Tensor Save Destinations:\n",
    "[02/02/2025-22:38:53] [I] === Reporting Options ===\n",
    "[02/02/2025-22:38:53] [I] Verbose: Disabled\n",
    "[02/02/2025-22:38:53] [I] Averages: 10 inferences\n",
    "[02/02/2025-22:38:53] [I] Percentiles: 90,95,99\n",
    "[02/02/2025-22:38:53] [I] Dump refittable layers:Disabled\n",
    "[02/02/2025-22:38:53] [I] Dump output: Disabled\n",
    "[02/02/2025-22:38:53] [I] Profile: Disabled\n",
    "[02/02/2025-22:38:53] [I] Export timing to JSON file:\n",
    "[02/02/2025-22:38:53] [I] Export output to JSON file:\n",
    "[02/02/2025-22:38:53] [I] Export profile to JSON file:\n",
    "[02/02/2025-22:38:53] [I]\n",
    "[02/02/2025-22:38:53] [I] === Device Information ===\n",
    "[02/02/2025-22:38:53] [I] Available Devices:\n",
    "[02/02/2025-22:38:53] [I]   Device 0: \"NVIDIA GeForce RTX 4050 Laptop GPU\" UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-22:38:53] [I] Selected Device: NVIDIA GeForce RTX 4050 Laptop GPU\n",
    "[02/02/2025-22:38:53] [I] Selected Device ID: 0\n",
    "[02/02/2025-22:38:53] [I] Selected Device UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-22:38:53] [I] Compute Capability: 8.9\n",
    "[02/02/2025-22:38:53] [I] SMs: 20\n",
    "[02/02/2025-22:38:53] [I] Device Global Memory: 6140 MiB\n",
    "[02/02/2025-22:38:53] [I] Shared Memory per SM: 100 KiB\n",
    "[02/02/2025-22:38:53] [I] Memory Bus Width: 96 bits (ECC disabled)\n",
    "[02/02/2025-22:38:53] [I] Application Compute Clock Rate: 2.355 GHz\n",
    "[02/02/2025-22:38:53] [I] Application Memory Clock Rate: 7.825 GHz\n",
    "[02/02/2025-22:38:53] [I]\n",
    "[02/02/2025-22:38:53] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
    "[02/02/2025-22:38:53] [I]\n",
    "[02/02/2025-22:38:53] [I] TensorRT version: 10.1.0\n",
    "[02/02/2025-22:38:53] [I] Loading standard plugins\n",
    "[02/02/2025-22:38:54] [I] [TRT] [MemUsageChange] Init CUDA: CPU +14, GPU +0, now: CPU 24, GPU 1065 (MiB)\n",
    "[02/02/2025-22:38:56] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1659, GPU +292, now: CPU 1830, GPU 1357 (MiB)\n",
    "[02/02/2025-22:38:56] [I] Start parsing network model.\n",
    "[02/02/2025-22:38:58] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-22:38:58] [I] [TRT] Input filename:   runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-22:38:58] [I] [TRT] ONNX IR version:  0.0.10\n",
    "[02/02/2025-22:38:58] [I] [TRT] Opset version:    13\n",
    "[02/02/2025-22:38:58] [I] [TRT] Producer name:    pytorch\n",
    "[02/02/2025-22:38:58] [I] [TRT] Producer version: 2.5.1\n",
    "[02/02/2025-22:38:58] [I] [TRT] Domain:\n",
    "[02/02/2025-22:38:58] [I] [TRT] Model version:    0\n",
    "[02/02/2025-22:38:58] [I] [TRT] Doc string:\n",
    "[02/02/2025-22:38:58] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-22:38:58] [I] Finished parsing network model. Parse time: 1.59801\n",
    "[02/02/2025-22:38:58] [I] Set shape of input tensor images for optimization profile 0 to: MIN=1x3x640x640 OPT=8x3x640x640 MAX=8x3x640x640\n",
    "[02/02/2025-22:38:58] [W] [TRT] Calibrator won't be used in explicit quantization mode. Please insert Quantize/Dequantize layers to indicate which tensors to quantize/dequantize.\n",
    "[02/02/2025-22:38:58] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
    "[02/02/2025-22:47:01] [I] [TRT] Detected 1 inputs and 6 output network tensors.\n",
    "[02/02/2025-22:47:15] [I] [TRT] Total Host Persistent Memory: 1307168\n",
    "[02/02/2025-22:47:15] [I] [TRT] Total Device Persistent Memory: 56320\n",
    "[02/02/2025-22:47:15] [I] [TRT] Total Scratch Memory: 0\n",
    "[02/02/2025-22:47:15] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 386 steps to complete.\n",
    "[02/02/2025-22:47:15] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 49.0361ms to assign 14 blocks to 386 nodes requiring 417074688 bytes.\n",
    "[02/02/2025-22:47:15] [I] [TRT] Total Activation Memory: 417074176\n",
    "[02/02/2025-22:47:15] [I] [TRT] Total Weights Memory: 52563968\n",
    "[02/02/2025-22:47:16] [I] [TRT] Engine generation completed in 497.536 seconds.\n",
    "[02/02/2025-22:47:16] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 301 MiB\n",
    "[02/02/2025-22:47:16] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3005 MiB\n",
    "[02/02/2025-22:47:16] [I] Engine built in 498.325 sec.\n",
    "[02/02/2025-22:47:16] [I] Created engine with size: 58.1702 MiB\n",
    "[02/02/2025-22:47:17] [I] [TRT] Loaded engine size: 58 MiB\n",
    "[02/02/2025-22:47:17] [I] Engine deserialized in 0.419651 sec.\n",
    "[02/02/2025-22:47:17] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +397, now: CPU 2, GPU 447 (MiB)\n",
    "[02/02/2025-22:47:17] [I] Setting persistentCacheLimit to 0 bytes.\n",
    "[02/02/2025-22:47:17] [I] Set shape of input tensor images to: 8x3x640x640\n",
    "[02/02/2025-22:47:17] [I] Created execution context with device memory size: 397.753 MiB\n",
    "[02/02/2025-22:47:17] [I] Using random values for input images\n",
    "[02/02/2025-22:47:17] [I] Input binding for images with dimensions 8x3x640x640 is created.\n",
    "[02/02/2025-22:47:17] [I] Output binding for output0 with dimensions 8x12x8400 is created.\n",
    "[02/02/2025-22:47:17] [I] Output binding for 4518 with dimensions 8x12x8400 is created.\n",
    "[02/02/2025-22:47:17] [I] Starting inference\n",
    "[02/02/2025-22:47:17] [I] Capturing CUDA graph for the current execution context\n",
    "[02/02/2025-22:47:18] [I] Successfully captured CUDA graph for the current execution context\n",
    "[02/02/2025-22:47:21] [I] Warmup completed 0 queries over 200 ms\n",
    "[02/02/2025-22:47:21] [I] Timing trace has 60 queries over 2.96453 s\n",
    "[02/02/2025-22:47:21] [I]\n",
    "[02/02/2025-22:47:21] [I] === Trace details ===\n",
    "[02/02/2025-22:47:21] [I] Trace averages of 10 runs:\n",
    "[02/02/2025-22:47:21] [I] Average on 10 runs - GPU latency: 46.0249 ms - Host latency: 49.6183 ms (enqueue 0.135452 ms)\n",
    "[02/02/2025-22:47:21] [I] Average on 10 runs - GPU latency: 45.5175 ms - Host latency: 49.0723 ms (enqueue 0.0948914 ms)\n",
    "[02/02/2025-22:47:21] [I] Average on 10 runs - GPU latency: 45.5245 ms - Host latency: 49.1127 ms (enqueue 0.111377 ms)\n",
    "[02/02/2025-22:47:21] [I] Average on 10 runs - GPU latency: 45.6276 ms - Host latency: 49.1858 ms (enqueue 0.0833862 ms)\n",
    "[02/02/2025-22:47:21] [I] Average on 10 runs - GPU latency: 45.6246 ms - Host latency: 49.2062 ms (enqueue 0.134375 ms)\n",
    "[02/02/2025-22:47:21] [I] Average on 10 runs - GPU latency: 45.6226 ms - Host latency: 49.2076 ms (enqueue 0.110205 ms)\n",
    "[02/02/2025-22:47:21] [I]\n",
    "[02/02/2025-22:47:21] [I] === Performance summary ===\n",
    "[02/02/2025-22:47:21] [I] Throughput: 20.2393 qps\n",
    "[02/02/2025-22:47:21] [I] Latency: min = 49.0367 ms, max = 50.9319 ms, mean = 49.2338 ms, median = 49.1551 ms, percentile(90%) = 49.2378 ms, percentile(95%) = 49.2554 ms, percentile(99%) = 50.9319 ms\n",
    "[02/02/2025-22:47:21] [I] Enqueue Time: min = 0.0470581 ms, max = 0.485352 ms, mean = 0.111614 ms, median = 0.0922852 ms, percentile(90%) = 0.158691 ms, percentile(95%) = 0.199951 ms, percentile(99%) = 0.485352 ms\n",
    "[02/02/2025-22:47:21] [I] H2D Latency: min = 3.0188 ms, max = 3.13257 ms, mean = 3.07547 ms, median = 3.07944 ms, percentile(90%) = 3.10376 ms, percentile(95%) = 3.11743 ms, percentile(99%) = 3.13257 ms\n",
    "[02/02/2025-22:47:21] [I] GPU Compute Time: min = 45.4707 ms, max = 47.276 ms, mean = 45.6569 ms, median = 45.6094 ms, percentile(90%) = 45.6396 ms, percentile(95%) = 45.6477 ms, percentile(99%) = 47.276 ms\n",
    "[02/02/2025-22:47:21] [I] D2H Latency: min = 0.495117 ms, max = 0.639862 ms, mean = 0.50141 ms, median = 0.496582 ms, percentile(90%) = 0.512695 ms, percentile(95%) = 0.515625 ms, percentile(99%) = 0.639862 ms\n",
    "[02/02/2025-22:47:21] [I] Total Host Walltime: 2.96453 s\n",
    "[02/02/2025-22:47:21] [I] Total GPU Compute Time: 2.73942 s\n",
    "[02/02/2025-22:47:21] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
    "[02/02/2025-22:47:21] [I]\n",
    "&&&& PASSED TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:8x3x640x640 --maxShapes=images:8x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs8.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>===================================================================</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = #FF79BC> Batch Size = 12</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "\n",
    " /usr/src/tensorrt/bin/trtexec \\\n",
    "  --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    "  --int8 --fp16  \\\n",
    "  --useCudaGraph \\\n",
    "  --minShapes=images:1x3x640x640 \\\n",
    "  --optShapes=images:12x3x640x640 \\\n",
    "  --maxShapes=images:12x3x640x640 \\\n",
    "  --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs12.engine\n",
    "  \n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Result</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(torch-3.10) user_pzj@DESKTOP-20USVPU:/mnt/c/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main$  /usr/src/tensorrt/bin/trtexec \\\n",
    ">   --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    ">   --int8 --fp16  \\\n",
    ">   --useCudaGraph \\\n",
    ">   --minShapes=images:1x3x640x640 \\\n",
    ">   --optShapes=images:12x3x640x640 \\\n",
    ">   --maxShapes=images:12x3x640x640 \\\n",
    ">   --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs12.engine\n",
    "&&&& RUNNING TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:12x3x640x640 --maxShapes=images:12x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs12.engine\n",
    "[02/02/2025-22:48:20] [I] === Model Options ===\n",
    "[02/02/2025-22:48:20] [I] Format: ONNX\n",
    "[02/02/2025-22:48:20] [I] Model: runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-22:48:20] [I] Output:\n",
    "[02/02/2025-22:48:20] [I] === Build Options ===\n",
    "[02/02/2025-22:48:20] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
    "[02/02/2025-22:48:20] [I] avgTiming: 8\n",
    "[02/02/2025-22:48:20] [I] Precision: FP32+FP16+INT8\n",
    "[02/02/2025-22:48:20] [I] LayerPrecisions:\n",
    "[02/02/2025-22:48:20] [I] Layer Device Types:\n",
    "[02/02/2025-22:48:20] [I] Calibration: Dynamic\n",
    "[02/02/2025-22:48:20] [I] Refit: Disabled\n",
    "[02/02/2025-22:48:20] [I] Strip weights: Disabled\n",
    "[02/02/2025-22:48:20] [I] Version Compatible: Disabled\n",
    "[02/02/2025-22:48:20] [I] ONNX Plugin InstanceNorm: Disabled\n",
    "[02/02/2025-22:48:20] [I] TensorRT runtime: full\n",
    "[02/02/2025-22:48:20] [I] Lean DLL Path:\n",
    "[02/02/2025-22:48:20] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
    "[02/02/2025-22:48:20] [I] Exclude Lean Runtime: Disabled\n",
    "[02/02/2025-22:48:20] [I] Sparsity: Disabled\n",
    "[02/02/2025-22:48:20] [I] Safe mode: Disabled\n",
    "[02/02/2025-22:48:20] [I] Build DLA standalone loadable: Disabled\n",
    "[02/02/2025-22:48:20] [I] Allow GPU fallback for DLA: Disabled\n",
    "[02/02/2025-22:48:20] [I] DirectIO mode: Disabled\n",
    "[02/02/2025-22:48:20] [I] Restricted mode: Disabled\n",
    "[02/02/2025-22:48:20] [I] Skip inference: Disabled\n",
    "[02/02/2025-22:48:20] [I] Save engine: runs/qat/qat_yolov9/weights/qat_best_best_bs12.engine\n",
    "[02/02/2025-22:48:20] [I] Load engine:\n",
    "[02/02/2025-22:48:20] [I] Profiling verbosity: 0\n",
    "[02/02/2025-22:48:20] [I] Tactic sources: Using default tactic sources\n",
    "[02/02/2025-22:48:20] [I] timingCacheMode: local\n",
    "[02/02/2025-22:48:20] [I] timingCacheFile:\n",
    "[02/02/2025-22:48:20] [I] Enable Compilation Cache: Enabled\n",
    "[02/02/2025-22:48:20] [I] errorOnTimingCacheMiss: Disabled\n",
    "[02/02/2025-22:48:20] [I] Preview Features: Use default preview flags.\n",
    "[02/02/2025-22:48:20] [I] MaxAuxStreams: -1\n",
    "[02/02/2025-22:48:20] [I] BuilderOptimizationLevel: -1\n",
    "[02/02/2025-22:48:20] [I] Calibration Profile Index: 0\n",
    "[02/02/2025-22:48:20] [I] Weight Streaming: Disabled\n",
    "[02/02/2025-22:48:20] [I] Debug Tensors:\n",
    "[02/02/2025-22:48:20] [I] Input(s)s format: fp32:CHW\n",
    "[02/02/2025-22:48:20] [I] Output(s)s format: fp32:CHW\n",
    "[02/02/2025-22:48:20] [I] Input build shape (profile 0): images=1x3x640x640+12x3x640x640+12x3x640x640\n",
    "[02/02/2025-22:48:20] [I] Input calibration shapes: model\n",
    "[02/02/2025-22:48:20] [I] === System Options ===\n",
    "[02/02/2025-22:48:20] [I] Device: 0\n",
    "[02/02/2025-22:48:20] [I] DLACore:\n",
    "[02/02/2025-22:48:20] [I] Plugins:\n",
    "[02/02/2025-22:48:20] [I] setPluginsToSerialize:\n",
    "[02/02/2025-22:48:20] [I] dynamicPlugins:\n",
    "[02/02/2025-22:48:20] [I] ignoreParsedPluginLibs: 0\n",
    "[02/02/2025-22:48:20] [I]\n",
    "[02/02/2025-22:48:20] [I] === Inference Options ===\n",
    "[02/02/2025-22:48:20] [I] Batch: Explicit\n",
    "[02/02/2025-22:48:20] [I] Input inference shape : images=12x3x640x640\n",
    "[02/02/2025-22:48:20] [I] Iterations: 10\n",
    "[02/02/2025-22:48:20] [I] Duration: 3s (+ 200ms warm up)\n",
    "[02/02/2025-22:48:20] [I] Sleep time: 0ms\n",
    "[02/02/2025-22:48:20] [I] Idle time: 0ms\n",
    "[02/02/2025-22:48:20] [I] Inference Streams: 1\n",
    "[02/02/2025-22:48:20] [I] ExposeDMA: Disabled\n",
    "[02/02/2025-22:48:20] [I] Data transfers: Enabled\n",
    "[02/02/2025-22:48:20] [I] Spin-wait: Disabled\n",
    "[02/02/2025-22:48:20] [I] Multithreading: Disabled\n",
    "[02/02/2025-22:48:20] [I] CUDA Graph: Enabled\n",
    "[02/02/2025-22:48:20] [I] Separate profiling: Disabled\n",
    "[02/02/2025-22:48:20] [I] Time Deserialize: Disabled\n",
    "[02/02/2025-22:48:20] [I] Time Refit: Disabled\n",
    "[02/02/2025-22:48:20] [I] NVTX verbosity: 0\n",
    "[02/02/2025-22:48:20] [I] Persistent Cache Ratio: 0\n",
    "[02/02/2025-22:48:20] [I] Optimization Profile Index: 0\n",
    "[02/02/2025-22:48:20] [I] Weight Streaming Budget: 100.000000%\n",
    "[02/02/2025-22:48:20] [I] Inputs:\n",
    "[02/02/2025-22:48:20] [I] Debug Tensor Save Destinations:\n",
    "[02/02/2025-22:48:20] [I] === Reporting Options ===\n",
    "[02/02/2025-22:48:20] [I] Verbose: Disabled\n",
    "[02/02/2025-22:48:20] [I] Averages: 10 inferences\n",
    "[02/02/2025-22:48:20] [I] Percentiles: 90,95,99\n",
    "[02/02/2025-22:48:20] [I] Dump refittable layers:Disabled\n",
    "[02/02/2025-22:48:20] [I] Dump output: Disabled\n",
    "[02/02/2025-22:48:20] [I] Profile: Disabled\n",
    "[02/02/2025-22:48:20] [I] Export timing to JSON file:\n",
    "[02/02/2025-22:48:20] [I] Export output to JSON file:\n",
    "[02/02/2025-22:48:20] [I] Export profile to JSON file:\n",
    "[02/02/2025-22:48:20] [I]\n",
    "[02/02/2025-22:48:20] [I] === Device Information ===\n",
    "[02/02/2025-22:48:21] [I] Available Devices:\n",
    "[02/02/2025-22:48:21] [I]   Device 0: \"NVIDIA GeForce RTX 4050 Laptop GPU\" UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-22:48:21] [I] Selected Device: NVIDIA GeForce RTX 4050 Laptop GPU\n",
    "[02/02/2025-22:48:21] [I] Selected Device ID: 0\n",
    "[02/02/2025-22:48:21] [I] Selected Device UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-22:48:21] [I] Compute Capability: 8.9\n",
    "[02/02/2025-22:48:21] [I] SMs: 20\n",
    "[02/02/2025-22:48:21] [I] Device Global Memory: 6140 MiB\n",
    "[02/02/2025-22:48:21] [I] Shared Memory per SM: 100 KiB\n",
    "[02/02/2025-22:48:21] [I] Memory Bus Width: 96 bits (ECC disabled)\n",
    "[02/02/2025-22:48:21] [I] Application Compute Clock Rate: 2.355 GHz\n",
    "[02/02/2025-22:48:21] [I] Application Memory Clock Rate: 7.825 GHz\n",
    "[02/02/2025-22:48:21] [I]\n",
    "[02/02/2025-22:48:21] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
    "[02/02/2025-22:48:21] [I]\n",
    "[02/02/2025-22:48:21] [I] TensorRT version: 10.1.0\n",
    "[02/02/2025-22:48:21] [I] Loading standard plugins\n",
    "[02/02/2025-22:48:21] [I] [TRT] [MemUsageChange] Init CUDA: CPU +14, GPU +0, now: CPU 24, GPU 1065 (MiB)\n",
    "[02/02/2025-22:48:24] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1659, GPU +292, now: CPU 1830, GPU 1357 (MiB)\n",
    "[02/02/2025-22:48:24] [I] Start parsing network model.\n",
    "[02/02/2025-22:48:26] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-22:48:26] [I] [TRT] Input filename:   runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-22:48:26] [I] [TRT] ONNX IR version:  0.0.10\n",
    "[02/02/2025-22:48:26] [I] [TRT] Opset version:    13\n",
    "[02/02/2025-22:48:26] [I] [TRT] Producer name:    pytorch\n",
    "[02/02/2025-22:48:26] [I] [TRT] Producer version: 2.5.1\n",
    "[02/02/2025-22:48:26] [I] [TRT] Domain:\n",
    "[02/02/2025-22:48:26] [I] [TRT] Model version:    0\n",
    "[02/02/2025-22:48:26] [I] [TRT] Doc string:\n",
    "[02/02/2025-22:48:26] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-22:48:26] [I] Finished parsing network model. Parse time: 2.41537\n",
    "[02/02/2025-22:48:26] [I] Set shape of input tensor images for optimization profile 0 to: MIN=1x3x640x640 OPT=12x3x640x640 MAX=12x3x640x640\n",
    "[02/02/2025-22:48:26] [W] [TRT] Calibrator won't be used in explicit quantization mode. Please insert Quantize/Dequantize layers to indicate which tensors to quantize/dequantize.\n",
    "[02/02/2025-22:48:27] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
    "[02/02/2025-22:56:56] [I] [TRT] Detected 1 inputs and 6 output network tensors.\n",
    "[02/02/2025-22:57:10] [I] [TRT] Total Host Persistent Memory: 1312368\n",
    "[02/02/2025-22:57:10] [I] [TRT] Total Device Persistent Memory: 56320\n",
    "[02/02/2025-22:57:10] [I] [TRT] Total Scratch Memory: 0\n",
    "[02/02/2025-22:57:10] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 393 steps to complete.\n",
    "[02/02/2025-22:57:10] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 46.4872ms to assign 13 blocks to 393 nodes requiring 615831040 bytes.\n",
    "[02/02/2025-22:57:10] [I] [TRT] Total Activation Memory: 615831040\n",
    "[02/02/2025-22:57:10] [I] [TRT] Total Weights Memory: 52561408\n",
    "[02/02/2025-22:57:10] [I] [TRT] Engine generation completed in 523.171 seconds.\n",
    "[02/02/2025-22:57:10] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 451 MiB\n",
    "[02/02/2025-22:57:10] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3006 MiB\n",
    "[02/02/2025-22:57:10] [I] Engine built in 523.95 sec.\n",
    "[02/02/2025-22:57:10] [I] Created engine with size: 57.9779 MiB\n",
    "[02/02/2025-22:57:11] [I] [TRT] Loaded engine size: 57 MiB\n",
    "[02/02/2025-22:57:11] [I] Engine deserialized in 0.394929 sec.\n",
    "[02/02/2025-22:57:12] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +587, now: CPU 2, GPU 637 (MiB)\n",
    "[02/02/2025-22:57:12] [I] Setting persistentCacheLimit to 0 bytes.\n",
    "[02/02/2025-22:57:12] [I] Set shape of input tensor images to: 12x3x640x640\n",
    "[02/02/2025-22:57:12] [I] Created execution context with device memory size: 587.302 MiB\n",
    "[02/02/2025-22:57:12] [I] Using random values for input images\n",
    "[02/02/2025-22:57:12] [I] Input binding for images with dimensions 12x3x640x640 is created.\n",
    "[02/02/2025-22:57:12] [I] Output binding for output0 with dimensions 12x12x8400 is created.\n",
    "[02/02/2025-22:57:12] [I] Output binding for 4518 with dimensions 12x12x8400 is created.\n",
    "[02/02/2025-22:57:12] [I] Starting inference\n",
    "[02/02/2025-22:57:12] [I] Capturing CUDA graph for the current execution context\n",
    "[02/02/2025-22:57:12] [I] Successfully captured CUDA graph for the current execution context\n",
    "[02/02/2025-22:57:15] [I] Warmup completed 0 queries over 200 ms\n",
    "[02/02/2025-22:57:15] [I] Timing trace has 40 queries over 3.02146 s\n",
    "[02/02/2025-22:57:15] [I]\n",
    "[02/02/2025-22:57:15] [I] === Trace details ===\n",
    "[02/02/2025-22:57:15] [I] Trace averages of 10 runs:\n",
    "[02/02/2025-22:57:15] [I] Average on 10 runs - GPU latency: 70.2197 ms - Host latency: 75.578 ms (enqueue 0.111853 ms)\n",
    "[02/02/2025-22:57:15] [I] Average on 10 runs - GPU latency: 69.8534 ms - Host latency: 75.1862 ms (enqueue 0.0808105 ms)\n",
    "[02/02/2025-22:57:15] [I] Average on 10 runs - GPU latency: 69.9911 ms - Host latency: 75.3379 ms (enqueue 0.104248 ms)\n",
    "[02/02/2025-22:57:15] [I] Average on 10 runs - GPU latency: 70.0156 ms - Host latency: 75.3624 ms (enqueue 0.0837891 ms)\n",
    "[02/02/2025-22:57:15] [I]\n",
    "[02/02/2025-22:57:15] [I] === Performance summary ===\n",
    "[02/02/2025-22:57:15] [I] Throughput: 13.2386 qps\n",
    "[02/02/2025-22:57:15] [I] Latency: min = 75.0947 ms, max = 77.7342 ms, mean = 75.3661 ms, median = 75.2736 ms, percentile(90%) = 75.3911 ms, percentile(95%) = 75.4097 ms, percentile(99%) = 77.7342 ms\n",
    "[02/02/2025-22:57:15] [I] Enqueue Time: min = 0.0456848 ms, max = 0.409454 ms, mean = 0.0951752 ms, median = 0.0687866 ms, percentile(90%) = 0.154297 ms, percentile(95%) = 0.174561 ms, percentile(99%) = 0.409454 ms\n",
    "[02/02/2025-22:57:15] [I] H2D Latency: min = 4.51971 ms, max = 4.68417 ms, mean = 4.60285 ms, median = 4.60938 ms, percentile(90%) = 4.6377 ms, percentile(95%) = 4.64478 ms, percentile(99%) = 4.68417 ms\n",
    "[02/02/2025-22:57:15] [I] GPU Compute Time: min = 69.7917 ms, max = 72.2617 ms, mean = 70.0199 ms, median = 69.977 ms, percentile(90%) = 70.0251 ms, percentile(95%) = 70.0283 ms, percentile(99%) = 72.2617 ms\n",
    "[02/02/2025-22:57:15] [I] D2H Latency: min = 0.739502 ms, max = 0.78833 ms, mean = 0.743293 ms, median = 0.740845 ms, percentile(90%) = 0.745361 ms, percentile(95%) = 0.750977 ms, percentile(99%) = 0.78833 ms\n",
    "[02/02/2025-22:57:15] [I] Total Host Walltime: 3.02146 s\n",
    "[02/02/2025-22:57:15] [I] Total GPU Compute Time: 2.8008 s\n",
    "[02/02/2025-22:57:15] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
    "[02/02/2025-22:57:15] [I]\n",
    "&&&& PASSED TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:12x3x640x640 --maxShapes=images:12x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs12.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>===================================================================</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = #FF79BC> Batch Size = 16</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "\n",
    " /usr/src/tensorrt/bin/trtexec \\\n",
    "  --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    "  --int8 --fp16  \\\n",
    "  --useCudaGraph \\\n",
    "  --minShapes=images:1x3x640x640 \\\n",
    "  --optShapes=images:16x3x640x640 \\\n",
    "  --maxShapes=images:16x3x640x640 \\\n",
    "  --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs16.engine\n",
    "  \n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Result</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(torch-3.10) user_pzj@DESKTOP-20USVPU:/mnt/c/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main$  /usr/src/tensorrt/bin/trtexec \\\n",
    ">   --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    ">   --int8 --fp16  \\\n",
    ">   --useCudaGraph \\\n",
    ">   --minShapes=images:1x3x640x640 \\\n",
    ">   --optShapes=images:16x3x640x640 \\\n",
    ">   --maxShapes=images:16x3x640x640 \\\n",
    ">   --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs16.engine\n",
    "&&&& RUNNING TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:16x3x640x640 --maxShapes=images:16x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs16.engine\n",
    "[02/02/2025-23:01:12] [I] === Model Options ===\n",
    "[02/02/2025-23:01:12] [I] Format: ONNX\n",
    "[02/02/2025-23:01:12] [I] Model: runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-23:01:12] [I] Output:\n",
    "[02/02/2025-23:01:12] [I] === Build Options ===\n",
    "[02/02/2025-23:01:12] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
    "[02/02/2025-23:01:12] [I] avgTiming: 8\n",
    "[02/02/2025-23:01:12] [I] Precision: FP32+FP16+INT8\n",
    "[02/02/2025-23:01:12] [I] LayerPrecisions:\n",
    "[02/02/2025-23:01:12] [I] Layer Device Types:\n",
    "[02/02/2025-23:01:12] [I] Calibration: Dynamic\n",
    "[02/02/2025-23:01:12] [I] Refit: Disabled\n",
    "[02/02/2025-23:01:12] [I] Strip weights: Disabled\n",
    "[02/02/2025-23:01:12] [I] Version Compatible: Disabled\n",
    "[02/02/2025-23:01:12] [I] ONNX Plugin InstanceNorm: Disabled\n",
    "[02/02/2025-23:01:12] [I] TensorRT runtime: full\n",
    "[02/02/2025-23:01:12] [I] Lean DLL Path:\n",
    "[02/02/2025-23:01:12] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
    "[02/02/2025-23:01:12] [I] Exclude Lean Runtime: Disabled\n",
    "[02/02/2025-23:01:12] [I] Sparsity: Disabled\n",
    "[02/02/2025-23:01:12] [I] Safe mode: Disabled\n",
    "[02/02/2025-23:01:12] [I] Build DLA standalone loadable: Disabled\n",
    "[02/02/2025-23:01:12] [I] Allow GPU fallback for DLA: Disabled\n",
    "[02/02/2025-23:01:12] [I] DirectIO mode: Disabled\n",
    "[02/02/2025-23:01:12] [I] Restricted mode: Disabled\n",
    "[02/02/2025-23:01:12] [I] Skip inference: Disabled\n",
    "[02/02/2025-23:01:12] [I] Save engine: runs/qat/qat_yolov9/weights/qat_best_best_bs16.engine\n",
    "[02/02/2025-23:01:12] [I] Load engine:\n",
    "[02/02/2025-23:01:12] [I] Profiling verbosity: 0\n",
    "[02/02/2025-23:01:12] [I] Tactic sources: Using default tactic sources\n",
    "[02/02/2025-23:01:12] [I] timingCacheMode: local\n",
    "[02/02/2025-23:01:12] [I] timingCacheFile:\n",
    "[02/02/2025-23:01:12] [I] Enable Compilation Cache: Enabled\n",
    "[02/02/2025-23:01:12] [I] errorOnTimingCacheMiss: Disabled\n",
    "[02/02/2025-23:01:12] [I] Preview Features: Use default preview flags.\n",
    "[02/02/2025-23:01:12] [I] MaxAuxStreams: -1\n",
    "[02/02/2025-23:01:12] [I] BuilderOptimizationLevel: -1\n",
    "[02/02/2025-23:01:12] [I] Calibration Profile Index: 0\n",
    "[02/02/2025-23:01:12] [I] Weight Streaming: Disabled\n",
    "[02/02/2025-23:01:12] [I] Debug Tensors:\n",
    "[02/02/2025-23:01:12] [I] Input(s)s format: fp32:CHW\n",
    "[02/02/2025-23:01:12] [I] Output(s)s format: fp32:CHW\n",
    "[02/02/2025-23:01:12] [I] Input build shape (profile 0): images=1x3x640x640+16x3x640x640+16x3x640x640\n",
    "[02/02/2025-23:01:12] [I] Input calibration shapes: model\n",
    "[02/02/2025-23:01:12] [I] === System Options ===\n",
    "[02/02/2025-23:01:12] [I] Device: 0\n",
    "[02/02/2025-23:01:12] [I] DLACore:\n",
    "[02/02/2025-23:01:12] [I] Plugins:\n",
    "[02/02/2025-23:01:12] [I] setPluginsToSerialize:\n",
    "[02/02/2025-23:01:12] [I] dynamicPlugins:\n",
    "[02/02/2025-23:01:12] [I] ignoreParsedPluginLibs: 0\n",
    "[02/02/2025-23:01:12] [I]\n",
    "[02/02/2025-23:01:12] [I] === Inference Options ===\n",
    "[02/02/2025-23:01:12] [I] Batch: Explicit\n",
    "[02/02/2025-23:01:12] [I] Input inference shape : images=16x3x640x640\n",
    "[02/02/2025-23:01:12] [I] Iterations: 10\n",
    "[02/02/2025-23:01:12] [I] Duration: 3s (+ 200ms warm up)\n",
    "[02/02/2025-23:01:12] [I] Sleep time: 0ms\n",
    "[02/02/2025-23:01:12] [I] Idle time: 0ms\n",
    "[02/02/2025-23:01:12] [I] Inference Streams: 1\n",
    "[02/02/2025-23:01:12] [I] ExposeDMA: Disabled\n",
    "[02/02/2025-23:01:12] [I] Data transfers: Enabled\n",
    "[02/02/2025-23:01:12] [I] Spin-wait: Disabled\n",
    "[02/02/2025-23:01:12] [I] Multithreading: Disabled\n",
    "[02/02/2025-23:01:12] [I] CUDA Graph: Enabled\n",
    "[02/02/2025-23:01:12] [I] Separate profiling: Disabled\n",
    "[02/02/2025-23:01:12] [I] Time Deserialize: Disabled\n",
    "[02/02/2025-23:01:12] [I] Time Refit: Disabled\n",
    "[02/02/2025-23:01:12] [I] NVTX verbosity: 0\n",
    "[02/02/2025-23:01:12] [I] Persistent Cache Ratio: 0\n",
    "[02/02/2025-23:01:12] [I] Optimization Profile Index: 0\n",
    "[02/02/2025-23:01:12] [I] Weight Streaming Budget: 100.000000%\n",
    "[02/02/2025-23:01:12] [I] Inputs:\n",
    "[02/02/2025-23:01:12] [I] Debug Tensor Save Destinations:\n",
    "[02/02/2025-23:01:12] [I] === Reporting Options ===\n",
    "[02/02/2025-23:01:12] [I] Verbose: Disabled\n",
    "[02/02/2025-23:01:12] [I] Averages: 10 inferences\n",
    "[02/02/2025-23:01:12] [I] Percentiles: 90,95,99\n",
    "[02/02/2025-23:01:12] [I] Dump refittable layers:Disabled\n",
    "[02/02/2025-23:01:12] [I] Dump output: Disabled\n",
    "[02/02/2025-23:01:12] [I] Profile: Disabled\n",
    "[02/02/2025-23:01:12] [I] Export timing to JSON file:\n",
    "[02/02/2025-23:01:12] [I] Export output to JSON file:\n",
    "[02/02/2025-23:01:12] [I] Export profile to JSON file:\n",
    "[02/02/2025-23:01:12] [I]\n",
    "[02/02/2025-23:01:12] [I] === Device Information ===\n",
    "[02/02/2025-23:01:12] [I] Available Devices:\n",
    "[02/02/2025-23:01:12] [I]   Device 0: \"NVIDIA GeForce RTX 4050 Laptop GPU\" UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-23:01:12] [I] Selected Device: NVIDIA GeForce RTX 4050 Laptop GPU\n",
    "[02/02/2025-23:01:12] [I] Selected Device ID: 0\n",
    "[02/02/2025-23:01:12] [I] Selected Device UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-23:01:12] [I] Compute Capability: 8.9\n",
    "[02/02/2025-23:01:12] [I] SMs: 20\n",
    "[02/02/2025-23:01:12] [I] Device Global Memory: 6140 MiB\n",
    "[02/02/2025-23:01:12] [I] Shared Memory per SM: 100 KiB\n",
    "[02/02/2025-23:01:12] [I] Memory Bus Width: 96 bits (ECC disabled)\n",
    "[02/02/2025-23:01:12] [I] Application Compute Clock Rate: 2.355 GHz\n",
    "[02/02/2025-23:01:12] [I] Application Memory Clock Rate: 7.825 GHz\n",
    "[02/02/2025-23:01:12] [I]\n",
    "[02/02/2025-23:01:12] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
    "[02/02/2025-23:01:12] [I]\n",
    "[02/02/2025-23:01:12] [I] TensorRT version: 10.1.0\n",
    "[02/02/2025-23:01:12] [I] Loading standard plugins\n",
    "[02/02/2025-23:01:12] [I] [TRT] [MemUsageChange] Init CUDA: CPU +14, GPU +0, now: CPU 24, GPU 1065 (MiB)\n",
    "[02/02/2025-23:01:15] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1659, GPU +292, now: CPU 1830, GPU 1357 (MiB)\n",
    "[02/02/2025-23:01:15] [I] Start parsing network model.\n",
    "[02/02/2025-23:01:16] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-23:01:16] [I] [TRT] Input filename:   runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-23:01:16] [I] [TRT] ONNX IR version:  0.0.10\n",
    "[02/02/2025-23:01:16] [I] [TRT] Opset version:    13\n",
    "[02/02/2025-23:01:16] [I] [TRT] Producer name:    pytorch\n",
    "[02/02/2025-23:01:16] [I] [TRT] Producer version: 2.5.1\n",
    "[02/02/2025-23:01:16] [I] [TRT] Domain:\n",
    "[02/02/2025-23:01:16] [I] [TRT] Model version:    0\n",
    "[02/02/2025-23:01:16] [I] [TRT] Doc string:\n",
    "[02/02/2025-23:01:16] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-23:01:16] [I] Finished parsing network model. Parse time: 1.77325\n",
    "[02/02/2025-23:01:16] [I] Set shape of input tensor images for optimization profile 0 to: MIN=1x3x640x640 OPT=16x3x640x640 MAX=16x3x640x640\n",
    "[02/02/2025-23:01:17] [W] [TRT] Calibrator won't be used in explicit quantization mode. Please insert Quantize/Dequantize layers to indicate which tensors to quantize/dequantize.\n",
    "[02/02/2025-23:01:17] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
    "[02/02/2025-23:10:31] [I] [TRT] Detected 1 inputs and 6 output network tensors.\n",
    "[02/02/2025-23:10:46] [I] [TRT] Total Host Persistent Memory: 1310560\n",
    "[02/02/2025-23:10:46] [I] [TRT] Total Device Persistent Memory: 56320\n",
    "[02/02/2025-23:10:46] [I] [TRT] Total Scratch Memory: 0\n",
    "[02/02/2025-23:10:46] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 398 steps to complete.\n",
    "[02/02/2025-23:10:46] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 45.4312ms to assign 13 blocks to 398 nodes requiring 821040640 bytes.\n",
    "[02/02/2025-23:10:46] [I] [TRT] Total Activation Memory: 821040640\n",
    "[02/02/2025-23:10:46] [I] [TRT] Total Weights Memory: 52561408\n",
    "[02/02/2025-23:10:46] [I] [TRT] Engine generation completed in 569.396 seconds.\n",
    "[02/02/2025-23:10:46] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 601 MiB\n",
    "[02/02/2025-23:10:47] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3023 MiB\n",
    "[02/02/2025-23:10:47] [I] Engine built in 570.161 sec.\n",
    "[02/02/2025-23:10:47] [I] Created engine with size: 57.8776 MiB\n",
    "[02/02/2025-23:10:48] [I] [TRT] Loaded engine size: 57 MiB\n",
    "[02/02/2025-23:10:48] [I] Engine deserialized in 0.384581 sec.\n",
    "[02/02/2025-23:10:48] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +783, now: CPU 2, GPU 833 (MiB)\n",
    "[02/02/2025-23:10:48] [I] Setting persistentCacheLimit to 0 bytes.\n",
    "[02/02/2025-23:10:48] [I] Set shape of input tensor images to: 16x3x640x640\n",
    "[02/02/2025-23:10:48] [I] Created execution context with device memory size: 783.005 MiB\n",
    "[02/02/2025-23:10:48] [I] Using random values for input images\n",
    "[02/02/2025-23:10:48] [I] Input binding for images with dimensions 16x3x640x640 is created.\n",
    "[02/02/2025-23:10:48] [I] Output binding for output0 with dimensions 16x12x8400 is created.\n",
    "[02/02/2025-23:10:48] [I] Output binding for 4518 with dimensions 16x12x8400 is created.\n",
    "[02/02/2025-23:10:48] [I] Starting inference\n",
    "[02/02/2025-23:10:48] [I] Capturing CUDA graph for the current execution context\n",
    "[02/02/2025-23:10:48] [I] Successfully captured CUDA graph for the current execution context\n",
    "[02/02/2025-23:10:52] [I] Warmup completed 1 queries over 200 ms\n",
    "[02/02/2025-23:10:52] [I] Timing trace has 32 queries over 3.25214 s\n",
    "[02/02/2025-23:10:52] [I]\n",
    "[02/02/2025-23:10:52] [I] === Trace details ===\n",
    "[02/02/2025-23:10:52] [I] Trace averages of 10 runs:\n",
    "[02/02/2025-23:10:52] [I] Average on 10 runs - GPU latency: 94.367 ms - Host latency: 101.476 ms (enqueue 0.105389 ms)\n",
    "[02/02/2025-23:10:52] [I] Average on 10 runs - GPU latency: 94.3193 ms - Host latency: 101.445 ms (enqueue 0.111597 ms)\n",
    "[02/02/2025-23:10:52] [I] Average on 10 runs - GPU latency: 94.3171 ms - Host latency: 101.433 ms (enqueue 0.088916 ms)\n",
    "[02/02/2025-23:10:52] [I]\n",
    "[02/02/2025-23:10:52] [I] === Performance summary ===\n",
    "[02/02/2025-23:10:52] [I] Throughput: 9.83966 qps\n",
    "[02/02/2025-23:10:52] [I] Latency: min = 101.13 ms, max = 103.695 ms, mean = 101.452 ms, median = 101.438 ms, percentile(90%) = 101.484 ms, percentile(95%) = 101.497 ms, percentile(99%) = 103.695 ms\n",
    "[02/02/2025-23:10:52] [I] Enqueue Time: min = 0.0618896 ms, max = 0.231323 ms, mean = 0.100386 ms, median = 0.0818787 ms, percentile(90%) = 0.174347 ms, percentile(95%) = 0.204224 ms, percentile(99%) = 0.231323 ms\n",
    "[02/02/2025-23:10:52] [I] H2D Latency: min = 6.02368 ms, max = 6.20361 ms, mean = 6.1301 ms, median = 6.13329 ms, percentile(90%) = 6.16101 ms, percentile(95%) = 6.18018 ms, percentile(99%) = 6.20361 ms\n",
    "[02/02/2025-23:10:52] [I] GPU Compute Time: min = 94.0995 ms, max = 96.5775 ms, mean = 94.3346 ms, median = 94.3109 ms, percentile(90%) = 94.3378 ms, percentile(95%) = 94.3401 ms, percentile(99%) = 96.5775 ms\n",
    "[02/02/2025-23:10:52] [I] D2H Latency: min = 0.984131 ms, max = 1.01172 ms, mean = 0.987203 ms, median = 0.985046 ms, percentile(90%) = 0.989746 ms, percentile(95%) = 1.00342 ms, percentile(99%) = 1.01172 ms\n",
    "[02/02/2025-23:10:52] [I] Total Host Walltime: 3.25214 s\n",
    "[02/02/2025-23:10:52] [I] Total GPU Compute Time: 3.01871 s\n",
    "[02/02/2025-23:10:52] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
    "[02/02/2025-23:10:52] [I]\n",
    "&&&& PASSED TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:16x3x640x640 --maxShapes=images:16x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_bs16.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>===================================================================</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = #FF79BC> More Resilience</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "\n",
    " /usr/src/tensorrt/bin/trtexec \\\n",
    "  --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    "  --int8 --fp16  \\\n",
    "  --useCudaGraph \\\n",
    "  --minShapes=images:1x3x640x640 \\\n",
    "  --optShapes=images:8x3x640x640 \\\n",
    "  --maxShapes=images:16x3x640x640 \\\n",
    "  --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_resilience.engine\n",
    "  \n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Result</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(torch-3.10) user_pzj@DESKTOP-20USVPU:/mnt/c/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main$  /usr/src/tensorrt/bin/trtexec \\\n",
    ">   --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx \\\n",
    ">   --int8 --fp16  \\\n",
    ">   --useCudaGraph \\\n",
    ">   --minShapes=images:1x3x640x640 \\\n",
    ">   --optShapes=images:8x3x640x640 \\\n",
    ">   --maxShapes=images:16x3x640x640 \\\n",
    ">   --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_resilience.engine\n",
    "&&&& RUNNING TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:8x3x640x640 --maxShapes=images:16x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_resilience.engine\n",
    "[02/02/2025-23:12:16] [I] === Model Options ===\n",
    "[02/02/2025-23:12:16] [I] Format: ONNX\n",
    "[02/02/2025-23:12:16] [I] Model: runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-23:12:16] [I] Output:\n",
    "[02/02/2025-23:12:16] [I] === Build Options ===\n",
    "[02/02/2025-23:12:16] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
    "[02/02/2025-23:12:16] [I] avgTiming: 8\n",
    "[02/02/2025-23:12:16] [I] Precision: FP32+FP16+INT8\n",
    "[02/02/2025-23:12:16] [I] LayerPrecisions:\n",
    "[02/02/2025-23:12:16] [I] Layer Device Types:\n",
    "[02/02/2025-23:12:16] [I] Calibration: Dynamic\n",
    "[02/02/2025-23:12:16] [I] Refit: Disabled\n",
    "[02/02/2025-23:12:16] [I] Strip weights: Disabled\n",
    "[02/02/2025-23:12:16] [I] Version Compatible: Disabled\n",
    "[02/02/2025-23:12:16] [I] ONNX Plugin InstanceNorm: Disabled\n",
    "[02/02/2025-23:12:16] [I] TensorRT runtime: full\n",
    "[02/02/2025-23:12:16] [I] Lean DLL Path:\n",
    "[02/02/2025-23:12:16] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
    "[02/02/2025-23:12:16] [I] Exclude Lean Runtime: Disabled\n",
    "[02/02/2025-23:12:16] [I] Sparsity: Disabled\n",
    "[02/02/2025-23:12:16] [I] Safe mode: Disabled\n",
    "[02/02/2025-23:12:16] [I] Build DLA standalone loadable: Disabled\n",
    "[02/02/2025-23:12:16] [I] Allow GPU fallback for DLA: Disabled\n",
    "[02/02/2025-23:12:16] [I] DirectIO mode: Disabled\n",
    "[02/02/2025-23:12:16] [I] Restricted mode: Disabled\n",
    "[02/02/2025-23:12:16] [I] Skip inference: Disabled\n",
    "[02/02/2025-23:12:16] [I] Save engine: runs/qat/qat_yolov9/weights/qat_best_best_resilience.engine\n",
    "[02/02/2025-23:12:16] [I] Load engine:\n",
    "[02/02/2025-23:12:16] [I] Profiling verbosity: 0\n",
    "[02/02/2025-23:12:16] [I] Tactic sources: Using default tactic sources\n",
    "[02/02/2025-23:12:16] [I] timingCacheMode: local\n",
    "[02/02/2025-23:12:16] [I] timingCacheFile:\n",
    "[02/02/2025-23:12:16] [I] Enable Compilation Cache: Enabled\n",
    "[02/02/2025-23:12:16] [I] errorOnTimingCacheMiss: Disabled\n",
    "[02/02/2025-23:12:16] [I] Preview Features: Use default preview flags.\n",
    "[02/02/2025-23:12:16] [I] MaxAuxStreams: -1\n",
    "[02/02/2025-23:12:16] [I] BuilderOptimizationLevel: -1\n",
    "[02/02/2025-23:12:16] [I] Calibration Profile Index: 0\n",
    "[02/02/2025-23:12:16] [I] Weight Streaming: Disabled\n",
    "[02/02/2025-23:12:16] [I] Debug Tensors:\n",
    "[02/02/2025-23:12:16] [I] Input(s)s format: fp32:CHW\n",
    "[02/02/2025-23:12:16] [I] Output(s)s format: fp32:CHW\n",
    "[02/02/2025-23:12:16] [I] Input build shape (profile 0): images=1x3x640x640+8x3x640x640+16x3x640x640\n",
    "[02/02/2025-23:12:16] [I] Input calibration shapes: model\n",
    "[02/02/2025-23:12:16] [I] === System Options ===\n",
    "[02/02/2025-23:12:16] [I] Device: 0\n",
    "[02/02/2025-23:12:16] [I] DLACore:\n",
    "[02/02/2025-23:12:16] [I] Plugins:\n",
    "[02/02/2025-23:12:16] [I] setPluginsToSerialize:\n",
    "[02/02/2025-23:12:16] [I] dynamicPlugins:\n",
    "[02/02/2025-23:12:16] [I] ignoreParsedPluginLibs: 0\n",
    "[02/02/2025-23:12:16] [I]\n",
    "[02/02/2025-23:12:16] [I] === Inference Options ===\n",
    "[02/02/2025-23:12:16] [I] Batch: Explicit\n",
    "[02/02/2025-23:12:16] [I] Input inference shape : images=8x3x640x640\n",
    "[02/02/2025-23:12:16] [I] Iterations: 10\n",
    "[02/02/2025-23:12:16] [I] Duration: 3s (+ 200ms warm up)\n",
    "[02/02/2025-23:12:16] [I] Sleep time: 0ms\n",
    "[02/02/2025-23:12:16] [I] Idle time: 0ms\n",
    "[02/02/2025-23:12:16] [I] Inference Streams: 1\n",
    "[02/02/2025-23:12:16] [I] ExposeDMA: Disabled\n",
    "[02/02/2025-23:12:16] [I] Data transfers: Enabled\n",
    "[02/02/2025-23:12:16] [I] Spin-wait: Disabled\n",
    "[02/02/2025-23:12:16] [I] Multithreading: Disabled\n",
    "[02/02/2025-23:12:16] [I] CUDA Graph: Enabled\n",
    "[02/02/2025-23:12:16] [I] Separate profiling: Disabled\n",
    "[02/02/2025-23:12:16] [I] Time Deserialize: Disabled\n",
    "[02/02/2025-23:12:16] [I] Time Refit: Disabled\n",
    "[02/02/2025-23:12:16] [I] NVTX verbosity: 0\n",
    "[02/02/2025-23:12:16] [I] Persistent Cache Ratio: 0\n",
    "[02/02/2025-23:12:16] [I] Optimization Profile Index: 0\n",
    "[02/02/2025-23:12:16] [I] Weight Streaming Budget: 100.000000%\n",
    "[02/02/2025-23:12:16] [I] Inputs:\n",
    "[02/02/2025-23:12:16] [I] Debug Tensor Save Destinations:\n",
    "[02/02/2025-23:12:16] [I] === Reporting Options ===\n",
    "[02/02/2025-23:12:16] [I] Verbose: Disabled\n",
    "[02/02/2025-23:12:16] [I] Averages: 10 inferences\n",
    "[02/02/2025-23:12:16] [I] Percentiles: 90,95,99\n",
    "[02/02/2025-23:12:16] [I] Dump refittable layers:Disabled\n",
    "[02/02/2025-23:12:16] [I] Dump output: Disabled\n",
    "[02/02/2025-23:12:16] [I] Profile: Disabled\n",
    "[02/02/2025-23:12:16] [I] Export timing to JSON file:\n",
    "[02/02/2025-23:12:16] [I] Export output to JSON file:\n",
    "[02/02/2025-23:12:16] [I] Export profile to JSON file:\n",
    "[02/02/2025-23:12:16] [I]\n",
    "[02/02/2025-23:12:16] [I] === Device Information ===\n",
    "[02/02/2025-23:12:16] [I] Available Devices:\n",
    "[02/02/2025-23:12:16] [I]   Device 0: \"NVIDIA GeForce RTX 4050 Laptop GPU\" UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-23:12:16] [I] Selected Device: NVIDIA GeForce RTX 4050 Laptop GPU\n",
    "[02/02/2025-23:12:16] [I] Selected Device ID: 0\n",
    "[02/02/2025-23:12:16] [I] Selected Device UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-23:12:16] [I] Compute Capability: 8.9\n",
    "[02/02/2025-23:12:16] [I] SMs: 20\n",
    "[02/02/2025-23:12:16] [I] Device Global Memory: 6140 MiB\n",
    "[02/02/2025-23:12:16] [I] Shared Memory per SM: 100 KiB\n",
    "[02/02/2025-23:12:16] [I] Memory Bus Width: 96 bits (ECC disabled)\n",
    "[02/02/2025-23:12:16] [I] Application Compute Clock Rate: 2.355 GHz\n",
    "[02/02/2025-23:12:16] [I] Application Memory Clock Rate: 7.825 GHz\n",
    "[02/02/2025-23:12:16] [I]\n",
    "[02/02/2025-23:12:16] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
    "[02/02/2025-23:12:16] [I]\n",
    "[02/02/2025-23:12:16] [I] TensorRT version: 10.1.0\n",
    "[02/02/2025-23:12:16] [I] Loading standard plugins\n",
    "[02/02/2025-23:12:16] [I] [TRT] [MemUsageChange] Init CUDA: CPU +14, GPU +0, now: CPU 24, GPU 1065 (MiB)\n",
    "[02/02/2025-23:12:19] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1659, GPU +292, now: CPU 1830, GPU 1357 (MiB)\n",
    "[02/02/2025-23:12:19] [I] Start parsing network model.\n",
    "[02/02/2025-23:12:20] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-23:12:20] [I] [TRT] Input filename:   runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-23:12:20] [I] [TRT] ONNX IR version:  0.0.10\n",
    "[02/02/2025-23:12:20] [I] [TRT] Opset version:    13\n",
    "[02/02/2025-23:12:20] [I] [TRT] Producer name:    pytorch\n",
    "[02/02/2025-23:12:20] [I] [TRT] Producer version: 2.5.1\n",
    "[02/02/2025-23:12:20] [I] [TRT] Domain:\n",
    "[02/02/2025-23:12:20] [I] [TRT] Model version:    0\n",
    "[02/02/2025-23:12:20] [I] [TRT] Doc string:\n",
    "[02/02/2025-23:12:20] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-23:12:20] [I] Finished parsing network model. Parse time: 1.17894\n",
    "[02/02/2025-23:12:20] [I] Set shape of input tensor images for optimization profile 0 to: MIN=1x3x640x640 OPT=8x3x640x640 MAX=16x3x640x640\n",
    "[02/02/2025-23:12:20] [W] [TRT] Calibrator won't be used in explicit quantization mode. Please insert Quantize/Dequantize layers to indicate which tensors to quantize/dequantize.\n",
    "[02/02/2025-23:12:20] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
    "[02/02/2025-23:20:29] [I] [TRT] Detected 1 inputs and 6 output network tensors.\n",
    "[02/02/2025-23:20:43] [I] [TRT] Total Host Persistent Memory: 1306464\n",
    "[02/02/2025-23:20:43] [I] [TRT] Total Device Persistent Memory: 59392\n",
    "[02/02/2025-23:20:43] [I] [TRT] Total Scratch Memory: 0\n",
    "[02/02/2025-23:20:43] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 389 steps to complete.\n",
    "[02/02/2025-23:20:43] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 47.3468ms to assign 14 blocks to 389 nodes requiring 820940288 bytes.\n",
    "[02/02/2025-23:20:43] [I] [TRT] Total Activation Memory: 820939776\n",
    "[02/02/2025-23:20:43] [I] [TRT] Total Weights Memory: 52559872\n",
    "[02/02/2025-23:20:43] [I] [TRT] Engine generation completed in 503.188 seconds.\n",
    "[02/02/2025-23:20:43] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 601 MiB\n",
    "[02/02/2025-23:20:44] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3019 MiB\n",
    "[02/02/2025-23:20:44] [I] Engine built in 503.95 sec.\n",
    "[02/02/2025-23:20:44] [I] Created engine with size: 57.9368 MiB\n",
    "[02/02/2025-23:20:45] [I] [TRT] Loaded engine size: 57 MiB\n",
    "[02/02/2025-23:20:45] [I] Engine deserialized in 0.425144 sec.\n",
    "[02/02/2025-23:20:45] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +783, now: CPU 2, GPU 833 (MiB)\n",
    "[02/02/2025-23:20:45] [I] Setting persistentCacheLimit to 0 bytes.\n",
    "[02/02/2025-23:20:45] [I] Set shape of input tensor images to: 8x3x640x640\n",
    "[02/02/2025-23:20:45] [I] Created execution context with device memory size: 782.909 MiB\n",
    "[02/02/2025-23:20:45] [I] Using random values for input images\n",
    "[02/02/2025-23:20:45] [I] Input binding for images with dimensions 8x3x640x640 is created.\n",
    "[02/02/2025-23:20:45] [I] Output binding for output0 with dimensions 8x12x8400 is created.\n",
    "[02/02/2025-23:20:45] [I] Output binding for 4518 with dimensions 8x12x8400 is created.\n",
    "[02/02/2025-23:20:45] [I] Starting inference\n",
    "[02/02/2025-23:20:45] [I] Capturing CUDA graph for the current execution context\n",
    "[02/02/2025-23:20:45] [I] Successfully captured CUDA graph for the current execution context\n",
    "[02/02/2025-23:20:48] [I] Warmup completed 3 queries over 200 ms\n",
    "[02/02/2025-23:20:48] [I] Timing trace has 63 queries over 3.09464 s\n",
    "[02/02/2025-23:20:48] [I]\n",
    "[02/02/2025-23:20:48] [I] === Trace details ===\n",
    "[02/02/2025-23:20:48] [I] Trace averages of 10 runs:\n",
    "[02/02/2025-23:20:48] [I] Average on 10 runs - GPU latency: 45.3151 ms - Host latency: 48.8996 ms (enqueue 0.0936111 ms)\n",
    "[02/02/2025-23:20:48] [I] Average on 10 runs - GPU latency: 45.3189 ms - Host latency: 48.8838 ms (enqueue 0.0920593 ms)\n",
    "[02/02/2025-23:20:48] [I] Average on 10 runs - GPU latency: 45.3289 ms - Host latency: 48.8775 ms (enqueue 0.143311 ms)\n",
    "[02/02/2025-23:20:48] [I] Average on 10 runs - GPU latency: 45.425 ms - Host latency: 48.9828 ms (enqueue 0.097998 ms)\n",
    "[02/02/2025-23:20:48] [I] Average on 10 runs - GPU latency: 45.4327 ms - Host latency: 49.0421 ms (enqueue 0.112183 ms)\n",
    "[02/02/2025-23:20:48] [I] Average on 10 runs - GPU latency: 45.4255 ms - Host latency: 48.9852 ms (enqueue 0.118213 ms)\n",
    "[02/02/2025-23:20:48] [I]\n",
    "[02/02/2025-23:20:48] [I] === Performance summary ===\n",
    "[02/02/2025-23:20:48] [I] Throughput: 20.3578 qps\n",
    "[02/02/2025-23:20:48] [I] Latency: min = 48.8158 ms, max = 49.1243 ms, mean = 48.9474 ms, median = 48.9478 ms, percentile(90%) = 49.0298 ms, percentile(95%) = 49.05 ms, percentile(99%) = 49.1243 ms\n",
    "[02/02/2025-23:20:48] [I] Enqueue Time: min = 0.0688477 ms, max = 0.43811 ms, mean = 0.108434 ms, median = 0.0889893 ms, percentile(90%) = 0.16626 ms, percentile(95%) = 0.183716 ms, percentile(99%) = 0.43811 ms\n",
    "[02/02/2025-23:20:48] [I] H2D Latency: min = 3.0177 ms, max = 3.17847 ms, mean = 3.07043 ms, median = 3.06934 ms, percentile(90%) = 3.10596 ms, percentile(95%) = 3.11896 ms, percentile(99%) = 3.17847 ms\n",
    "[02/02/2025-23:20:48] [I] GPU Compute Time: min = 45.2567 ms, max = 45.4482 ms, mean = 45.3773 ms, median = 45.4041 ms, percentile(90%) = 45.439 ms, percentile(95%) = 45.4412 ms, percentile(99%) = 45.4482 ms\n",
    "[02/02/2025-23:20:48] [I] D2H Latency: min = 0.494873 ms, max = 0.551453 ms, mean = 0.499667 ms, median = 0.49707 ms, percentile(90%) = 0.500977 ms, percentile(95%) = 0.515381 ms, percentile(99%) = 0.551453 ms\n",
    "[02/02/2025-23:20:48] [I] Total Host Walltime: 3.09464 s\n",
    "[02/02/2025-23:20:48] [I] Total GPU Compute Time: 2.85877 s\n",
    "[02/02/2025-23:20:48] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
    "[02/02/2025-23:20:48] [I]\n",
    "&&&& PASSED TensorRT.trtexec [TensorRT v100100] # /usr/src/tensorrt/bin/trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --int8 --fp16 --useCudaGraph --minShapes=images:1x3x640x640 --optShapes=images:8x3x640x640 --maxShapes=images:16x3x640x640 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best_resilience.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>===================================================================</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *<font face =微軟黑體 color = aqua>Benchmark</font>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variable batch_size  and model_path_no_ext\n",
    "\"\"\"\n",
    "export batch_size=4\n",
    "export filepath_no_ext=runs/qat/qat_yolov9/weights/qat_best_best\n",
    "trtexec \\\n",
    "\t--onnx=${filepath_no_ext}.onnx \\\n",
    "\t--fp16 \\\n",
    "\t--int8 \\\n",
    "\t--saveEngine=${filepath_no_ext}.engine \\\n",
    "\t--timingCacheFile=${filepath_no_ext}.engine.timing.cache \\\n",
    "\t--warmUp=500 \\\n",
    "\t--duration=10  \\\n",
    "\t--useCudaGraph \\\n",
    "\t--useSpinWait \\\n",
    "\t--noDataTransfers \\\n",
    "\t--minShapes=images:1x3x640x640 \\\n",
    "\t--optShapes=images:${batch_size}x3x640x640 \\\n",
    "\t--maxShapes=images:${batch_size}x3x640x640\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>Result</font>* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(torch-3.10) user_pzj@DESKTOP-20USVPU:/mnt/c/Users/PZJ/Desktop/yolov9/yolov9-main_measure/yolov9-main$ trtexec \\\n",
    "--onnx=${filepat> --onnx=${filepath_no_ext}.onnx \\\n",
    "> --fp16 \\\n",
    "> --int8 \\\n",
    "> --saveEngine=${filepath_no_ext}.engine \\\n",
    "> --timingCacheFile=${filepath_no_ext}.engine.timing.cache \\\n",
    "> --warmUp=500 \\\n",
    "> --duration=10  \\\n",
    "> --useCudaGraph \\\n",
    "> --useSpinWait \\\n",
    "> --noDataTransfers \\\n",
    "> --minShapes=images:1x3x640x640 \\\n",
    "> --optShapes=images:${batch_size}x3x640x640 \\\n",
    "> --maxShapes=images:${batch_size}x3x640x640\n",
    "&&&& RUNNING TensorRT.trtexec [TensorRT v100100] # trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --fp16 --int8 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best.engine --timingCacheFile=runs/qat/qat_yolov9/weights/qat_best_best.engine.timing.cache --warmUp=500 --duration=10 --useCudaGraph --useSpinWait --noDataTransfers --minShapes=images:1x3x640x640 --optShapes=images:4x3x640x640 --maxShapes=images:4x3x640x640\n",
    "[02/02/2025-23:37:45] [I] === Model Options ===\n",
    "[02/02/2025-23:37:45] [I] Format: ONNX\n",
    "[02/02/2025-23:37:45] [I] Model: runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-23:37:45] [I] Output:\n",
    "[02/02/2025-23:37:45] [I] === Build Options ===\n",
    "[02/02/2025-23:37:45] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
    "[02/02/2025-23:37:45] [I] avgTiming: 8\n",
    "[02/02/2025-23:37:45] [I] Precision: FP32+FP16+INT8\n",
    "[02/02/2025-23:37:45] [I] LayerPrecisions:\n",
    "[02/02/2025-23:37:45] [I] Layer Device Types:\n",
    "[02/02/2025-23:37:45] [I] Calibration: Dynamic\n",
    "[02/02/2025-23:37:45] [I] Refit: Disabled\n",
    "[02/02/2025-23:37:45] [I] Strip weights: Disabled\n",
    "[02/02/2025-23:37:45] [I] Version Compatible: Disabled\n",
    "[02/02/2025-23:37:45] [I] ONNX Plugin InstanceNorm: Disabled\n",
    "[02/02/2025-23:37:45] [I] TensorRT runtime: full\n",
    "[02/02/2025-23:37:45] [I] Lean DLL Path:\n",
    "[02/02/2025-23:37:45] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
    "[02/02/2025-23:37:45] [I] Exclude Lean Runtime: Disabled\n",
    "[02/02/2025-23:37:45] [I] Sparsity: Disabled\n",
    "[02/02/2025-23:37:45] [I] Safe mode: Disabled\n",
    "[02/02/2025-23:37:45] [I] Build DLA standalone loadable: Disabled\n",
    "[02/02/2025-23:37:45] [I] Allow GPU fallback for DLA: Disabled\n",
    "[02/02/2025-23:37:45] [I] DirectIO mode: Disabled\n",
    "[02/02/2025-23:37:45] [I] Restricted mode: Disabled\n",
    "[02/02/2025-23:37:45] [I] Skip inference: Disabled\n",
    "[02/02/2025-23:37:45] [I] Save engine: runs/qat/qat_yolov9/weights/qat_best_best.engine\n",
    "[02/02/2025-23:37:45] [I] Load engine:\n",
    "[02/02/2025-23:37:45] [I] Profiling verbosity: 0\n",
    "[02/02/2025-23:37:45] [I] Tactic sources: Using default tactic sources\n",
    "[02/02/2025-23:37:45] [I] timingCacheMode: global\n",
    "[02/02/2025-23:37:45] [I] timingCacheFile: runs/qat/qat_yolov9/weights/qat_best_best.engine.timing.cache\n",
    "[02/02/2025-23:37:45] [I] Enable Compilation Cache: Enabled\n",
    "[02/02/2025-23:37:45] [I] errorOnTimingCacheMiss: Disabled\n",
    "[02/02/2025-23:37:45] [I] Preview Features: Use default preview flags.\n",
    "[02/02/2025-23:37:45] [I] MaxAuxStreams: -1\n",
    "[02/02/2025-23:37:45] [I] BuilderOptimizationLevel: -1\n",
    "[02/02/2025-23:37:45] [I] Calibration Profile Index: 0\n",
    "[02/02/2025-23:37:45] [I] Weight Streaming: Disabled\n",
    "[02/02/2025-23:37:45] [I] Debug Tensors:\n",
    "[02/02/2025-23:37:45] [I] Input(s)s format: fp32:CHW\n",
    "[02/02/2025-23:37:45] [I] Output(s)s format: fp32:CHW\n",
    "[02/02/2025-23:37:45] [I] Input build shape (profile 0): images=1x3x640x640+4x3x640x640+4x3x640x640\n",
    "[02/02/2025-23:37:45] [I] Input calibration shapes: model\n",
    "[02/02/2025-23:37:45] [I] === System Options ===\n",
    "[02/02/2025-23:37:45] [I] Device: 0\n",
    "[02/02/2025-23:37:45] [I] DLACore:\n",
    "[02/02/2025-23:37:45] [I] Plugins:\n",
    "[02/02/2025-23:37:45] [I] setPluginsToSerialize:\n",
    "[02/02/2025-23:37:45] [I] dynamicPlugins:\n",
    "[02/02/2025-23:37:45] [I] ignoreParsedPluginLibs: 0\n",
    "[02/02/2025-23:37:45] [I]\n",
    "[02/02/2025-23:37:45] [I] === Inference Options ===\n",
    "[02/02/2025-23:37:45] [I] Batch: Explicit\n",
    "[02/02/2025-23:37:45] [I] Input inference shape : images=4x3x640x640\n",
    "[02/02/2025-23:37:45] [I] Iterations: 10\n",
    "[02/02/2025-23:37:45] [I] Duration: 10s (+ 500ms warm up)\n",
    "[02/02/2025-23:37:45] [I] Sleep time: 0ms\n",
    "[02/02/2025-23:37:45] [I] Idle time: 0ms\n",
    "[02/02/2025-23:37:45] [I] Inference Streams: 1\n",
    "[02/02/2025-23:37:45] [I] ExposeDMA: Disabled\n",
    "[02/02/2025-23:37:45] [I] Data transfers: Disabled\n",
    "[02/02/2025-23:37:45] [I] Spin-wait: Enabled\n",
    "[02/02/2025-23:37:45] [I] Multithreading: Disabled\n",
    "[02/02/2025-23:37:45] [I] CUDA Graph: Enabled\n",
    "[02/02/2025-23:37:45] [I] Separate profiling: Disabled\n",
    "[02/02/2025-23:37:45] [I] Time Deserialize: Disabled\n",
    "[02/02/2025-23:37:45] [I] Time Refit: Disabled\n",
    "[02/02/2025-23:37:45] [I] NVTX verbosity: 0\n",
    "[02/02/2025-23:37:45] [I] Persistent Cache Ratio: 0\n",
    "[02/02/2025-23:37:45] [I] Optimization Profile Index: 0\n",
    "[02/02/2025-23:37:45] [I] Weight Streaming Budget: 100.000000%\n",
    "[02/02/2025-23:37:45] [I] Inputs:\n",
    "[02/02/2025-23:37:45] [I] Debug Tensor Save Destinations:\n",
    "[02/02/2025-23:37:45] [I] === Reporting Options ===\n",
    "[02/02/2025-23:37:45] [I] Verbose: Disabled\n",
    "[02/02/2025-23:37:45] [I] Averages: 10 inferences\n",
    "[02/02/2025-23:37:45] [I] Percentiles: 90,95,99\n",
    "[02/02/2025-23:37:45] [I] Dump refittable layers:Disabled\n",
    "[02/02/2025-23:37:45] [I] Dump output: Disabled\n",
    "[02/02/2025-23:37:45] [I] Profile: Disabled\n",
    "[02/02/2025-23:37:45] [I] Export timing to JSON file:\n",
    "[02/02/2025-23:37:45] [I] Export output to JSON file:\n",
    "[02/02/2025-23:37:45] [I] Export profile to JSON file:\n",
    "[02/02/2025-23:37:45] [I]\n",
    "[02/02/2025-23:37:45] [I] === Device Information ===\n",
    "[02/02/2025-23:37:45] [I] Available Devices:\n",
    "[02/02/2025-23:37:45] [I]   Device 0: \"NVIDIA GeForce RTX 4050 Laptop GPU\" UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-23:37:45] [I] Selected Device: NVIDIA GeForce RTX 4050 Laptop GPU\n",
    "[02/02/2025-23:37:45] [I] Selected Device ID: 0\n",
    "[02/02/2025-23:37:45] [I] Selected Device UUID: GPU-aaf71924-66aa-3d05-6f74-9b9c3942079b\n",
    "[02/02/2025-23:37:45] [I] Compute Capability: 8.9\n",
    "[02/02/2025-23:37:45] [I] SMs: 20\n",
    "[02/02/2025-23:37:45] [I] Device Global Memory: 6140 MiB\n",
    "[02/02/2025-23:37:45] [I] Shared Memory per SM: 100 KiB\n",
    "[02/02/2025-23:37:45] [I] Memory Bus Width: 96 bits (ECC disabled)\n",
    "[02/02/2025-23:37:45] [I] Application Compute Clock Rate: 2.355 GHz\n",
    "[02/02/2025-23:37:45] [I] Application Memory Clock Rate: 7.825 GHz\n",
    "[02/02/2025-23:37:45] [I]\n",
    "[02/02/2025-23:37:45] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
    "[02/02/2025-23:37:45] [I]\n",
    "[02/02/2025-23:37:45] [I] TensorRT version: 10.1.0\n",
    "[02/02/2025-23:37:45] [I] Loading standard plugins\n",
    "[02/02/2025-23:37:45] [I] [TRT] [MemUsageChange] Init CUDA: CPU +14, GPU +0, now: CPU 24, GPU 1065 (MiB)\n",
    "[02/02/2025-23:37:48] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1659, GPU +292, now: CPU 1830, GPU 1357 (MiB)\n",
    "[02/02/2025-23:37:48] [I] Start parsing network model.\n",
    "[02/02/2025-23:37:49] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-23:37:49] [I] [TRT] Input filename:   runs/qat/qat_yolov9/weights/qat_best_best.onnx\n",
    "[02/02/2025-23:37:49] [I] [TRT] ONNX IR version:  0.0.10\n",
    "[02/02/2025-23:37:49] [I] [TRT] Opset version:    13\n",
    "[02/02/2025-23:37:49] [I] [TRT] Producer name:    pytorch\n",
    "[02/02/2025-23:37:49] [I] [TRT] Producer version: 2.5.1\n",
    "[02/02/2025-23:37:49] [I] [TRT] Domain:\n",
    "[02/02/2025-23:37:49] [I] [TRT] Model version:    0\n",
    "[02/02/2025-23:37:49] [I] [TRT] Doc string:\n",
    "[02/02/2025-23:37:49] [I] [TRT] ----------------------------------------------------------------\n",
    "[02/02/2025-23:37:49] [I] Finished parsing network model. Parse time: 1.51177\n",
    "[02/02/2025-23:37:49] [I] Set shape of input tensor images for optimization profile 0 to: MIN=1x3x640x640 OPT=4x3x640x640 MAX=4x3x640x640\n",
    "[02/02/2025-23:37:49] [I] [TRT] Loaded 803376 bytes of timing cache from runs/qat/qat_yolov9/weights/qat_best_best.engine.timing.cache\n",
    "[02/02/2025-23:37:49] [W] [TRT] Calibrator won't be used in explicit quantization mode. Please insert Quantize/Dequantize layers to indicate which tensors to quantize/dequantize.\n",
    "[02/02/2025-23:37:49] [I] [TRT] Global timing cache in use. Profiling results in this builder pass will be stored.\n",
    "[02/02/2025-23:44:09] [I] [TRT] Detected 1 inputs and 6 output network tensors.\n",
    "[02/02/2025-23:44:22] [I] [TRT] Total Host Persistent Memory: 1302096\n",
    "[02/02/2025-23:44:22] [I] [TRT] Total Device Persistent Memory: 54272\n",
    "[02/02/2025-23:44:22] [I] [TRT] Total Scratch Memory: 4300800\n",
    "[02/02/2025-23:44:22] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 377 steps to complete.\n",
    "[02/02/2025-23:44:22] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 44.0362ms to assign 14 blocks to 377 nodes requiring 208588288 bytes.\n",
    "[02/02/2025-23:44:22] [I] [TRT] Total Activation Memory: 208587776\n",
    "[02/02/2025-23:44:22] [I] [TRT] Total Weights Memory: 52567040\n",
    "[02/02/2025-23:44:22] [I] [TRT] Engine generation completed in 393.021 seconds.\n",
    "[02/02/2025-23:44:22] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 151 MiB\n",
    "[02/02/2025-23:44:23] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 2983 MiB\n",
    "[02/02/2025-23:44:23] [I] Engine built in 393.797 sec.\n",
    "[02/02/2025-23:44:23] [I] Created engine with size: 57.9305 MiB\n",
    "[02/02/2025-23:44:23] [I] [TRT] Loaded 803376 bytes of timing cache from runs/qat/qat_yolov9/weights/qat_best_best.engine.timing.cache\n",
    "[02/02/2025-23:44:23] [I] [TRT] Serialized 26 bytes of code generator cache.\n",
    "[02/02/2025-23:44:23] [I] [TRT] Serialized 15313 timing cache entries\n",
    "[02/02/2025-23:44:23] [I] [TRT] Saved 1592736 bytes of timing cache to runs/qat/qat_yolov9/weights/qat_best_best.engine.timing.cache\n",
    "[02/02/2025-23:44:24] [I] [TRT] Loaded engine size: 57 MiB\n",
    "[02/02/2025-23:44:24] [I] Engine deserialized in 0.472527 sec.\n",
    "[02/02/2025-23:44:24] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +199, now: CPU 2, GPU 249 (MiB)\n",
    "[02/02/2025-23:44:24] [I] Setting persistentCacheLimit to 0 bytes.\n",
    "[02/02/2025-23:44:24] [I] Set shape of input tensor images to: 4x3x640x640\n",
    "[02/02/2025-23:44:24] [I] Created execution context with device memory size: 198.925 MiB\n",
    "[02/02/2025-23:44:24] [I] Using random values for input images\n",
    "[02/02/2025-23:44:24] [I] Input binding for images with dimensions 4x3x640x640 is created.\n",
    "[02/02/2025-23:44:24] [I] Output binding for output0 with dimensions 4x12x8400 is created.\n",
    "[02/02/2025-23:44:24] [I] Output binding for 4518 with dimensions 4x12x8400 is created.\n",
    "[02/02/2025-23:44:24] [I] Starting inference\n",
    "[02/02/2025-23:44:24] [I] Capturing CUDA graph for the current execution context\n",
    "[02/02/2025-23:44:24] [I] Successfully captured CUDA graph for the current execution context\n",
    "[02/02/2025-23:44:35] [I] Warmup completed 15 queries over 500 ms\n",
    "[02/02/2025-23:44:35] [I] Timing trace has 458 queries over 10.029 s\n",
    "[02/02/2025-23:44:35] [I]\n",
    "[02/02/2025-23:44:35] [I] === Trace details ===\n",
    "[02/02/2025-23:44:35] [I] Trace averages of 10 runs:\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8379 ms - Host latency: 21.8379 ms (enqueue 0.104266 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8721 ms - Host latency: 21.8721 ms (enqueue 0.101605 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8976 ms - Host latency: 21.8976 ms (enqueue 0.083667 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8964 ms - Host latency: 21.8964 ms (enqueue 0.0829468 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.893 ms - Host latency: 21.893 ms (enqueue 0.10896 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.898 ms - Host latency: 21.898 ms (enqueue 0.101257 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8985 ms - Host latency: 21.8985 ms (enqueue 0.0855713 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8958 ms - Host latency: 21.8958 ms (enqueue 0.124231 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8917 ms - Host latency: 21.8917 ms (enqueue 0.11123 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.894 ms - Host latency: 21.894 ms (enqueue 0.112524 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8971 ms - Host latency: 21.8971 ms (enqueue 0.107983 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8935 ms - Host latency: 21.8935 ms (enqueue 0.107861 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8938 ms - Host latency: 21.8938 ms (enqueue 0.146558 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.9021 ms - Host latency: 21.9021 ms (enqueue 0.0981445 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8917 ms - Host latency: 21.8917 ms (enqueue 0.113916 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8979 ms - Host latency: 21.8979 ms (enqueue 0.117896 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8938 ms - Host latency: 21.8938 ms (enqueue 0.0969482 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8985 ms - Host latency: 21.8985 ms (enqueue 0.114014 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8941 ms - Host latency: 21.8941 ms (enqueue 0.0885254 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8969 ms - Host latency: 21.8969 ms (enqueue 0.0922852 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8933 ms - Host latency: 21.8933 ms (enqueue 0.0964844 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8939 ms - Host latency: 21.8939 ms (enqueue 0.140137 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.895 ms - Host latency: 21.895 ms (enqueue 0.12334 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8947 ms - Host latency: 21.8947 ms (enqueue 0.125342 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8989 ms - Host latency: 21.8989 ms (enqueue 0.110352 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8945 ms - Host latency: 21.8945 ms (enqueue 0.111816 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8951 ms - Host latency: 21.8951 ms (enqueue 0.12915 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8968 ms - Host latency: 21.8968 ms (enqueue 0.131201 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8985 ms - Host latency: 21.8985 ms (enqueue 0.144287 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8957 ms - Host latency: 21.8957 ms (enqueue 0.121191 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8968 ms - Host latency: 21.8968 ms (enqueue 0.108008 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8958 ms - Host latency: 21.8958 ms (enqueue 0.0898926 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8992 ms - Host latency: 21.8992 ms (enqueue 0.078418 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8979 ms - Host latency: 21.8979 ms (enqueue 0.083252 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8947 ms - Host latency: 21.8947 ms (enqueue 0.122998 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.9018 ms - Host latency: 21.9018 ms (enqueue 0.127148 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.9009 ms - Host latency: 21.9009 ms (enqueue 0.123145 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.9044 ms - Host latency: 21.9044 ms (enqueue 0.116016 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.9033 ms - Host latency: 21.9033 ms (enqueue 0.103418 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.9018 ms - Host latency: 21.9018 ms (enqueue 0.141602 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.9037 ms - Host latency: 21.9037 ms (enqueue 0.130371 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8991 ms - Host latency: 21.8991 ms (enqueue 0.0979492 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.9033 ms - Host latency: 21.9033 ms (enqueue 0.106152 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.8991 ms - Host latency: 21.8991 ms (enqueue 0.112402 ms)\n",
    "[02/02/2025-23:44:35] [I] Average on 10 runs - GPU latency: 21.906 ms - Host latency: 21.906 ms (enqueue 0.116309 ms)\n",
    "[02/02/2025-23:44:35] [I]\n",
    "[02/02/2025-23:44:35] [I] === Performance summary ===\n",
    "[02/02/2025-23:44:35] [I] Throughput: 45.6678 qps\n",
    "[02/02/2025-23:44:35] [I] Latency: min = 21.8286 ms, max = 21.9287 ms, mean = 21.8956 ms, median = 21.897 ms, percentile(90%) = 21.9087 ms, percentile(95%) = 21.9121 ms, percentile(99%) = 21.9194 ms\n",
    "[02/02/2025-23:44:35] [I] Enqueue Time: min = 0.0371094 ms, max = 0.441406 ms, mean = 0.111212 ms, median = 0.0922852 ms, percentile(90%) = 0.177734 ms, percentile(95%) = 0.192383 ms, percentile(99%) = 0.318115 ms\n",
    "[02/02/2025-23:44:35] [I] H2D Latency: min = 0 ms, max = 0 ms, mean = 0 ms, median = 0 ms, percentile(90%) = 0 ms, percentile(95%) = 0 ms, percentile(99%) = 0 ms\n",
    "[02/02/2025-23:44:35] [I] GPU Compute Time: min = 21.8286 ms, max = 21.9287 ms, mean = 21.8956 ms, median = 21.897 ms, percentile(90%) = 21.9087 ms, percentile(95%) = 21.9121 ms, percentile(99%) = 21.9194 ms\n",
    "[02/02/2025-23:44:35] [I] D2H Latency: min = 0 ms, max = 0 ms, mean = 0 ms, median = 0 ms, percentile(90%) = 0 ms, percentile(95%) = 0 ms, percentile(99%) = 0 ms\n",
    "[02/02/2025-23:44:35] [I] Total Host Walltime: 10.029 s\n",
    "[02/02/2025-23:44:35] [I] Total GPU Compute Time: 10.0282 s\n",
    "[02/02/2025-23:44:35] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
    "[02/02/2025-23:44:35] [I]\n",
    "&&&& PASSED TensorRT.trtexec [TensorRT v100100] # trtexec --onnx=runs/qat/qat_yolov9/weights/qat_best_best.onnx --fp16 --int8 --saveEngine=runs/qat/qat_yolov9/weights/qat_best_best.engine --timingCacheFile=runs/qat/qat_yolov9/weights/qat_best_best.engine.timing.cache --warmUp=500 --duration=10 --useCudaGraph --useSpinWait --noDataTransfers --minShapes=images:1x3x640x640 --optShapes=images:4x3x640x640 --maxShapes=images:4x3x640x640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font face =微軟黑體 color = aqua>===================================================================</font>* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
